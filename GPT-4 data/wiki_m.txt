@
The history of molecular biology begins in the 1930s with the convergence of various, previously distinct biological and physical disciplines: biochemistry, genetics, microbiology, virology and physics. With the hope of understanding life at its most fundamental level, numerous physicists and chemists also took an interest in what would become molecular biology.

In its modern sense, molecular biology attempts to explain the phenomena of life starting from the macromolecular properties that generate them. Two categories of macromolecules in particular are the focus of the molecular biologist: 1) nucleic acids, among which the most famous is deoxyribonucleic acid (or DNA), the constituent of genes, and 2) proteins, which are the active agents of living organisms. One definition of the scope of molecular biology therefore is to characterize the structure, function and relationships between these two types of macromolecules. This relatively limited definition will suffice to allow us to establish a date for the so-called "molecular revolution", or at least to establish a chronology of its most fundamental developments.

General overview
In its earliest manifestations, molecular biology—the name was coined by Warren Weaver of the Rockefeller Foundation in 1938[1]—was an idea of physical and chemical explanations of life, rather than a coherent discipline. Following the advent of the Mendelian-chromosome theory of heredity in the 1910s and the maturation of atomic theory and quantum mechanics in the 1920s, such explanations seemed within reach. Weaver and others encouraged (and funded) research at the intersection of biology, chemistry and physics, while prominent physicists such as Niels Bohr and Erwin Schrödinger turned their attention to biological speculation. However, in the 1930s and 1940s it was by no means clear which—if any—cross-disciplinary research would bear fruit; work in colloid chemistry, biophysics and radiation biology, crystallography, and other emerging fields all seemed promising.

In 1940, George Beadle and Edward Tatum demonstrated the existence of a precise relationship between genes and proteins.[2] In the course of their experiments connecting genetics with biochemistry, they switched from the genetics mainstay Drosophila to a more appropriate model organism, the fungus Neurospora; the construction and exploitation of new model organisms would become a recurring theme in the development of molecular biology. In 1944, Oswald Avery, working at the Rockefeller Institute of New York, demonstrated that genes are made up of DNA[3](see Avery–MacLeod–McCarty experiment). In 1952, Alfred Hershey and Martha Chase confirmed that the genetic material of the bacteriophage, the virus which infects bacteria, is made up of DNA[4] (see Hershey–Chase experiment). In 1953, James Watson and Francis Crick discovered the double helical structure of the DNA molecule based on the discoveries made by Rosalind Franklin.[5] In 1961, François Jacob and Jacques Monod demonstrated that the products of certain genes regulated the expression of other genes by acting upon specific sites at the edge of those genes. They also hypothesized the existence of an intermediary between DNA and its protein products, which they called messenger RNA.[6] Between 1961 and 1965, the relationship between the information contained in DNA and the structure of proteins was determined: there is a code, the genetic code, which creates a correspondence between the succession of nucleotides in the DNA sequence and a series of amino acids in proteins.

In April 2023, scientists, based on new evidence, concluded that Rosalind Franklin was a contributor and "equal player" in the discovery process of DNA, rather than otherwise, as may have been presented subsequently after the time of the discovery.[7][8][9]

The chief discoveries of molecular biology took place in a period of only about twenty-five years. Another fifteen years were required before new and more sophisticated technologies, united today under the name of genetic engineering, would permit the isolation and characterization of genes, in particular those of highly complex organisms.
$
10
Question 1: What event in the 1930s marked the beginning of the history of molecular biology?
A: The discovery of DNA
B: The convergence of various biological and physical disciplines
C: The naming of molecular biology
D: The advent of quantum mechanics
E: The Mendelian-chromosome theory

Answer: B

Question 2: Who coined the term "molecular biology" in 1938?
A: Niels Bohr
B: Erwin Schrödinger
C: Warren Weaver
D: George Beadle
E: Oswald Avery

Answer: C

Question 3: What was the main focus of molecular biology in its early manifestations?
A: The study of genes and proteins
B: The exploration of quantum mechanics
C: Physical and chemical explanations of life
D: The development of atomic theory
E: The use of colloid chemistry

Answer: C

Question 4: Which two categories of macromolecules are the primary focus of molecular biology?
A: Carbohydrates and lipids
B: Nucleic acids and proteins
C: Proteins and lipids
D: Nucleic acids and carbohydrates
E: Carbohydrates and nucleotides

Answer: B

Question 5: In what year did James Watson and Francis Crick discover the double helical structure of the DNA molecule?
A: 1938
B: 1944
C: 1952
D: 1961
E: 1953

Answer: E

Question 6: Who confirmed that the genetic material of the bacteriophage is made up of DNA?
A: Oswald Avery and Martha Chase
B: George Beadle and Edward Tatum
C: James Watson and Francis Crick
D: François Jacob and Jacques Monod
E: Rosalind Franklin

Answer: A

Question 7: What significant relationship between genes and proteins did George Beadle and Edward Tatum demonstrate?
A: Genes are made up of DNA
B: Proteins are made up of genes
C: A precise relationship exists between genes and proteins
D: Genes and proteins have no connection
E: The genetic code was discovered

Answer: C

Question 8: What did François Jacob and Jacques Monod hypothesize about the intermediary between DNA and its protein products?
A: It is called ribonucleic acid (RNA)
B: It regulates the expression of other genes
C: It is a part of the genetic code
D: It is not important in molecular biology
E: It is responsible for the structure of proteins

Answer: B

Question 9: When did scientists conclude that Rosalind Franklin was an "equal player" in the discovery process of DNA?
A: In 1953
B: In 1940
C: In 1961
D: In 2023
E: In 1910

Answer: D

Question 10: What technology, united today under the name of genetic engineering, allowed for the isolation and characterization of genes?
A: Quantum mechanics
B: Colloid chemistry
C: Atomic theory
D: Highly complex organisms
E: More sophisticated technologies

Answer: E
@
Proteins are large biomolecules and macromolecules that comprise one or more long chains of amino acid residues. Proteins perform a vast array of functions within organisms, including catalysing metabolic reactions, DNA replication, responding to stimuli, providing structure to cells and organisms, and transporting molecules from one location to another. Proteins differ from one another primarily in their sequence of amino acids, which is dictated by the nucleotide sequence of their genes, and which usually results in protein folding into a specific 3D structure that determines its activity.

A linear chain of amino acid residues is called a polypeptide. A protein contains at least one long polypeptide. Short polypeptides, containing less than 20–30 residues, are rarely considered to be proteins and are commonly called peptides. The individual amino acid residues are bonded together by peptide bonds and adjacent amino acid residues. The sequence of amino acid residues in a protein is defined by the sequence of a gene, which is encoded in the genetic code. In general, the genetic code specifies 20 standard amino acids; but in certain organisms the genetic code can include selenocysteine and—in certain archaea—pyrrolysine. Shortly after or even during synthesis, the residues in a protein are often chemically modified by post-translational modification, which alters the physical and chemical properties, folding, stability, activity, and ultimately, the function of the proteins. Some proteins have non-peptide groups attached, which can be called prosthetic groups or cofactors. Proteins can also work together to achieve a particular function, and they often associate to form stable protein complexes.

Once formed, proteins only exist for a certain period and are then degraded and recycled by the cell's machinery through the process of protein turnover. A protein's lifespan is measured in terms of its half-life and covers a wide range. They can exist for minutes or years with an average lifespan of 1–2 days in mammalian cells. Abnormal or misfolded proteins are degraded more rapidly either due to being targeted for destruction or due to being unstable.

Like other biological macromolecules such as polysaccharides and nucleic acids, proteins are essential parts of organisms and participate in virtually every process within cells. Many proteins are enzymes that catalyse biochemical reactions and are vital to metabolism. Proteins also have structural or mechanical functions, such as actin and myosin in muscle and the proteins in the cytoskeleton, which form a system of scaffolding that maintains cell shape. Other proteins are important in cell signaling, immune responses, cell adhesion, and the cell cycle. In animals, proteins are needed in the diet to provide the essential amino acids that cannot be synthesized. Digestion breaks the proteins down for metabolic use.

Proteins may be purified from other cellular components using a variety of techniques such as ultracentrifugation, precipitation, electrophoresis, and chromatography; the advent of genetic engineering has made possible a number of methods to facilitate purification. Methods commonly used to study protein structure and function include immunohistochemistry, site-directed mutagenesis, X-ray crystallography, nuclear magnetic resonance and mass spectrometry.
$
10
Question 1: What is the primary determinant of a protein's sequence of amino acids?
A: Genetic code
B: Protein turnover
C: Peptide bonds
D: Post-translational modification
E: Prosthetic groups

Answer: A

Question 2: What is the term for a linear chain of amino acid residues?
A: Peptide bonds
B: Polypeptide
C: Prosthetic groups
D: Nucleotide sequence
E: Protein turnover

Answer: B

Question 3: Which process alters the physical and chemical properties, folding, and stability of proteins?
A: Post-translational modification
B: Protein turnover
C: Genetic code
D: Polysaccharide synthesis
E: Peptide bond formation

Answer: A

Question 4: What is the average lifespan of proteins in mammalian cells?
A: Minutes
B: Years
C: 1-2 days
D: Weeks
E: Months

Answer: C

Question 5: What is the term for non-peptide groups attached to proteins that play a role in their function?
A: Peptide bonds
B: Polysaccharides
C: Cofactors
D: Nucleotides
E: Prosthetic groups

Answer: C

Question 6: Which technique is commonly used to purify proteins from other cellular components?
A: Protein turnover
B: Electrophoresis
C: Peptide bond formation
D: Polysaccharide synthesis
E: Chromatography

Answer: E

Question 7: What are actin and myosin examples of in the context of proteins?
A: Polysaccharides
B: Enzymes
C: Muscle proteins
D: Prosthetic groups
E: Cytoskeleton components

Answer: C

Question 8: What is the process by which proteins are degraded and recycled by the cell's machinery?
A: Peptide bond formation
B: Protein turnover
C: Post-translational modification
D: Genetic code translation
E: Polysaccharide synthesis

Answer: B

Question 9: What is the term for essential parts of organisms that participate in virtually every process within cells?
A: Proteins
B: Nucleic acids
C: Polysaccharides
D: Peptides
E: Prosthetic groups

Answer: A

Question 10: Which method is commonly used to study protein structure and function involving the use of X-ray technology?
A: Ultracentrifugation
B: Immunohistochemistry
C: Mass spectrometry
D: X-ray crystallography
E: Site-directed mutagenesis

Answer: D
@
A biomolecule or biological molecule is a loosely used term for molecules present in organisms that are essential to one or more typically biological processes, such as cell division, morphogenesis, or development.[1] Biomolecules include large macromolecules (or polyelectrolytes) such as proteins, carbohydrates, lipids, and nucleic acids, as well as small molecules such as primary metabolites, secondary metabolites and natural products. A more general name for this class of material is biological materials. Biomolecules are an important element of living organisms, those biomolecules are often endogenous,[2] produced within the organism[3] but organisms usually need exogenous biomolecules, for example certain nutrients, to survive.

Biology and its subfields of biochemistry and molecular biology study biomolecules and their reactions. Most biomolecules are organic compounds, and just four elements—oxygen, carbon, hydrogen, and nitrogen—make up 96% of the human body's mass. But many other elements, such as the various biometals, are also present in small amounts.

The uniformity of both specific types of molecules (the biomolecules) and of certain metabolic pathways are invariant features among the wide diversity of life forms; thus these biomolecules and metabolic pathways are referred to as "biochemical universals"[4] or "theory of material unity of the living beings", a unifying concept in biology, along with cell theory and evolution theory.[5]
$
10
Question 1: What are the four elements that make up 96% of the human body's mass?
A: Carbon, hydrogen, nitrogen, and calcium
B: Oxygen, carbon, hydrogen, and sulfur
C: Sodium, potassium, calcium, and magnesium
D: Iron, copper, zinc, and manganese
E: Nitrogen, oxygen, phosphorus, and sulfur

Answer: B

Question 2: What term is often used to describe molecules that are essential to biological processes in organisms?
A: Organic molecules
B: Primary metabolites
C: Biomolecules
D: Biometals
E: Natural products

Answer: C

Question 3: In addition to proteins, carbohydrates, lipids, and nucleic acids, what are the other two categories of biomolecules mentioned in the text?
A: Vitamins and minerals
B: Primary metabolites and secondary metabolites
C: Enzymes and coenzymes
D: Organic compounds and inorganic compounds
E: Amino acids and fatty acids

Answer: B

Question 4: What is the term for biomolecules produced within the organism?
A: Endogenous
B: Exogenous
C: Metabolites
D: Inorganic compounds
E: Enzymes

Answer: A

Question 5: What is the term used in biology to refer to the concept of the uniformity of certain types of molecules and metabolic pathways across diverse life forms?
A: Cell theory
B: Theory of evolution
C: Biochemical universals
D: Genetic variation
E: Metabolic diversity

Answer: C

Question 6: Which four elements make up the majority of biomolecules?
A: Iron, copper, zinc, and manganese
B: Oxygen, carbon, hydrogen, and nitrogen
C: Sodium, potassium, calcium, and magnesium
D: Nitrogen, oxygen, phosphorus, and sulfur
E: Carbon, hydrogen, nitrogen, and calcium

Answer: B

Question 7: What are molecules called that are essential to processes like cell division and development in organisms?
A: Organic compounds
B: Secondary metabolites
C: Natural products
D: Biomolecules
E: Enzymes

Answer: D

Question 8: Which subfields of biology study biomolecules and their reactions?
A: Botany and zoology
B: Ecology and genetics
C: Biochemistry and molecular biology
D: Microbiology and virology
E: Paleontology and geology

Answer: C

Question 9: What is the term for biomolecules that organisms usually need from external sources to survive?
A: Exogenous
B: Metabolites
C: Endogenous
D: Inorganic compounds
E: Primary metabolites

Answer: A

Question 10: What are the most abundant elements in the human body, making up 96% of its mass?
A: Carbon, hydrogen, oxygen, and nitrogen
B: Sodium, potassium, calcium, and magnesium
C: Iron, copper, zinc, and manganese
D: Nitrogen, oxygen, phosphorus, and sulfur
E: Oxygen, carbon, hydrogen, and sulfur

Answer: A
@
A molecule is a group of two or more atoms held together by attractive forces known as chemical bonds; depending on context, the term may or may not include ions which satisfy this criterion.[4][5][6][7][8] In quantum physics, organic chemistry, and biochemistry, the distinction from ions is dropped and molecule is often used when referring to polyatomic ions.

A molecule may be homonuclear, that is, it consists of atoms of one chemical element, e.g. two atoms in the oxygen molecule (O2); or it may be heteronuclear, a chemical compound composed of more than one element, e.g. water (two hydrogen atoms and one oxygen atom; H2O). In the kinetic theory of gases, the term molecule is often used for any gaseous particle regardless of its composition. This relaxes the requirement that a molecule contains two or more atoms, since the noble gases are individual atoms.[9] Atoms and complexes connected by non-covalent interactions, such as hydrogen bonds or ionic bonds, are typically not considered single molecules.[10]

Concepts similar to molecules have been discussed since ancient times, but modern investigation into the nature of molecules and their bonds began in the 17th century. Refined over time by scientists such as Robert Boyle, Amedeo Avogadro, Jean Perrin, and Linus Pauling, the study of molecules is today known as molecular physics or molecular chemistry.

Molecular science
The science of molecules is called molecular chemistry or molecular physics, depending on whether the focus is on chemistry or physics. Molecular chemistry deals with the laws governing the interaction between molecules that results in the formation and breakage of chemical bonds, while molecular physics deals with the laws governing their structure and properties. In practice, however, this distinction is vague. In molecular sciences, a molecule consists of a stable system (bound state) composed of two or more atoms. Polyatomic ions may sometimes be usefully thought of as electrically charged molecules. The term unstable molecule is used for very reactive species, i.e., short-lived assemblies (resonances) of electrons and nuclei, such as radicals, molecular ions, Rydberg molecules, transition states, van der Waals complexes, or systems of colliding atoms as in Bose–Einstein condensate.
$
10
Question 1: What are the attractive forces that hold atoms together in a molecule called?
A: Chemical bonds
B: Ionic bonds
C: Hydrogen bonds
D: Van der Waals forces
E: Covalent bonds

Question 2: In which field of study is the distinction from ions often dropped, and the term "molecule" used for polyatomic ions?
A: Quantum physics
B: Organic chemistry
C: Molecular biology
D: Biochemistry
E: Kinetic theory of gases

Question 3: What type of molecule consists of atoms of one chemical element?
A: Heteronuclear molecule
B: Ionic molecule
C: Homonuclear molecule
D: Covalent molecule
E: Hydrogen molecule

Question 4: What does the term "molecule" often refer to in the kinetic theory of gases?
A: Noble gases
B: Organic compounds
C: Polyatomic ions
D: Ionic compounds
E: Gaseous particles

Question 5: Who are some of the scientists mentioned in the text who contributed to the study of molecules?
A: Robert Boyle and Linus Pauling
B: Amedeo Avogadro and Jean Perrin
C: Isaac Newton and Galileo Galilei
D: Marie Curie and Albert Einstein
E: Charles Darwin and Gregor Mendel

Question 6: What is the study of molecules known as today?
A: Molecular chemistry
B: Molecular biology
C: Molecular physics
D: Molecular genetics
E: Molecular geology

Question 7: In molecular sciences, what is a molecule considered to be composed of?
A: Atoms and electrons
B: Atoms and ions
C: Polyatomic ions
D: Two or more atoms
E: Noble gases

Question 8: What term is used for very reactive species, such as molecular ions and radicals?
A: Stable molecules
B: Ionic compounds
C: Van der Waals complexes
D: Unstable molecules
E: Covalent molecules

Question 9: What does molecular chemistry deal with?
A: The laws governing molecular structure
B: The laws governing molecular properties
C: The formation and breakage of chemical bonds
D: The interaction between atoms and electrons
E: The study of polyatomic ions

Question 10: What type of molecules may sometimes be thought of as electrically charged molecules?
A: Heteronuclear molecules
B: Stable molecules
C: Ionic molecules
D: Unstable molecules
E: Hydrogen molecules
@
In condensed matter physics, a Bose–Einstein condensate (BEC) is a state of matter that is typically formed when a gas of bosons at very low densities is cooled to temperatures very close to absolute zero (−273.15 °C or −459.67 °F). Under such conditions, a large fraction of bosons occupy the lowest quantum state, at which microscopic quantum mechanical phenomena, particularly wavefunction interference, become apparent macroscopically.

This state was first predicted, generally, in 1924–1925 by Albert Einstein,[1] crediting a pioneering paper by Satyendra Nath Bose on the new field now known as quantum statistics.[2] In 1995, the Bose–Einstein condensate was created by Eric Cornell and Carl Wieman of the University of Colorado Boulder using rubidium atoms; later that year, Wolfgang Ketterle of MIT produced a BEC using sodium atoms. In 2001 Cornell, Wieman and Ketterle shared the Nobel Prize in Physics "for the achievement of Bose-Einstein condensation in dilute gases of alkali atoms, and for early fundamental studies of the properties of the condensates."[3]

History
Bose first sent a paper to Einstein on the quantum statistics of light quanta (now called photons), in which he derived Planck's quantum radiation law without any reference to classical physics. Einstein was impressed, translated the paper himself from English to German and submitted it for Bose to the Zeitschrift für Physik, which published it in 1924.[4] (The Einstein manuscript, once believed to be lost, was found in a library at Leiden University in 2005.[5]) Einstein then extended Bose's ideas to matter in two other papers.[6][7] The result of their efforts is the concept of a Bose gas, governed by Bose–Einstein statistics, which describes the statistical distribution of identical particles with integer spin, now called bosons. Bosons, particles that include the photon as well as atoms such as helium-4 (4
He
), are allowed to share a quantum state. Einstein proposed that cooling bosonic atoms to a very low temperature would cause them to fall (or "condense") into the lowest accessible quantum state, resulting in a new form of matter.

In 1938, Fritz London proposed the BEC as a mechanism for superfluidity in 4
He
 and superconductivity.[8][9]

The quest to produce a Bose–Einstein condensate in the laboratory was stimulated by a paper published in 1976 by two Program Directors at the National Science Foundation (William Stwalley and Lewis Nosanow).[10] This led to the immediate pursuit of the idea by four independent research groups; these were led by Isaac Silvera (University of Amsterdam), Walter Hardy (University of British Columbia), Thomas Greytak (Massachusetts Institute of Technology) and David Lee (Cornell University).[11]

On 5 June 1995, the first gaseous condensate was produced by Eric Cornell and Carl Wieman at the University of Colorado at Boulder NIST–JILA lab, in a gas of rubidium atoms cooled to 170 nanokelvins (nK).[12] Shortly thereafter, Wolfgang Ketterle at MIT produced a Bose–Einstein Condensate in a gas of sodium atoms. For their achievements Cornell, Wieman, and Ketterle received the 2001 Nobel Prize in Physics.[13] These early studies founded the field of ultracold atoms, and hundreds of research groups around the world now routinely produce BECs of dilute atomic vapors in their labs.

Since 1995, many other atomic species have been condensed, and BECs have also been realized using molecules, quasi-particles, and photons.[14]
$
10
Question 1: In what state of matter is a Bose-Einstein condensate (BEC) typically formed?
A: Solid
B: Liquid
C: Gas
D: Plasma
E: Superfluid

Answer: C

Question 2: What is the main characteristic of a Bose-Einstein condensate in terms of the quantum state of its particles?
A: They occupy the highest quantum state.
B: They occupy the intermediate quantum state.
C: They occupy the lowest quantum state.
D: They have no quantum state.
E: They have an undefined quantum state.

Answer: C

Question 3: Who first predicted the existence of a Bose-Einstein condensate, and whose work on quantum statistics was credited for this prediction?
A: Albert Einstein
B: Wolfgang Ketterle
C: Fritz London
D: Satyendra Nath Bose
E: Eric Cornell

Answer: A

Question 4: In which year was the Bose-Einstein condensate first created using rubidium atoms?
A: 1938
B: 1976
C: 1995
D: 2001
E: 1924

Answer: C

Question 5: What is the term for particles that include the photon as well as atoms such as helium-4?
A: Fermions
B: Leptons
C: Bosons
D: Quarks
E: Protons

Answer: C

Question 6: Who proposed the concept of a Bose gas governed by Bose-Einstein statistics?
A: Fritz London
B: Isaac Silvera
C: Walter Hardy
D: David Lee
E: Albert Einstein

Answer: E

Question 7: What is the mechanism proposed by Fritz London for superfluidity in helium-4?
A: Bose-Einstein condensation
B: Ionic bonding
C: Covalent bonding
D: Quantum tunneling
E: Van der Waals forces

Answer: A

Question 8: What temperature were rubidium atoms cooled to when the first gaseous condensate was produced in 1995?
A: 170 nanokelvins (nK)
B: 273 degrees Celsius
C: Absolute zero
D: 1000 degrees Kelvin
E: 0.001 nanokelvins (nK)

Answer: A

Question 9: Which field of study has been founded by the early studies of Bose-Einstein condensates using dilute atomic vapors?
A: Quantum mechanics
B: Molecular physics
C: Superconductivity
D: Ultracold atoms
E: Thermodynamics

Answer: D

Question 10: In addition to atoms, what other types of particles have been used to create Bose-Einstein condensates?
A: Molecules, quarks, and photons
B: Electrons, protons, and neutrons
C: Ions, electrons, and photons
D: Fermions, leptons, and quarks
E: Neutrinos, positrons, and mesons

Answer: A
@
Molecular physics is the study of the physical properties of molecules and molecular dynamics. The field overlaps significantly with physical chemistry, chemical physics, and quantum chemistry. It is often considered as a sub-field of atomic, molecular, and optical physics. Research groups studying molecular physics are typically designated as one of these other fields. Molecular physics addresses phenomena due to both molecular structure and individual atomic processes within molecules. Like atomic physics, it relies on a combination of classical and quantum mechanics to describe interactions between electromagnetic radiation and matter. Experiments in the field often rely heavily on techniques borrowed from atomic physics, such as spectroscopy and scattering.

Molecular Structure
In a molecule, both the electrons and nuclei experience similar-scale forces from the Coulomb interaction. However, the nuclei remain at nearly fixed locations in the molecule while the electrons move significantly. This picture of a molecule is based on the idea that nucleons are much heavier than electrons, so will move much less in response to the same force. Neutron scattering experiments on molecules have been used to verify this description.[1]

When atoms join into molecules, their inner electrons remain bound to their original nucleus while the outer valence electrons are distributed around the molecule. The charge distribution of these valence electrons determines the electronic energy level of a molecule, and can be described by molecular orbital theory, which closely follows the atomic orbital theory used for single atoms. Assuming that the momenta of the electrons are on the order of ħ/a (where ħ is the reduced Planck's constant and a is the average internuclear distance within a molecule, ~1Å), the magnitude of the energy spacing for electronic states can be estimated at a few electron volts. This is the case for most low-lying molecular energy states, and corresponds to transitions in the visible and ultraviolet regions of the electromagnetic spectrum.[1][2]

In addition to the electronic energy levels shared with atoms, molecules have additional quantized energy levels corresponding to vibrational and rotational states. Vibrational energy levels refer to motion of the nuclei about their equilibrium positions in the molecule. The approximate energy spacing of these levels can be estimated by treating each nucleus as a quantum harmonic oscillator in the potential produced by the molecule, and comparing its associated frequency to that of an electron experiencing the same potential. The result is a is an energy spacing about 100x smaller than that for electronic levels. In agreement with this estimate, vibrational spectra show transitions in the near infrared (about 1 - 5 μm).[2] Finally, rotational energy states describe semi-rigid rotation of the entire molecule and produce transition wavelengths in the far infrared and microwave regions (about 100-10,000 μm in wavelength). These are the smallest energy spacings, and their size can be understood by comparing the energy of a diatomic molecule with internuclear spacing ~1Å to the energy of a valence electron (estimated above as ~ħ/a).[1]

Actual molecular spectra also show transitions which simultaneously couple electronic, vibrational, and rotational states. For example, transitions involving both rotational and vibrational states are often referred to as rotational-vibrational or rovibrational transitions. Vibronic transitions combine electronic and vibrational transitions, and rovibronic transitions combine electronic, rotational, and vibrational transitions. Due to the very different frequencies associated with each type of transition, the wavelengths associated with these mixed transitions vary across the electromagnetic spectrum.[2]
$
10
Question 1: What field of study is often considered a sub-field of atomic, molecular, and optical physics?
A: Quantum chemistry
B: Chemical physics
C: Molecular physics
D: Physical chemistry
E: Quantum physics

Answer: C

Question 2: What kind of interactions between electromagnetic radiation and matter are described in molecular physics?
A: Gravitational interactions
B: Magnetic interactions
C: Strong nuclear interactions
D: Coulomb interactions
E: Weak nuclear interactions

Answer: D

Question 3: What determines the electronic energy level of a molecule?
A: The charge distribution of valence electrons
B: The number of neutrons in the molecule
C: The temperature of the surroundings
D: The speed of light in the medium
E: The size of the molecule

Answer: A

Question 4: What energy spacing is typically associated with electronic states of molecules?
A: A few electron volts
B: A few nanometers
C: A few picoseconds
D: A few angstroms
E: A few megahertz

Answer: A

Question 5: What type of energy levels correspond to motion of the nuclei around their equilibrium positions in a molecule?
A: Rotational energy levels
B: Electronic energy levels
C: Vibrational energy levels
D: Quantum energy levels
E: Kinetic energy levels

Answer: C

Question 6: What is the approximate energy spacing of vibrational energy levels compared to electronic energy levels?
A: About the same
B: 100 times smaller
C: 100 times larger
D: 10 times smaller
E: 10 times larger

Answer: B

Question 7: Which region of the electromagnetic spectrum do rotational energy states of molecules produce transition wavelengths in?
A: Near infrared
B: Ultraviolet
C: Visible
D: Far infrared
E: Microwave

Answer: D

Question 8: What are transitions that simultaneously couple electronic, vibrational, and rotational states often referred to as?
A: Electronic transitions
B: Vibrational transitions
C: Rotational-vibrational transitions
D: Quantum transitions
E: Spectroscopic transitions

Answer: C

Question 9: What kind of transitions combine electronic and vibrational transitions in molecules?
A: Vibronic transitions
B: Rovibrational transitions
C: Electronic-vibrational transitions
D: Quantum transitions
E: Spin transitions

Answer: A

Question 10: What is the largest energy spacing among the different types of molecular energy levels mentioned in the text?
A: Electronic energy levels
B: Vibrational energy levels
C: Rotational energy levels
D: Quantum energy levels
E: Valence energy levels

Answer: C
@
Spectroscopy is the field of study that measures and interprets the electromagnetic spectra that result from the interaction between electromagnetic radiation and matter as a function of the wavelength or frequency of the radiation.[1][2] In simpler terms, spectroscopy is the precise study of color as generalized from visible light to all bands of the electromagnetic spectrum.

Spectroscopy, primarily in the electromagnetic spectrum, is a fundamental exploratory tool in the fields of astronomy, chemistry, materials science, and physics, allowing the composition, physical structure and electronic structure of matter to be investigated at the atomic, molecular and macro scale, and over astronomical distances.

Historically, spectroscopy originated as the study of the wavelength dependence of the absorption by gas phase matter of visible light dispersed by a prism. Current applications of spectroscopy include biomedical spectroscopy in the areas of tissue analysis and medical imaging. Matter waves and acoustic waves can also be considered forms of radiative energy, and recently gravitational waves have been associated with a spectral signature in the context of the Laser Interferometer Gravitational-Wave Observatory (LIGO).[3]

Introduction
Spectroscopy is a branch of science concerned with the spectra of electromagnetic radiation as a function of its wavelength or frequency measured by spectrographic equipment, and other techniques, in order to obtain information concerning the structure and properties of matter.[4] Spectral measurement devices are referred to as spectrometers, spectrophotometers, spectrographs or spectral analyzers. Most spectroscopic analysis in the laboratory starts with a sample to be analyzed, then a light source is chosen from any desired range of the light spectrum, then the light goes through the sample to a dispersion array (diffraction grating instrument) and is captured by a photodiode. For astronomical purposes, the telescope must be equipped with the light dispersion device. There are various versions of this basic setup that may be employed.

Spectroscopy began with Isaac Newton splitting light with a prism; a key moment in the development of modern optics.[5] Therefore, it was originally the study of visible light which we call color that later under the studies of James Clerk Maxwell came to include the entire electromagnetic spectrum.[6] Although color is involved in spectroscopy, it is not equated with the color of elements or objects which involve the absorption and reflection of certain electromagnetic waves to give objects a sense of color to our eyes. Rather spectroscopy involves the splitting of light by a prism, diffraction grating, or similar instrument, to give off a particular discrete line pattern called a “spectrum” unique to each different type of element. Most elements are first put into a gaseous phase to allow the spectra to be examined although today other methods can be used on different phases. Each element that is diffracted by a prism-like instrument displays either an absorption spectrum or an emission spectrum depending upon whether the element is being cooled or heated.[7]

Until recently all spectroscopy involved the study of line spectra and most spectroscopy still does.[8] Vibrational spectroscopy is the branch of spectroscopy that studies the spectra.[9] However, the latest developments in spectroscopy can sometimes dispense with the dispersion technique. In biochemical spectroscopy, information can be gathered about biological tissue by absorption and light scattering techniques. Light scattering spectroscopy is a type of reflectance spectroscopy that determines tissue structures by examining elastic scattering.[10] In such a case, it is the tissue that acts as a diffraction or dispersion mechanism.

Spectroscopic studies were central to the development of quantum mechanics, because the first useful atomic models described the spectra of Hydrogen which models include the Bohr model, the Schrödinger equation, and Matrix mechanics which all can produce the spectral lines of Hydrogen, therefore, providing the basis for discrete quantum jumps to match the discrete hydrogen spectrum. Also, Max Planck's explanation of blackbody radiation involved spectroscopy because he was comparing the wavelength of light using a photometer to the temperature of a Black Body.[11] Spectroscopy is used in physical and analytical chemistry because atoms and molecules have unique spectra. As a result, these spectra can be used to detect, identify and quantify information about the atoms and molecules. Spectroscopy is also used in astronomy and remote sensing on Earth. Most research telescopes have spectrographs. The measured spectra are used to determine the chemical composition and physical properties of astronomical objects (such as their temperature, density of elements in a star, velocity, black holes and more).[12] An important use for spectroscopy is in biochemistry. Molecular samples may be analyzed for species identification and energy content.[13]
$
10
Question 1: What is spectroscopy primarily concerned with studying?
A: Gravitational waves
B: Color
C: Acoustic waves
D: Matter waves
E: Electromagnetic spectra

Answer: E

Question 2: In what fields is spectroscopy a fundamental exploratory tool?
A: Geology and psychology
B: Geography and engineering
C: Astronomy, chemistry, materials science, and physics
D: Botany and economics
E: Linguistics and sociology

Answer: C

Question 3: What is the term for spectral measurement devices used in spectroscopic analysis?
A: Telescopes
B: Radiometers
C: Spectrometers
D: Oscilloscopes
E: Calorimeters

Answer: C

Question 4: Who is credited with splitting light with a prism, a key moment in the development of modern optics?
A: Albert Einstein
B: Isaac Newton
C: Max Planck
D: James Clerk Maxwell
E: Niels Bohr

Answer: B

Question 5: What term is used to describe the particular discrete line pattern produced when light is split by a prism in spectroscopy?
A: Spectrum
B: Rainbow
C: Diffraction
D: Dispersion
E: Absorption

Answer: A

Question 6: What does vibrational spectroscopy study?
A: The colors of elements
B: Tissue structures
C: The spectra of gases
D: Line spectra
E: Spectrograph design

Answer: B

Question 7: What did spectroscopic studies contribute to the development of quantum mechanics?
A: Models of the solar system
B: Explanations of blackbody radiation
C: The theory of relativity
D: The discovery of atomic nuclei
E: The concept of black holes

Answer: B

Question 8: How can spectroscopy be used in biochemistry?
A: To determine the temperature of biological samples
B: To identify species and measure energy content in molecular samples
C: To create diffraction patterns in tissues
D: To study the behavior of elastic scattering
E: To examine the dispersion of light in biological tissues

Answer: B

Question 9: What physical properties of astronomical objects can be determined using spectroscopy?
A: Their color and shape
B: Their size and mass
C: Their age and lifespan
D: Their temperature and density of elements
E: Their gravitational pull and magnetic field

Answer: D

Question 10: What information can be obtained about atoms and molecules using spectroscopy?
A: Their weight and size
B: Their chemical composition and physical properties
C: Their location in space
D: Their electrical charge and spin
E: Their speed and direction of movement

Answer: B
@
The electromagnetic spectrum is the range of frequencies (the spectrum) of electromagnetic radiation and their respective wavelengths and photon energies.

The electromagnetic spectrum covers electromagnetic waves with frequencies ranging from below one hertz to above 1025 hertz, corresponding to wavelengths from thousands of kilometers down to a fraction of the size of an atomic nucleus. This frequency range is divided into separate bands, and the electromagnetic waves within each frequency band are called by different names; beginning at the low-frequency (long-wavelength) end of the spectrum these are: radio waves, microwaves, infrared, visible light, ultraviolet, X-rays, and gamma rays at the high-frequency (short wavelength) end. The electromagnetic waves in each of these bands have different characteristics, such as how they are produced, how they interact with matter, and their practical applications. There is no known limit for long and short wavelengths. Extreme ultraviolet, soft X-rays, hard X-rays and gamma rays are classified as ionizing radiation because their photons have enough energy to ionize atoms, causing chemical reactions. Radiation of visible light and longer wavelengths are classified as nonionizing radiation because they have insufficient energy to cause these effects.

Throughout most of the electromagnetic spectrum, spectroscopy can be used to separate waves of different frequencies, producing a spectrum of the constituent frequencies. Spectroscopy is used to study the interactions of electromagnetic waves with matter.[1]

Regions
Class	 	Wave-
length
�\lambda 	Freq-
uency
�
f	Energy per
photon
�
E
Ionizing
radiation	γ	Gamma rays	 	10 pm	30 EHz	124 keV
100 pm	3 EHz	12.4 keV
HX	Hard X-rays
SX	Soft X-rays	10 nm	30 PHz	124 eV
EUV	Extreme
ultraviolet	121 nm	3 PHz	10.2 eV
 	NUV	Near ultraviolet,
400 nm	750 THz	
 		Visible spectrum	700 nm	480 THz	
Infrared	NIR	Near infrared	1 μm	300 THz	1.24 eV
10 μm	30 THz	124 meV
MIR	Mid infrared
100 μm	3 THz	12.4 meV
FIR	Far infrared
1 mm	300 GHz	1.24 meV
Micro-
waves	EHF	Extremely high
frequency
1 cm	30 GHz	124 μeV
SHF	Super high
frequency
1 dm	3 GHz	12.4 μeV
UHF	Ultra high
frequency
1 m	300 MHz	1.24 μeV
Radio
waves	VHF	Very high
frequency
10 m	30 MHz	124 neV
HF	High
frequency
100 m	3 MHz	12.4 neV
MF	Medium
frequency
1 km	300 kHz	1.24 neV
LF	Low
frequency
10 km	30 kHz	124 peV
VLF	Very low
frequency
100 km	3 kHz	12.4 peV
ULF	Ultra low
frequency
1 Mm	300 Hz	1.24 peV
SLF	Super low
frequency
10 Mm	30 Hz	124 feV
ELF	Extremely low
frequency
100 Mm	3 Hz	12.4 feV
Sources: File:Light spectrum.svg[7][8][9]Table shows the lower limits for the specified class

The electromagnetic spectrum

A visualization of the electromagnetic spectrum.
The types of electromagnetic radiation are broadly classified into the following classes (regions, bands or types):[1]

Gamma radiation
X-ray radiation
Ultraviolet radiation
Visible light
Infrared radiation
Microwave radiation
Radio waves
This classification goes in the increasing order of wavelength, which is characteristic of the type of radiation.[1]

There are no precisely defined boundaries between the bands of the electromagnetic spectrum; rather they fade into each other like the bands in a rainbow (which is the sub-spectrum of visible light). Radiation of each frequency and wavelength (or in each band) has a mix of properties of the two regions of the spectrum that bound it. For example, red light resembles infrared radiation in that it can excite and add energy to some chemical bonds and indeed must do so to power the chemical mechanisms responsible for photosynthesis and the working of the visual system.

The distinction between X-rays and gamma rays is partly based on sources: the photons generated from nuclear decay or other nuclear and subnuclear/particle process are always termed gamma rays, whereas X-rays are generated by electronic transitions involving highly energetic inner atomic electrons.[10][11][12] In general, nuclear transitions are much more energetic than electronic transitions, so gamma rays are more energetic than X-rays, but exceptions exist. By analogy to electronic transitions, muonic atom transitions are also said to produce X-rays, even though their energy may exceed 6 megaelectronvolts (0.96 pJ),[13] whereas there are many (77 known to be less than 10 keV (1.6 fJ)) low-energy nuclear transitions (e.g., the 7.6 eV (1.22 aJ) nuclear transition of thorium-229m), and, despite being one million-fold less energetic than some muonic X-rays, the emitted photons are still called gamma rays due to their nuclear origin.[14]

The convention that EM radiation that is known to come from the nucleus is always called "gamma ray" radiation is the only convention that is universally respected, however. Many astronomical gamma ray sources (such as gamma ray bursts) are known to be too energetic (in both intensity and wavelength) to be of nuclear origin. Quite often, in high-energy physics and in medical radiotherapy, very high energy EMR (in the > 10 MeV region)—which is of higher energy than any nuclear gamma ray—is not called X-ray or gamma ray, but instead by the generic term of "high-energy photons".

The region of the spectrum where a particular observed electromagnetic radiation falls is reference frame-dependent (due to the Doppler shift for light), so EM radiation that one observer would say is in one region of the spectrum could appear to an observer moving at a substantial fraction of the speed of light with respect to the first to be in another part of the spectrum. For example, consider the cosmic microwave background. It was produced when matter and radiation decoupled, by the de-excitation of hydrogen atoms to the ground state. These photons were from Lyman series transitions, putting them in the ultraviolet (UV) part of the electromagnetic spectrum. Now this radiation has undergone enough cosmological red shift to put it into the microwave region of the spectrum for observers moving slowly (compared to the speed of light) with respect to the cosmos.
$
10
Question 1: What is the electromagnetic spectrum's range of frequencies and wavelengths typically used to study?
A: The visible light range
B: Extremely low frequencies
C: The entire electromagnetic spectrum
D: Wavelengths shorter than an atomic nucleus
E: Only radio waves

Answer: C

Question 2: Which class of electromagnetic radiation is classified as ionizing radiation?
A: Microwaves
B: Visible light
C: Ultraviolet
D: X-rays
E: Radio waves

Answer: D

Question 3: What is the primary function of spectroscopy in the context of the electromagnetic spectrum?
A: To generate electromagnetic waves
B: To measure the speed of light
C: To identify the color of light
D: To study the interactions of electromagnetic waves with matter
E: To measure the temperature of objects

Answer: D

Question 4: What is the classification of radiation that includes visible light?
A: X-ray radiation
B: Ultraviolet radiation
C: Infrared radiation
D: Visible light
E: Radio waves

Answer: D

Question 5: What is the distinguishing factor between X-rays and gamma rays in terms of their sources?
A: Gamma rays are generated by electronic transitions, while X-rays are from nuclear decay.
B: X-rays are always more energetic than gamma rays.
C: Gamma rays are never associated with nuclear processes.
D: X-rays are produced by cosmic microwave background radiation.
E: There is no difference between X-rays and gamma rays.

Answer: A

Question 6: What determines the region of the electromagnetic spectrum where radiation appears for an observer?
A: The type of radiation
B: The observer's velocity relative to the cosmos
C: The wavelength of the radiation
D: The energy of the radiation
E: The temperature of the source

Answer: B

Question 7: What is the generic term used for very high-energy electromagnetic radiation that exceeds 10 MeV?
A: Gamma rays
B: X-rays
C: Ultraviolet radiation
D: Radio waves
E: High-energy photons

Answer: E

Question 8: Which class of electromagnetic radiation is associated with nuclear transitions?
A: Radio waves
B: Microwaves
C: Visible light
D: Gamma rays
E: Ultraviolet radiation

Answer: D

Question 9: What is the characteristic of electromagnetic radiation that spans from thousands of kilometers to the size of an atomic nucleus?
A: It exhibits ionizing radiation.
B: It covers the entire electromagnetic spectrum.
C: It has a continuous wavelength range.
D: It is subject to the Doppler shift effect.
E: It fades into other regions like a rainbow.

Answer: E

Question 10: What does the Doppler shift effect influence regarding the region of the electromagnetic spectrum?
A: The energy of radiation
B: The speed of light
C: The type of radiation
D: The observer's perception of radiation
E: The wavelength of radiation

Answer: D
@
Ionizing radiation (or ionising radiation), including nuclear radiation, consists of subatomic particles or electromagnetic waves that have sufficient energy to ionize atoms or molecules by detaching electrons from them.[1] Some particles can travel up to 99% of the speed of light, and the electromagnetic waves are on the high-energy portion of the electromagnetic spectrum.

Gamma rays, X-rays, and the higher energy ultraviolet part of the electromagnetic spectrum are ionizing radiation, whereas the lower energy ultraviolet, visible light, nearly all types of laser light, infrared, microwaves, and radio waves are non-ionizing radiation. The boundary between ionizing and non-ionizing radiation in the ultraviolet area cannot be sharply defined, as different molecules and atoms ionize at different energies. The energy of ionizing radiation starts between 10 electronvolts (eV) and 33 eV.

Typical ionizing subatomic particles include alpha particles, beta particles, and neutrons. These are typically created by radioactive decay, and almost all are energetic enough to ionize. There are also secondary cosmic particles produced after cosmic rays interact with Earth's atmosphere, including muons, mesons, and positrons.[2][3] Cosmic rays may also produce radioisotopes on Earth (for example, carbon-14), which in turn decay and emit ionizing radiation. Cosmic rays and the decay of radioactive isotopes are the primary sources of natural ionizing radiation on Earth, contributing to background radiation. Ionizing radiation is also generated artificially by X-ray tubes, particle accelerators, and nuclear fission.

Ionizing radiation is not immediately detectable by human senses, so instruments such as Geiger counters are used to detect and measure it. However, very high energy particles can produce visible effects on both organic and inorganic matter (e.g. water lighting in Cherenkov radiation) or humans (e.g. acute radiation syndrome).[4]

Ionizing radiation is used in a wide variety of fields such as medicine, nuclear power, research, and industrial manufacturing, but presents a health hazard if proper measures against excessive exposure are not taken. Exposure to ionizing radiation causes cell damage to living tissue and organ damage. In high acute doses, it will result in radiation burns and radiation sickness, and lower level doses over a protracted time can cause cancer.[5][6] The International Commission on Radiological Protection (ICRP) issues guidance on ionizing radiation protection, and the effects of dose uptake on human health.
$
10
Question 1: What is the primary characteristic that distinguishes ionizing radiation from non-ionizing radiation?
A: Particle velocity
B: Wavelength
C: Frequency
D: Energy level
E: Source of radiation

Answer: D

Question 2: Which part of the electromagnetic spectrum contains ionizing radiation?
A: Radio waves
B: Infrared
C: Visible light
D: Gamma rays
E: Microwaves

Answer: D

Question 3: What is the lower limit of energy for ionizing radiation?
A: 1 electronvolt (eV)
B: 10 electronvolts (eV)
C: 33 electronvolts (eV)
D: 50 electronvolts (eV)
E: 100 electronvolts (eV)

Answer: B

Question 4: Which subatomic particles are typically considered ionizing when they interact with matter?
A: Protons
B: Neutrons
C: Electrons
D: Alpha particles
E: Gamma rays

Answer: D

Question 5: What is the primary source of natural ionizing radiation on Earth?
A: Ultraviolet light
B: Cosmic rays
C: Radio waves
D: Visible light
E: Infrared radiation

Answer: B

Question 6: Which instrument is commonly used to detect and measure ionizing radiation?
A: Thermometer
B: Barometer
C: Geiger counter
D: Microscope
E: Compass

Answer: C

Question 7: How do very high-energy particles of ionizing radiation manifest visible effects on matter?
A: By causing chemical reactions
B: By producing visible light
C: By changing the color of materials
D: By altering the composition of atoms
E: By creating visible heat

Answer: B

Question 8: In which fields is ionizing radiation commonly used?
A: Agriculture and farming
B: Astronomy and astrophysics
C: Medicine and nuclear power
D: Geology and archaeology
E: Meteorology and weather forecasting

Answer: C

Question 9: What health hazards are associated with exposure to ionizing radiation?
A: Increased muscle strength
B: Improved digestion
C: Radiation burns and sickness
D: Enhanced cognitive abilities
E: Resistance to common illnesses

Answer: C

Question 10: Which organization provides guidance on ionizing radiation protection and its effects on human health?
A: World Health Organization (WHO)
B: International Atomic Energy Agency (IAEA)
C: International Commission on Radiological Protection (ICRP)
D: United Nations Educational, Scientific and Cultural Organization (UNESCO)
E: National Aeronautics and Space Administration (NASA)

Answer: C
@
In physics, a subatomic particle is a particle smaller than an atom.[1] According to the Standard Model of particle physics, a subatomic particle can be either a composite particle, which is composed of other particles (for example, a proton, neutron, or meson), or an elementary particle, which is not composed of other particles (for example, an electron, photon, or muon).[2] Particle physics and nuclear physics study these particles and how they interact.[3]

Experiments show that light could behave like a stream of particles (called photons) as well as exhibiting wave-like properties. This led to the concept of wave–particle duality to reflect that quantum-scale particles behave both like particles and like waves; they are sometimes called wavicles to reflect this.[4]

Another concept, the uncertainty principle, states that some of their properties taken together, such as their simultaneous position and momentum, cannot be measured exactly.[5] The wave–particle duality has been shown to apply not only to photons but to more massive particles as well.[6]

Interactions of particles in the framework of quantum field theory are understood as creation and annihilation of quanta of corresponding fundamental interactions. This blends particle physics with field theory.

Even among particle physicists, the exact definition of a particle has diverse descriptions. These professional attempts at the definition of a particle include:[7]

A particle is a collapsed wave function
A particle is a quantum excitation of a field
A particle is an irreducible representation of the Poincaré group
A particle is an observed thing

Classification
By composition
Subatomic particles are either "elementary", i.e. not made of multiple other particles, or "composite" and made of more than one elementary particle bound together.

The elementary particles of the Standard Model are:[8]

Six "flavors" of quarks: up, down, strange, charm, bottom, and top;
Six types of leptons: electron, electron neutrino, muon, muon neutrino, tau, tau neutrino;
Twelve gauge bosons (force carriers): the photon of electromagnetism, the three W and Z bosons of the weak force, and the eight gluons of the strong force;
The Higgs boson.

The Standard Model classification of particles
All of these have now been discovered by experiments, with the latest being the top quark (1995), tau neutrino (2000), and Higgs boson (2012).

Various extensions of the Standard Model predict the existence of an elementary graviton particle and many other elementary particles, but none have been discovered as of 2021.
$
10
Question 1: According to the Standard Model of particle physics, what are the two categories of subatomic particles?
A: Quarks and leptons
B: Protons and electrons
C: Mesons and muons
D: Neutrinos and photons
E: Gluons and bosons

Answer: A

Question 2: What concept in physics describes the dual behavior of particles, behaving both like particles and waves?
A: Wavefunction collapse
B: Uncertainty principle
C: Wave–particle duality
D: Quantum excitation
E: Poincaré group

Answer: C

Question 3: Which principle states that certain properties of particles, like their simultaneous position and momentum, cannot be precisely measured?
A: Wave–particle duality
B: Standard Model
C: Uncertainty principle
D: Poincaré representation
E: Quantum excitation

Answer: C

Question 4: In the context of quantum field theory, how are interactions of particles understood?
A: As creation and annihilation of fundamental particles
B: As deterministic events
C: As fixed trajectories
D: As wave propagation
E: As static entities

Answer: A

Question 5: What is one of the descriptions used by particle physicists to define a particle?
A: A collapsed wave function
B: A quantum excitation of a field
C: A quantum leap
D: A composite entity
E: An observable phenomenon

Answer: B

Question 6: How are subatomic particles classified based on composition?
A: As either elementary or composite
B: As protons or neutrons
C: As fermions or bosons
D: As particles or waves
E: As up or down quarks

Answer: A

Question 7: Which subatomic particle is responsible for carrying the electromagnetic force?
A: Quark
B: Lepton
C: Photon
D: Gluon
E: Higgs boson

Answer: C

Question 8: What is the latest discovered elementary particle mentioned in the text?
A: Electron neutrino
B: Muon
C: Top quark
D: Tau neutrino
E: Higgs boson

Answer: C

Question 9: What elementary particle is predicted by the Standard Model but has not been discovered as of 2021?
A: Graviton
B: Photon
C: Quark
D: Electron
E: Neutrino

Answer: A

Question 10: How many "flavors" of quarks are there according to the Standard Model?
A: Three
B: Four
C: Five
D: Six
E: Seven

Answer: D
@
An atom is a particle that consists of a nucleus of protons and neutrons surrounded by an electromagnetically-bound cloud of electrons. The atom is the basic particle of the chemical elements, and the chemical elements are distinguished from each other by the number of protons that are in their atoms. For example, any atom that contains 11 protons is sodium, and any atom that contains 29 protons is copper. The number of neutrons defines the isotope of the element.

Atoms are extremely small, typically around 100 picometers across. A human hair is about a million carbon atoms wide. This is smaller than the shortest wavelength of visible light, which means humans cannot see atoms with conventional microscopes. Atoms are so small that accurately predicting their behavior using classical physics is not possible due to quantum effects.

More than 99.94% of an atom's mass is in the nucleus. Each proton has a positive electric charge, while each electron has a negative charge, and the neutrons, if any are present, have no electric charge. If the numbers of protons and electrons are equal, as they normally are, then the atom is electrically neutral. If an atom has more electrons than protons, then it has an overall negative charge, and is called a negative ion (or anion). Conversely, if it has more protons than electrons, it has a positive charge, and is called a positive ion (or cation).

The electrons of an atom are attracted to the protons in an atomic nucleus by the electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by the nuclear force. This force is usually stronger than the electromagnetic force that repels the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force. In this case, the nucleus splits and leaves behind different elements. This is a form of nuclear decay.

Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules or crystals. The ability of atoms to attach and detach from each other is responsible for most of the physical changes observed in nature. Chemistry is the discipline that studies these changes.
$
10
Question 1: What distinguishes one chemical element from another?
A: The number of neutrons
B: The number of electrons
C: The number of protons
D: The number of electrons and protons combined
E: The number of neutrons and protons combined

Answer: C

Question 2: What defines the isotope of an element?
A: The number of electrons
B: The number of protons
C: The number of neutrons
D: The number of electrons and protons combined
E: The number of protons and neutrons combined

Answer: C

Question 3: What is the approximate size of an atom?
A: 1 millimeter
B: 1 micrometer
C: 100 picometers
D: 1 nanometer
E: 1 centimeter

Answer: C

Question 4: What percentage of an atom's mass is typically found in the nucleus?
A: Less than 1%
B: About 10%
C: Approximately 50%
D: More than 99.94%
E: About 75%

Answer: D

Question 5: When an atom has more electrons than protons, what type of ion is formed?
A: Neutral ion
B: Anion
C: Cation
D: Isotope
E: Neutron

Answer: B

Question 6: What force attracts electrons to the protons in an atomic nucleus?
A: Gravitational force
B: Nuclear force
C: Electromagnetic force
D: Strong force
E: Weak force

Answer: C

Question 7: Under what circumstances does the nucleus of an atom split, leaving behind different elements?
A: When the electromagnetic force becomes stronger than the nuclear force
B: When it absorbs light
C: When it loses electrons
D: When it forms a chemical bond
E: When it gains protons

Answer: A

Question 8: What term is used for an atom with more protons than electrons?
A: Neutral atom
B: Negative ion (anion)
C: Positive ion (cation)
D: Isotope
E: Neutron

Answer: C

Question 9: How do atoms typically form chemical compounds?
A: By emitting gamma rays
B: By sharing electrons through chemical bonds
C: By losing protons
D: By merging nuclei
E: By absorbing neutrons

Answer: B

Question 10: Which discipline studies the changes that occur when atoms attach to one another to form compounds?
A: Biology
B: Physics
C: Chemistry
D: Geology
E: Astronomy

Answer: C
@
Classical physics is a group of physics theories that predate modern, more complete, or more widely applicable theories. If a currently accepted theory is considered to be modern, and its introduction represented a major paradigm shift, then the previous theories, or new theories based on the older paradigm, will often be referred to as belonging to the area of "classical physics".

As such, the definition of a classical theory depends on context. Classical physical concepts are often used when modern theories are unnecessarily complex for a particular situation. Most often, classical physics refers to pre-1900 physics, while modern physics refers to post-1900 physics, which incorporates elements of quantum mechanics and relativity.[1]

Overview
Classical theory has at least two distinct meanings in physics. In the context of quantum mechanics, classical theory refers to theories of physics that do not use the quantisation paradigm, which includes classical mechanics and relativity.[2] Likewise, classical field theories, such as general relativity and classical electromagnetism, are those that do not use quantum mechanics.[3] In the context of general and special relativity, classical theories are those that obey Galilean relativity.[4]

Depending on point of view, among the branches of theory sometimes included in classical physics are variably:

Classical mechanics
Newton's laws of motion
Classical Lagrangian and Hamiltonian formalisms
Classical electrodynamics (Maxwell's Equations)
Classical thermodynamics
Classical chaos theory and nonlinear dynamics
$
10
Question 1:
A: Classical physics theories are considered classical when they predate which era of physics?
B: Pre-1900
C: Post-1900
D: Post-1950
E: Pre-1800
Answer: B

Question 2:
A: Classical physics is often used when modern theories are seen as too what for a specific situation?
B: Precise
C: Simple
D: Complex
E: Abstract
Answer: D

Question 3:
A: Which branch of classical physics includes Maxwell's Equations?
B: Classical mechanics
C: Classical thermodynamics
D: Classical chaos theory
E: Classical electrodynamics
Answer: E

Question 4:
A: Classical field theories like general relativity do or do not use quantum mechanics?
B: Do
C: Do not
D: Occasionally
E: Sometimes
Answer: C

Question 5:
A: In the context of quantum mechanics, classical theory refers to theories that use what paradigm?
B: Quantisation
C: Relativity
D: Discrete mathematics
E: Probability
Answer: A

Question 6:
A: Classical physics refers to theories that belong to which era of physics?
B: Modern physics
C: Pre-1800 physics
D: Post-1950 physics
E: Pre-1900 physics
Answer: E

Question 7:
A: Classical physics encompasses classical field theories, which include which of the following?
B: Quantum mechanics
C: Classical mechanics
D: General relativity
E: Special relativity
Answer: D

Question 8:
A: Classical theory in the context of general and special relativity obeys which relativity?
B: Newtonian relativity
C: Galilean relativity
D: Einsteinian relativity
E: Bohr's relativity
Answer: C

Question 9:
A: Classical physics is often used when modern theories are deemed too what for a particular situation?
B: Inaccurate
C: Precise
D: Simple
E: Theoretical
Answer: C

Question 10:
A: Classical mechanics is a part of which era of physics?
B: Pre-1800 physics
C: Post-1950 physics
D: Modern physics
E: Pre-1900 physics
Answer: E
@
Thermodynamics is a branch of physics that deals with heat, work, and temperature, and their relation to energy, entropy, and the physical properties of matter and radiation. The behavior of these quantities is governed by the four laws of thermodynamics which convey a quantitative description using measurable macroscopic physical quantities, but may be explained in terms of microscopic constituents by statistical mechanics. Thermodynamics applies to a wide variety of topics in science and engineering, especially physical chemistry, biochemistry, chemical engineering and mechanical engineering, but also in other complex fields such as meteorology.

Historically, thermodynamics developed out of a desire to increase the efficiency of early steam engines, particularly through the work of French physicist Sadi Carnot (1824) who believed that engine efficiency was the key that could help France win the Napoleonic Wars.[1] Scots-Irish physicist Lord Kelvin was the first to formulate a concise definition of thermodynamics in 1854[2] which stated, "Thermo-dynamics is the subject of the relation of heat to forces acting between contiguous parts of bodies, and the relation of heat to electrical agency." German physicist and mathematician Rudolf Clausius restated Carnot's principle known as the Carnot cycle and gave so the theory of heat a truer and sounder basis. His most important paper, "On the Moving Force of Heat",[3] published in 1850, first stated the second law of thermodynamics. In 1865 he introduced the concept of entropy. In 1870 he introduced the virial theorem, which applied to heat.[4]

The initial application of thermodynamics to mechanical heat engines was quickly extended to the study of chemical compounds and chemical reactions. Chemical thermodynamics studies the nature of the role of entropy in the process of chemical reactions and has provided the bulk of expansion and knowledge of the field. Other formulations of thermodynamics emerged. Statistical thermodynamics, or statistical mechanics, concerns itself with statistical predictions of the collective motion of particles from their microscopic behavior. In 1909, Constantin Carathéodory presented a purely mathematical approach in an axiomatic formulation, a description often referred to as geometrical thermodynamics.
$
10
Question 1:
A: What branch of physics deals with heat, work, and temperature?
B: Quantum physics
C: Thermodynamics
D: Electromagnetism
E: Relativity
Answer: C

Question 2:
A: Who was the French physicist known for his work on engine efficiency in early steam engines and his contribution to thermodynamics?
B: Lord Kelvin
C: Rudolf Clausius
D: Sadi Carnot
E: Constantin Carathéodory
Answer: D

Question 3:
A: Who restated Carnot's principle and gave the theory of heat a truer and sounder basis, including introducing the concept of entropy?
B: Lord Kelvin
C: Rudolf Clausius
D: Sadi Carnot
E: Constantin Carathéodory
Answer: C

Question 4:
A: Chemical thermodynamics primarily studies the role of what in chemical reactions?
B: Heat
C: Pressure
D: Light
E: Gravity
Answer: B

Question 5:
A: What formulation of thermodynamics focuses on statistical predictions of the collective motion of particles based on their microscopic behavior?
B: Geometrical thermodynamics
C: Chemical thermodynamics
D: Classical thermodynamics
E: Statistical thermodynamics
Answer: E

Question 6:
A: In what year did Lord Kelvin provide a concise definition of thermodynamics, describing it as "the subject of the relation of heat to forces acting between contiguous parts of bodies"?
B: 1824
C: 1850
D: 1854
E: 1865
Answer: D

Question 7:
A: Who introduced the virial theorem, which applied to heat, in 1870?
B: Lord Kelvin
C: Rudolf Clausius
D: Sadi Carnot
E: Constantin Carathéodory
Answer: C

Question 8:
A: What branch of physics concerns itself with statistical predictions of particle behavior based on their microscopic actions?
B: Classical mechanics
C: Electromagnetism
D: Statistical thermodynamics
E: Quantum physics
Answer: D

Question 9:
A: What formulation of thermodynamics did Constantin Carathéodory present in 1909, often referred to as geometrical thermodynamics?
B: Statistical thermodynamics
C: Chemical thermodynamics
D: Classical thermodynamics
E: Geometrical thermodynamics
Answer: E

Question 10:
A: What was the initial application of thermodynamics to, which was later extended to the study of chemical compounds and reactions?
B: Geometrical thermodynamics
C: Chemical thermodynamics
D: Statistical thermodynamics
E: Steam engines
Answer: E
@
Engineering is the practice of using natural science, mathematics, and the engineering design process[1] to solve technical problems, increase efficiency and productivity, and improve systems. Modern engineering comprises many subfields which include designing and improving infrastructure, machinery, vehicles, electronics, materials, and energy.[2]

The discipline of engineering encompasses a broad range of more specialized fields of engineering, each with a more specific emphasis on particular areas of applied mathematics, applied science, and types of application. See glossary of engineering.

The term engineering is derived from the Latin ingenium, meaning "cleverness" and ingeniare, meaning "to contrive, devise".[3]

Definition
The American Engineers' Council for Professional Development (ECPD, the predecessor of ABET)[4] has defined "engineering" as:

The creative application of scientific principles to design or develop structures, machines, apparatus, or manufacturing processes, or works utilizing them singly or in combination; or to construct or operate the same with full cognizance of their design; or to forecast their behavior under specific operating conditions; all as respects an intended function, economics of operation and safety to life and property.[5][6]

Main branches of engineering
Engineering is a broad discipline that is often broken down into several sub-disciplines. Although an engineer will usually be trained in a specific discipline, he or she may become multi-disciplined through experience. Engineering is often characterized as having four main branches:[56][57][58] chemical engineering, civil engineering, electrical engineering, and mechanical engineering.

Chemical engineering
Main article: Chemical engineering
Chemical engineering is the application of physics, chemistry, biology, and engineering principles in order to carry out chemical processes on a commercial scale, such as the manufacture of commodity chemicals, specialty chemicals, petroleum refining, microfabrication, fermentation, and biomolecule production.

Civil engineering
Main article: Civil engineering
Civil engineering is the design and construction of public and private works, such as infrastructure (airports, roads, railways, water supply, and treatment etc.), bridges, tunnels, dams, and buildings.[59][60] Civil engineering is traditionally broken into a number of sub-disciplines, including structural engineering, environmental engineering, and surveying. It is traditionally considered to be separate from military engineering.[61]

Electrical engineering
Main article: Electrical engineering

Electric motor
Electrical engineering is the design, study, and manufacture of various electrical and electronic systems, such as broadcast engineering, electrical circuits, generators, motors, electromagnetic/electromechanical devices, electronic devices, electronic circuits, optical fibers, optoelectronic devices, computer systems, telecommunications, instrumentation, control systems, and electronics.

Mechanical engineering
Main article: Mechanical engineering
Mechanical engineering is the design and manufacture of physical or mechanical systems, such as power and energy systems, aerospace/aircraft products, weapon systems, transportation products, engines, compressors, powertrains, kinematic chains, vacuum technology, vibration isolation equipment, manufacturing, robotics, turbines, audio equipments, and mechatronics.

Bioengineering
Main article: Biological engineering
Bioengineering is the engineering of biological systems for a useful purpose. Examples of bioengineering research include bacteria engineered to produce chemicals, new medical imaging technology, portable and rapid disease diagnostic devices, prosthetics, biopharmaceuticals, and tissue-engineered organs.
$
10
Question 1:
A: What practice uses natural science, mathematics, and the engineering design process to solve technical problems and improve systems?
B: Mathematics
C: Engineering
D: Science
E: Economics
Answer: C

Question 2:
A: Engineering comprises many subfields, each with a specific emphasis on areas of applied mathematics and applied science. What term is used to describe this specialization?
B: Engineering diversity
C: Engineering subdisciplines
D: Engineering collaboration
E: Engineering unity
Answer: B

Question 3:
A: What is the Latin term for "cleverness" from which the word "engineering" is derived?
B: Inertia
C: Ingenuity
D: Innovation
E: Inception
Answer: C

Question 4:
A: According to the American Engineers' Council for Professional Development, what is the definition of engineering?
B: The creative application of economic principles to solve technical problems.
C: The application of artistic principles to design and construct structures.
D: The study of scientific principles without practical application.
E: The creative application of scientific principles to design or develop structures, machines, and more.
Answer: E

Question 5:
A: Engineering is often divided into four main branches. Which of the following is NOT one of these branches?
B: Chemical engineering
C: Civil engineering
D: Electrical engineering
E: Medical engineering
Answer: E

Question 6:
A: What branch of engineering involves the application of physics, chemistry, biology, and engineering principles to carry out chemical processes on a commercial scale?
B: Mechanical engineering
C: Electrical engineering
D: Civil engineering
E: Chemical engineering
Answer: E

Question 7:
A: Which branch of engineering deals with the design and construction of infrastructure, bridges, dams, and buildings?
B: Mechanical engineering
C: Chemical engineering
D: Electrical engineering
E: Civil engineering
Answer: E

Question 8:
A: What field of engineering focuses on electrical and electronic systems, telecommunications, computer systems, and control systems?
B: Civil engineering
C: Mechanical engineering
D: Chemical engineering
E: Electrical engineering
Answer: E

Question 9:
A: Mechanical engineering involves the design and manufacture of various physical systems. Which of the following is NOT an area covered by mechanical engineering?
B: Aerospace products
C: Power and energy systems
D: Computer systems
E: Robotics
Answer: D

Question 10:
A: What branch of engineering involves the engineering of biological systems for purposes such as medical imaging, prosthetics, and tissue-engineered organs?
B: Mechanical engineering
C: Electrical engineering
D: Chemical engineering
E: Bioengineering
Answer: E
@
Civil engineering is a professional engineering discipline that deals with the design, construction, and maintenance of the physical and naturally built environment, including public works such as roads, bridges, canals, dams, airports, sewage systems, pipelines, structural components of buildings, and railways.[1][2]

Civil engineering is traditionally broken into a number of sub-disciplines. It is considered the second-oldest engineering discipline after military engineering,[3] and it is defined to distinguish non-military engineering from military engineering.[4] Civil engineering can take place in the public sector from municipal public works departments through to federal government agencies, and in the private sector from locally based firms to global Fortune 500 companies.[5]

History
Civil engineering as a discipline
Civil engineering is the application of physical and scientific principles for solving the problems of society, and its history is intricately linked to advances in the understanding of physics and mathematics throughout history. Because civil engineering is a broad profession, including several specialized sub-disciplines, its history is linked to knowledge of structures, materials science, geography, geology, soils, hydrology, environmental science, mechanics, project management, and other fields.[6]

Throughout ancient and medieval history most architectural design and construction was carried out by artisans, such as stonemasons and carpenters, rising to the role of master builder. Knowledge was retained in guilds and seldom supplanted by advances. Structures, roads, and infrastructure that existed were repetitive, and increases in scale were incremental.[7]

One of the earliest examples of a scientific approach to physical and mathematical problems applicable to civil engineering is the work of Archimedes in the 3rd century BC, including Archimedes' principle, which underpins our understanding of buoyancy, and practical solutions such as Archimedes' screw. Brahmagupta, an Indian mathematician, used arithmetic in the 7th century AD, based on Hindu-Arabic numerals, for excavation (volume) computations.[8]
$
10
Question 1:
A: What is the primary focus of civil engineering?
B: Chemical research
C: Biological studies
D: Construction of spacecraft
E: Design and construction of the built environment
Answer: E

Question 2:
A: Civil engineering is considered one of the oldest engineering disciplines. What is the only engineering discipline that predates it?
B: Electrical engineering
C: Mechanical engineering
D: Military engineering
E: Computer engineering
Answer: D

Question 3:
A: Civil engineering includes various sub-disciplines. Which of the following is NOT traditionally considered a sub-discipline of civil engineering?
B: Structural engineering
C: Environmental engineering
D: Aerospace engineering
E: Geotechnical engineering
Answer: D

Question 4:
A: What scientific principles are applied in civil engineering to solve societal problems?
B: Physics and mathematics
C: Chemistry and biology
D: Astronomy and geology
E: Computer science and robotics
Answer: B

Question 5:
A: In ancient and medieval times, who was primarily responsible for architectural design and construction?
B: Civil engineers
C: Scientists
D: Artisans like stonemasons and carpenters
E: Politicians and rulers
Answer: D

Question 6:
A: Which ancient mathematician made significant contributions to civil engineering by developing principles related to buoyancy and practical solutions like the Archimedes' screw?
B: Euclid
C: Pythagoras
D: Archimedes
E: Brahmagupta
Answer: D

Question 7:
A: What mathematical system did Brahmagupta use for excavation computations in civil engineering during the 7th century AD?
B: Roman numerals
C: Greek numerals
D: Hindu-Arabic numerals
E: Mayan numerals
Answer: D
@
Building design, also called architectural design, refers to the broadly based architectural, engineering and technical applications to the design of buildings. All building projects require the services of a building designer, typically a licensed architect. Smaller, less complicated projects often do not require a licensed professional, and the design of such projects is often undertaken by building designers, draftspersons, interior designers (for interior fit-outs or renovations), or contractors. Larger, more complex building projects require the services of many professionals trained in specialist disciplines, usually coordinated by an architect.

Occupations
Architect
Main article: Architect
An architect is a person trained in the planning, design and supervision of the construction of buildings. Professionally, an architect's decisions affect public safety, and thus an architect must undergo specialized training consisting of advanced education and a practicum (or internship) for practical experience to earn a license to practice architecture. In most of the world's jurisdictions, the professional and commercial use of the term "architect" is legally protected.

Building engineer
Main article: Building engineering
Building engineering typically includes the services of electrical, mechanical and structural engineers.

Draftsperson
A draftsperson or documenter is someone who has attained a certificate or diploma in architectural drafting (or equivalent training), and provides services relating to the preparation of construction documents rather than building design. Some draftspersons are employed by architectural design firms and building contractors, while others are self-employed.[1]

Building designer
In many places, building codes and legislation of professions allow persons to design single family residential buildings and in some cases light commercial buildings without an architectural license. As such, "Building designer" is a common designation in the United States, Canada, Australia and elsewhere for someone who offers building design services but is not a licensed architect or engineer.

Anyone may use the title of "building designer" in the broadest sense. In many places, a building designer may achieve certification demonstrating a higher level of training. In the U.S., the National Council of Building Designer Certification (NCBDC),[2] an offshoot of the American Institute of Building Design,[3] administers a program leading to the title of Certified Professional Building Designer (CPBD). In most cases, building designers are trained as architectural technologists or draftspersons; they may also be architecture school graduates that have not completed licensing requirements.[4]

Many building designers are known as "residential" or "home designers", since they focus mainly on residential design and remodeling.[5] In the U.S. state of Nevada, "Residential Designer" is a regulated term for those who are registered as such under Nevada State Board of Architecture, Interior Design and Residential Design, and one may not legally represent oneself in a professional capacity without being currently registered.

In Australia where use of the term architect and some derivatives is highly restricted but the architectural design of buildings has very few restrictions in place, the term building designer is used extensively by people or design practices who are not registered by the relevant State Board of Architects. In Queensland the term building design is used in legislation which licences practitioners as part of a broader building industry licensing system. In Victoria there is a registration process for building designers and in other States there is currently no regulation of the profession. A Building Designers Association operates in each state to represent the interests of building designers.

Building surveyor
Building surveyors are technically minded general practitioners in the United Kingdom, Australia and elsewhere, trained much like architectural technologists. In the UK, the knowledge and expertise of the building surveyor is applied to various tasks in the property and construction markets, including building design for smaller residential and light commercial projects. This aspect of the practice is similar to other European occupations, most notably the geometra in Italy, but also the géomètre in France, Belgium and Switzerland. the building surveyors are also capable on establishment of bills of quantities for the new works and renovation or maintenance or rehabilitation works.[6]

The profession of Building Surveyor does not exist in the US. The title Surveyor refers almost exclusively to Land surveyors. Architects, Building Designers, Residential Designers, Construction Managers, and Home Inspectors perform some or all of the work of the U.K. Building Surveyor.
$
10
Question 1:
A: Who is typically responsible for planning, designing, and supervising the construction of buildings?
B: Building engineer
C: Draftsperson
D: Building designer
E: Architect
Answer: E

Question 2:
A: Which profession is responsible for electrical, mechanical, and structural aspects of building engineering?
B: Building surveyor
C: Draftsperson
D: Architect
E: Building engineer
Answer: E

Question 3:
A: In some regions, individuals who design single-family residential buildings without an architectural license are known as what?
B: Architects
C: Building engineers
D: Building surveyors
E: Building designers
Answer: E

Question 4:
A: What organization administers a program leading to the title of Certified Professional Building Designer (CPBD) in the United States?
B: American Institute of Building Design
C: National Council of Building Designer Certification
D: American Institute of Architects
E: Building Designers Association
Answer: C

Question 5:
A: What term is used for someone who prepares construction documents but does not engage in building design?
B: Architect
C: Building engineer
D: Building surveyor
E: Draftsperson
Answer: E

Question 6:
A: In which country does the title "building surveyor" apply to technically minded general practitioners in property and construction markets?
B: United States
C: Australia
D: Italy
E: France
Answer: C

Question 7:
A: Which occupation in the UK is similar to the role of building surveyors in assessing property and construction projects?
B: Geometra
C: Architect
D: Draftsperson
E: Building engineer
Answer: B

Question 8:
A: In the United States, which title is regulated for those engaged in residential design and remodeling?
B: Architect
C: Building designer
D: Building surveyor
E: Architectural technologist
Answer: C

Question 9:
A: What term is commonly used for those focusing mainly on residential design and remodeling in the United States?
B: Architectural technologist
C: Building engineer
D: Residential designer
E: Building surveyor
Answer: D

Question 10:
A: What is the primary focus of building surveyors in the UK and similar occupations in Europe?
B: Land surveying
C: Building design for large commercial projects
D: Building design for smaller residential and light commercial projects
E: Home inspection
Answer: D
@
A building or edifice is an enclosed structure with a roof and walls, usually standing permanently in one place,[1] such as a house or factory.[1] Buildings come in a variety of sizes, shapes, and functions, and have been adapted throughout history for numerous factors, from building materials available, to weather conditions, land prices, ground conditions, specific uses, prestige, and aesthetic reasons. To better understand the concept, see Nonbuilding structure for contrast.

Buildings serve several societal needs – occupancy, primarily as shelter from weather, security, living space, privacy, to store belongings, and to comfortably live and work. A building as a shelter represents a physical separation of the human habitat (a place of comfort and safety) from the outside (a place that may be harsh and harmful at times).

Ever since the first cave paintings, buildings have been objects or canvasses of much artistic expression. In recent years, interest in sustainable planning and building practices has become an intentional part of the design process of many new buildings and other structures, usually green buildings.

A building is 'a structure that has a roof and walls and stands more or less permanently in one place';[1] "there was a three-storey building on the corner"; "it was an imposing edifice". In the broadest interpretation a fence or wall is a building.[2] However, the word structure is used more broadly than building, to include natural and human-made formations[3] and ones that do not have walls; structure is more often used for a fence. Sturgis' Dictionary included that "[building] differs from architecture in excluding all idea of artistic treatment; and it differs from construction in the idea of excluding scientific or highly skilful treatment."[4]

Structural height in technical usage is the height to the highest architectural detail on the building from street level. Spires and masts may or may not be included in this height, depending on how they are classified. Spires and masts used as antennas are not generally included. The distinction between a low-rise and high-rise building is a matter of debate, but generally three stories or less is considered low-rise.[5]
$
10
Question 1:
A: What is the primary function of a building as described in the text?
B: Aesthetic expression
C: Shelter from weather
D: Artistic canvas
E: Green building practices
Answer: C

Question 2:
A: What does a building provide to its occupants in terms of living space and privacy?
B: Artistic expression
C: Security
D: Aesthetic reasons
E: Green building practices
Answer: C

Question 3:
A: How is structural height measured in technical usage?
B: Height to the highest architectural detail from street level
C: Number of stories in the building
D: Distance from the building to the nearest street
E: Height of spires and masts on the building
Answer: B

Question 4:
A: What is typically considered a low-rise building in terms of stories?
B: Three stories or less
C: Four stories or more
D: Five stories or less
E: Six stories or more
Answer: A

Question 5:
A: What distinguishes a building from a fence or wall according to the text?
B: Building has a roof and walls, while a fence or wall doesn't.
C: Building is more artistic, while a fence or wall is not.
D: Building is taller, while a fence or wall is shorter.
E: Building is structurally complex, while a fence or wall is simple.
Answer: A

Question 6:
A: What aspect of building design has become an intentional part of many new structures?
B: Artistic expression
C: Structural height
D: Sustainable planning and building practices
E: Aesthetic reasons
Answer: D

Question 7:
A: What societal needs do buildings primarily serve, as mentioned in the text?
B: Aesthetic expression and artistic canvas
C: Shelter, security, and living space
D: Structural height and green building practices
E: Privacy and prestige
Answer: C

Question 8:
A: What is the purpose of the distinction between low-rise and high-rise buildings?
B: To classify buildings based on aesthetics
C: To determine architectural details
D: To calculate structural height
E: To categorize buildings by the number of stories
Answer: E

Question 9:
A: What is the text's interpretation of the word "structure" in comparison to "building"?
B: Structure includes natural and human-made formations, while building has walls.
C: Structure is used for fences, while building is used for walls.
D: Structure implies artistic treatment, while building does not.
E: Structure excludes artistic treatment, while building includes it.
Answer: A

Question 10:
A: What is excluded from the measurement of structural height in technical usage?
B: The height to the highest architectural detail
C: The height of spires and masts used as antennas
D: The number of stories in the building
E: The distance from the building to the nearest street
Answer: C
@
In archaeology, cave paintings are a type of parietal art (which category also includes petroglyphs, or engravings), found on the wall or ceilings of caves. The term usually implies prehistoric origin, and the oldest known are more than 40,000 years old (art of the Upper Paleolithic) and found in the caves in the district of Maros (Sulawesi, Indonesia). The oldest are often constructed from hand stencils and simple geometric shapes.[5] More recently, in 2021, cave art of a pig found in Sulawesi, Indonesia, and dated to over 45,500 years ago, has been reported.[6][7]

A 2018 study claimed an age of 64,000 years for the oldest examples of non-figurative cave art in the Iberian Peninsula. Represented by three red non-figurative symbols found in the caves of Maltravieso, Ardales and La Pasiega, Spain, these predate the appearance of modern humans in Europe by at least 20,000 years and thus must have been made by Neanderthals rather than modern humans.[8]

In November 2018, scientists reported the discovery of the then-oldest known figurative art painting, over 40,000 (perhaps as old as 52,000) years old, of an unknown animal, in the cave of Lubang Jeriji Saléh on the Indonesian island of Borneo.[9][10] Nevertheless, in December 2019, cave paintings portraying pig hunting within the Maros-Pangkep karst region in Sulawesi were discovered to be even older, with an estimated age of at least 43,900 years. This remarkable finding was recognized as "the oldest known depiction of storytelling and the earliest instance of figurative art in human history."[11][12]

Dating
Nearly 350 caves have now been discovered in France and Spain that contain art from prehistoric times. Initially, the age of the paintings had been a contentious issue, since methods like radiocarbon dating can produce misleading results if contaminated by other samples,[13] and caves and rocky overhangs (where parietal art is found) are typically littered with debris from many time periods. But subsequent technology has made it possible to date the paintings by sampling the pigment itself, torch marks on the walls,[14] or the formation of carbonate deposits on top of the paintings.[15] The subject matter can also indicate chronology: for instance, the reindeer depicted in the Spanish cave of Cueva de las Monedas places the drawings in the last Ice Age.

The oldest known cave painting is a red hand stencil in Maltravieso cave, Cáceres, Spain. It has been dated using the uranium-thorium method[15] to older than 64,000 years and was made by a Neanderthal.[8] The oldest date given to an animal cave painting is now a depiction of several human figures hunting pigs in the caves in the Maros-Pangkep karst of South Sulawesi, Indonesia, dated to be over 43,900 years old.[12] Before this, the oldest known figurative cave paintings were that of a bull dated to 40,000 years, at Lubang Jeriji Saléh cave, East Kalimantan, Indonesian Borneo,[16] and a depiction of a pig with a minimum age of 35,400 years at Timpuseng cave in Sulawesi.[5]
$
10
Question 1:
A: What are cave paintings typically found on?
B: Tree trunks
C: Cave floors
D: Cave walls or ceilings
E: Cave entrances
Answer: D

Question 2:
A: Where were the oldest known cave paintings found?
B: France
C: Indonesia
D: Spain
E: Australia
Answer: D

Question 3:
A: What is the primary material used in creating the oldest known cave paintings?
B: Oil paints
C: Handprints
D: Uranium
E: Pigments
Answer: E

Question 4:
A: What distinguishes the age of the oldest known cave paintings in Spain and France from previous estimates?
B: Contaminated samples
C: Carbonate deposits on the walls
D: Radiocarbon dating
E: Sampling the pigment itself
Answer: E

Question 5:
A: What subject matter in cave paintings can help indicate their chronology?
B: Human figures hunting pigs
C: Reindeer
D: Abstract symbols
E: Bulls
Answer: C

Question 6:
A: Which method was used to date the oldest known cave painting made by a Neanderthal?
B: Radiocarbon dating
C: Torch marks on the walls
D: Uranium-thorium dating
E: Carbonate deposits on top of the painting
Answer: D

Question 7:
A: What animal is depicted in the oldest known figurative cave painting?
B: Bull
C: Pig
D: Reindeer
E: Human figures
Answer: B

Question 8:
A: Where is the oldest known depiction of storytelling and figurative art in human history found?
B: French caves
C: Spanish caves
D: Indonesian caves
E: Australian caves
Answer: D

Question 9:
A: How was the age of the oldest known cave paintings initially a contentious issue?
B: Due to the presence of torch marks on the walls
C: Because caves and rocky overhangs were typically debris-free
D: Radiocarbon dating could produce misleading results if contaminated
E: The pigment used in the paintings was not suitable for dating
Answer: D

Question 10:
A: What type of art is typically found in caves?
B: Petroglyphs
C: Engravings
D: Parietal art
E: Sculptures
Answer: D
@
Archaeology or archeology[a] is the study of human activity through the recovery and analysis of material culture. The archaeological record consists of artifacts, architecture, biofacts or ecofacts, sites, and cultural landscapes. Archaeology can be considered both a social science and a branch of the humanities.[1][2][3] It is usually considered an independent academic discipline, but may also be classified as part of anthropology (in North America – the four-field approach), history or geography.[4]

Archaeologists study human prehistory and history, from the development of the first stone tools at Lomekwi in East Africa 3.3 million years ago up until recent decades.[5] Archaeology is distinct from palaeontology, which is the study of fossil remains. Archaeology is particularly important for learning about prehistoric societies, for which, by definition, there are no written records. Prehistory includes over 99% of the human past, from the Paleolithic until the advent of literacy in societies around the world.[1] Archaeology has various goals, which range from understanding culture history to reconstructing past lifeways to documenting and explaining changes in human societies through time.[6] Derived from the Greek, the term archaeology literally means "the study of ancient history".[7]

The discipline involves surveying, excavation, and eventually analysis of data collected, to learn more about the past. In broad scope, archaeology relies on cross-disciplinary research.

Archaeology developed out of antiquarianism in Europe during the 19th century, and has since become a discipline practised around the world. Archaeology has been used by nation-states to create particular visions of the past.[8][9] Since its early development, various specific sub-disciplines of archaeology have developed, including maritime archaeology, feminist archaeology, and archaeoastronomy, and numerous different scientific techniques have been developed to aid archaeological investigation. Nonetheless, today, archaeologists face many problems, such as dealing with pseudoarchaeology, the looting of artifacts,[10][11] a lack of public interest, and opposition to the excavation of human remains.
$
10
Question 1:
A: What is the primary focus of archaeology?
B: The study of human language
C: The analysis of current cultures
D: The study of material culture
E: The exploration of outer space
Answer: D

Question 2:
A: What does the archaeological record consist of?
B: Only written records
C: Artifacts and architecture only
D: Biofacts, ecofacts, sites, and cultural landscapes
E: Fossil remains
Answer: D

Question 3:
A: What distinguishes archaeology from palaeontology?
B: Archaeology studies ancient cultures, while palaeontology studies modern societies.
C: Palaeontology focuses on written records, while archaeology relies on oral history.
D: Archaeology examines material culture, while palaeontology studies fossil remains.
E: Palaeontology investigates cultural landscapes, while archaeology analyzes ecofacts.
Answer: D

Question 4:
A: What is one of the goals of archaeology?
B: Predicting future human behavior
C: Studying only modern societies
D: Reconstructing past lifeways
E: Ignoring cultural history
Answer: D

Question 5:
A: What does the term "archaeology" mean in its literal sense?
B: The study of ancient history
C: The exploration of outer space
D: The study of fossil remains
E: The analysis of current cultures
Answer: B

Question 6:
A: What techniques are involved in archaeology?
B: Excavation only
C: Surveying, excavation, and data analysis
D: Only analysis of written records
E: Cross-disciplinary research only
Answer: C

Question 7:
A: When did archaeology develop as a discipline?
B: In the 19th century
C: In the 3.3 million years ago
D: In recent decades
E: In the Paleolithic era
Answer: B

Question 8:
A: What problems do archaeologists face today?
B: Dealing with paleontology
C: A surplus of artifacts
D: Lack of public interest
E: A wealth of written records
Answer: D

Question 9:
A: Which sub-disciplines of archaeology have developed over time?
B: Maritime archaeology, feminist archaeology, and archaeoastronomy
C: Paleontology, anthropology, and sociology
D: Linguistics, geology, and astronomy
E: Architecture, history, and geography
Answer: A

Question 10:
A: What role has archaeology played in nation-states?
B: It has created visions of the future.
C: It has focused solely on modern history.
D: It has promoted pseudoarchaeology.
E: It has been used to shape visions of the past.
Answer: E
@
Prehistory, also called pre-literary history,[1] is the period of human history between the first known use of stone tools by hominins c. 3.3 million years ago and the beginning of recorded history with the invention of writing systems. The use of symbols, marks, and images appears very early among humans, but the earliest known writing systems appeared c. 5,000 years ago. It took thousands of years for writing systems to be widely adopted, with writing spreading to almost all cultures by the 19th century. The end of prehistory therefore came at very different times in different places, and the term is less often used in discussing societies where prehistory ended relatively recently.

In the early Bronze Age, Sumer in Mesopotamia, the Indus Valley Civilisation, and ancient Egypt were the first civilizations to develop their own scripts and to keep historical records, with their neighbours following. Most other civilizations reached the end of prehistory during the following Iron Age. The three-age division of prehistory into Stone Age, Bronze Age, and Iron Age remains in use for much of Eurasia and North Africa, but is not generally used in those parts of the world where the working of hard metals arrived abruptly from contact with Eurasian cultures, such as Oceania, Australasia, much of Sub-Saharan Africa, and parts of the Americas. With some exceptions in pre-Columbian civilizations in the Americas, these areas did not develop complex writing systems before the arrival of Eurasians, so their prehistory reaches into relatively recent periods; for example, 1788 is usually taken as the end of the prehistory of Australia.

The period when a culture is written about by others, but has not developed its own writing system is often known as the protohistory of the culture. By definition,[2] there are no written records from human prehistory, which can only be known from material archaeological and anthropological evidence: prehistoric materials and human remains. These were at first understood by the collection of folklore and by analogy with pre-literate societies observed in modern times. The key step to understanding prehistoric evidence is dating, and reliable dating techniques have developed steadily since the nineteenth century.[3] Further evidence has come from the reconstruction of ancient spoken languages. More recent techniques include forensic chemical analysis to reveal the use and provenance of materials, and genetic analysis of bones to determine kinship and physical characteristics of prehistoric peoples.
$
10
Question 1:
A: What is prehistory?
B: The period before the first known use of stone tools.
C: The period before the invention of writing systems.
D: The period before the end of the Iron Age.
E: The period before recorded history.
Answer: C

Question 2:
A: When did the earliest known writing systems appear?
B: Around 19th century
C: About 5,000 years ago
D: During the Bronze Age
E: Approximately 3.3 million years ago
Answer: C

Question 3:
A: What marked the end of prehistory in different cultures?
B: The invention of writing systems
C: The spread of stone tools
D: The arrival of Eurasian cultures
E: The use of symbols and marks
Answer: B

Question 4:
A: Which civilizations were among the first to develop their own scripts and historical records?
B: Roman Empire and Ancient Greece
C: Sumer, Indus Valley, and ancient Egypt
D: Aztec, Inca, and Mayan
E: Chinese Dynasties
Answer: C

Question 5:
A: What division of prehistory is commonly used in Eurasia and North Africa?
B: Bronze Age, Copper Age, and Iron Age
C: Stone Age, Bronze Age, and Industrial Age
D: Neolithic Age, Paleolithic Age, and Modern Age
E: Stone Age, Bronze Age, and Iron Age
Answer: E

Question 6:
A: In which regions is the three-age division of prehistory not generally used?
B: Europe and Asia
C: Oceania, Australasia, and parts of the Americas
D: Africa and the Middle East
E: South America and Antarctica
Answer: C

Question 7:
A: What is the period when a culture is written about by others but has no writing system called?
B: Prehistory
C: Protohistory
D: Iron Age
E: Modern history
Answer: C

Question 8:
A: How is human prehistory primarily known?
B: Through written records
C: By analyzing ancient fossils
D: From material archaeological and anthropological evidence
E: By studying folklore
Answer: D

Question 9:
A: What is a key step to understanding prehistoric evidence?
B: Collection of folklore
C: Analysis of ancient languages
D: Reliable dating techniques
E: Genetic analysis of bones
Answer: D

Question 10:
A: What techniques have been used to analyze prehistoric evidence?
B: Analysis of ancient languages only
C: Collection of folklore and analogy with modern societies
D: Genetic analysis of modern populations
E: Forensic chemical analysis and genetic analysis of bones
Answer: E
@
The geologic time scale or geological time scale (GTS) is a representation of time based on the rock record of Earth. It is a system of chronological dating that uses chronostratigraphy (the process of relating strata to time) and geochronology (a scientific branch of geology that aims to determine the age of rocks). It is used primarily by Earth scientists (including geologists, paleontologists, geophysicists, geochemists, and paleoclimatologists) to describe the timing and relationships of events in geologic history. The time scale has been developed through the study of rock layers and the observation of their relationships and identifying features such as lithologies, paleomagnetic properties, and fossils. The definition of standardized international units of geologic time is the responsibility of the International Commission on Stratigraphy (ICS), a constituent body of the International Union of Geological Sciences (IUGS), whose primary objective[1] is to precisely define global chronostratigraphic units of the International Chronostratigraphic Chart (ICC)[2] that are used to define divisions of geologic time. The chronostratigraphic divisions are in turn used to define geochronologic units.[2]

While some regional terms are still in use,[3] the table of geologic time presented in this article conforms to the nomenclature, ages, and color codes set forth by the ICS.[1][4]

The geologic time scale is a way of representing deep time based on events that have occurred throughout Earth's history, a time span of about 4.54 ± 0.05 Ga (4.54 billion years).[5] It chronologically organizes strata, and subsequently time, by observing fundamental changes in stratigraphy that correspond to major geological or paleontological events. For example, the Cretaceous–Paleogene extinction event, marks the lower boundary of the Paleogene System/Period and thus the boundary between the Cretaceous and Paleogene Systems/Periods. For divisions prior to the Cryogenian, arbitrary numeric boundary definitions (Global Standard Stratigraphic Ages, GSSAs) are used to divide geologic time. Proposals have been made to better reconcile these divisions with the rock record.[6][3]

Historically, regional geologic time scales were used[3] due to the litho- and biostratigraphic differences around the world in time equivalent rocks. The ICS has long worked to reconcile conflicting terminology by standardizing globally significant and identifiable stratigraphic horizons that can be used to define the lower boundaries of chronostratigraphic units. Defining chronostratigraphic units in such a manner allows for the use of global, standardised nomenclature. The ICC represents this ongoing effort.

The relative relationships of rocks for determining their chronostratigraphic positions use the overriding principles of[citation needed]:

Superposition – Newer rock beds will lie on top of older rock beds unless the succession has been overturned.
Horizontality – All rock layers were originally deposited horizontally.[note 1]
Lateral continuity – Originally deposited layers of rock extend laterally in all directions until either thinning out or being cut off by a different rock layer.
Biologic succession (where applicable) – This states that each stratum in a succession contains a distinctive set of fossils. This allows for a correlation of the stratum even when the horizon between them is not continuous.
Cross-cutting relationships – A rock feature that cuts across another feature must be younger than the rock it cuts across.
Inclusion – Small fragments of one type of rock but embedded in a second type of rock must have formed first, and were included when the second rock was forming.
Relationships of unconformities – Geologic features representing periods of erosion or non-deposition, indicating non-continuous sediment deposition.
$
10
Question 1:
A: What is the geologic time scale primarily used for?
B: Describing the timing and relationships of events in geologic history
C: Calculating the age of Earth's core
D: Identifying the primary colors of rocks
E: Measuring the speed of geological processes
Answer: B

Question 2:
A: Who is responsible for defining standardized international units of geologic time?
B: International Union of Geological Sciences (IUGS)
C: International Commission on Stratigraphy (ICS)
D: International Geological Union (IGU)
E: International Geological Commission (IGC)
Answer: C

Question 3:
A: What is the timespan covered by the geologic time scale?
B: About 1 billion years
C: Approximately 2.5 billion years
D: Roughly 4.54 billion years
E: Around 500 million years
Answer: D

Question 4:
A: What event marks the lower boundary of the Paleogene System/Period?
B: The formation of the Rocky Mountains
C: The Cretaceous–Paleogene extinction event
D: The development of the first dinosaurs
E: The discovery of fossil fuels
Answer: C

Question 5:
A: What principles are used to determine chronostratigraphic positions of rocks?
B: Fossil rarity, lithology, and biostratigraphy
C: Superposition, horizontality, and cross-cutting relationships
D: Rock color, fossil size, and seismic activity
E: Magnetic properties, radioactivity, and density
Answer: C

Question 6:
A: Why were regional geologic time scales historically used?
B: Due to global standardization of terminology
C: Because they accurately represented the entire geological record
D: To account for differences in time equivalent rocks around the world
E: To avoid using standardized nomenclature
Answer: D

Question 7:
A: What is the purpose of defining chronostratigraphic units?
B: To create confusion in geology
C: To standardize globally significant stratigraphic horizons
D: To establish the colors of rock layers
E: To determine the age of the Earth's core
Answer: C

Question 8:
A: What does the term "superposition" mean in the context of the geologic time scale?
B: Older rock beds are generally found on top of newer rock beds.
C: Rock beds are originally deposited at an angle.
D: Younger rock beds always contain fossils.
E: The study of meteorites is essential for geology.
Answer: A

Question 9:
A: What is the significance of cross-cutting relationships in geology?
B: They determine the color of rock layers.
C: They establish the age of the Earth.
D: They show which rock feature is on top.
E: They indicate the speed of geological processes.
Answer: D

Question 10:
A: What do relationships of unconformities in geology represent?
B: Periods of continuous sediment deposition
C: A lack of erosion or non-deposition
D: Non-continuous sediment deposition
E: The uniformity of rock layers
Answer: D
@
The history of Earth concerns the development of planet Earth from its formation to the present day.[1][2] Nearly all branches of natural science have contributed to understanding of the main events of Earth's past, characterized by constant geological change and biological evolution.

The geological time scale (GTS), as defined by international convention,[3] depicts the large spans of time from the beginning of the Earth to the present, and its divisions chronicle some definitive events of Earth history. (In the graphic, Ma means "million years ago".) Earth formed around 4.54 billion years ago, approximately one-third the age of the universe, by accretion from the solar nebula.[4][5][6] Volcanic outgassing probably created the primordial atmosphere and then the ocean, but the early atmosphere contained almost no oxygen. Much of the Earth was molten because of frequent collisions with other bodies which led to extreme volcanism. While the Earth was in its earliest stage (Early Earth), a giant impact collision with a planet-sized body named Theia is thought to have formed the Moon. Over time, the Earth cooled, causing the formation of a solid crust, and allowing liquid water on the surface. In June 2023, scientists reported evidence that the planet Earth may have formed in just three million years, much faster than the 10−100 million years thought earlier.[7][8]

The Hadean eon represents the time before a reliable (fossil) record of life; it began with the formation of the planet and ended 4.0 billion years ago. The following Archean and Proterozoic eons produced the beginnings of life on Earth and its earliest evolution. The succeeding eon is the Phanerozoic, divided into three eras: the Palaeozoic, an era of arthropods, fishes, and the first life on land; the Mesozoic, which spanned the rise, reign, and climactic extinction of the non-avian dinosaurs; and the Cenozoic, which saw the rise of mammals. Recognizable humans emerged at most 2 million years ago, a vanishingly small period on the geological scale.

The earliest undisputed evidence of life on Earth dates at least from 3.5 billion years ago,[9][10][11] during the Eoarchean Era, after a geological crust started to solidify following the earlier molten Hadean Eon. There are microbial mat fossils such as stromatolites found in 3.48 billion-year-old sandstone discovered in Western Australia.[12][13][14] Other early physical evidence of a biogenic substance is graphite in 3.7 billion-year-old metasedimentary rocks discovered in southwestern Greenland[15] as well as "remains of biotic life" found in 4.1 billion-year-old rocks in Western Australia.[16][17] According to one of the researchers, "If life arose relatively quickly on Earth … then it could be common in the universe."[16]

Photosynthetic organisms appeared between 3.2 and 2.4 billion years ago and began enriching the atmosphere with oxygen. Life remained mostly small and microscopic until about 580 million years ago, when complex multicellular life arose, developed over time, and culminated in the Cambrian Explosion about 538.8 million years ago. This sudden diversification of life forms produced most of the major phyla known today, and divided the Proterozoic Eon from the Cambrian Period of the Paleozoic Era. It is estimated that 99 percent of all species that ever lived on Earth, over five billion,[18] have gone extinct.[19][20] Estimates on the number of Earth's current species range from 10 million to 14 million,[21] of which about 1.2 million are documented, but over 86 percent have not been described.[22] However, it was recently claimed that 1 trillion species currently live on Earth, with only one-thousandth of one percent described.[23]

The Earth's crust has constantly changed since its formation, as has life since its first appearance. Species continue to evolve, taking on new forms, splitting into daughter species, or going extinct in the face of ever-changing physical environments. The process of plate tectonics continues to shape the Earth's continents and oceans and the life they harbor.
$
10
Question 1:
A: What marks the beginning of Earth's formation?
B: The emergence of multicellular life
C: Volcanic outgassing
D: The rise of mammals
E: Plate tectonics
Answer: C

Question 2:
A: What eon represents the time before a reliable fossil record of life?
B: Proterozoic
C: Phanerozoic
D: Hadean
E: Mesozoic
Answer: D

Question 3:
A: When did photosynthetic organisms first appear on Earth?
B: 580 million years ago
C: 2.4 billion years ago
D: During the Cambrian Explosion
E: 4.54 billion years ago
Answer: B

Question 4:
A: What is the estimated percentage of species that have gone extinct on Earth?
B: 10 percent
C: 50 percent
D: 99 percent
E: 25 percent
Answer: D

Question 5:
A: When did complex multicellular life arise on Earth?
B: During the Hadean eon
C: After the Cambrian Explosion
D: Between 3.2 and 2.4 billion years ago
E: In the Eoarchean Era
Answer: C

Question 6:
A: What evidence of life on Earth dates back at least 3.5 billion years?
B: Stromatolites
C: Plate tectonics
D: Photosynthetic organisms
E: Cambrian Explosion
Answer: A

Question 7:
A: When did recognizable humans first emerge?
B: During the Palaeozoic era
C: About 2 million years ago
D: During the Hadean eon
E: After the Cambrian Explosion
Answer: C

Question 8:
A: What is the estimated number of Earth's current species?
B: 10 million
C: 14 million
D: 1.2 million
E: 1 trillion
Answer: B

Question 9:
A: What geological event is responsible for shaping the Earth's continents and oceans?
B: Cambrian Explosion
C: Plate tectonics
D: Hadean eon
E: Rise of mammals
Answer: C

Question 10:
A: What process has constantly changed Earth's crust since its formation?
B: Evolution of species
C: Cambrian Explosion
D: Multicellular life
E: Volcanic outgassing
Answer: B
@
Photosynthesis (/ˌfoʊtəˈsɪnθəsɪs/ FOH-tə-SINTH-ə-sis)[1] is a biological process used by many cellular organisms to convert light energy into chemical energy, which is stored in organic compounds that can later be metabolized through cellular respiration to fuel the organism's activities. The term usually refers to oxygenic photosynthesis, where oxygen is produced as a byproduct, and some of the chemical energy produced is stored in carbohydrate molecules such as sugars, starch and cellulose, which are synthesized from endergonic reaction of carbon dioxide with water. Most plants, algae and cyanobacteria perform photosynthesis; such organisms are called photoautotrophs. Photosynthesis is largely responsible for producing and maintaining the oxygen content of the Earth's atmosphere, and supplies most of the biological energy necessary for complex life on Earth.[2]

Some bacteria also perform anoxygenic photosynthesis, which use bacteriochlorophyll to split hydrogen sulfide as a reductant instead of water, and sulfur is produced as a byproduct instead of oxygen. Archaea such as Halobacterium also perform a type of non-carbon-fixing anoxygenic photosynthesis, where the simpler photopigment retinal and its microbial rhodopsin derivatives are used to absorb green light and power proton pumps to directly synthesize adenosine triphosphate (ATP). Such archaeal photosynthesis might have been the earliest form of photosynthesis evolved on Earth, going back as far as the Paleoarchean, preceding that of cyanobacteria (see Purple Earth hypothesis).

Although photosynthesis is performed differently by different species, the process always begins when energy from light is absorbed by proteins called reaction centers that contain photosynthetic pigments or chromophores. In plants, these proteins are chlorophyll (a porphyrin derivative that absorbs the red and blue spectrums of light, thus reflecting a green color) held inside organelles called chloroplasts, which are most abundant in leaf cells, while in bacteria they are embedded in the plasma membrane. In these light-dependent reactions, some energy is used to strip electrons from suitable substances, such as water, producing oxygen gas. The hydrogen freed by the splitting of water is used in the creation of two further compounds that serve as short-term stores of energy, enabling its transfer to drive other reactions: these compounds are reduced nicotinamide adenine dinucleotide phosphate (NADPH) and adenosine triphosphate (ATP), the "energy currency" of cells.

In plants, algae and cyanobacteria, sugars are synthesized by a subsequent sequence of light-independent reactions called the Calvin cycle. In the Calvin cycle, atmospheric carbon dioxide is incorporated into already existing organic carbon compounds, such as ribulose bisphosphate (RuBP).[3] Using the ATP and NADPH produced by the light-dependent reactions, the resulting compounds are then reduced and removed to form further carbohydrates, such as glucose. In other bacteria, different mechanisms such as the reverse Krebs cycle are used to achieve the same end.

The first photosynthetic organisms probably evolved early in the evolutionary history of life and most likely used reducing agents such as hydrogen or hydrogen sulfide, rather than water, as sources of electrons.[4] Cyanobacteria appeared later; the excess oxygen they produced contributed directly to the oxygenation of the Earth,[5] which rendered the evolution of complex life possible. Today, the average rate of energy capture by photosynthesis globally is approximately 130 terawatts,[6][7][8] which is about eight times the current power consumption of human civilization.[9] Photosynthetic organisms also convert around 100–115 billion tons (91–104 Pg petagrams, or billion metric tons), of carbon into biomass per year.[10][11] That plants receive some energy from light – in addition to air, soil, and water – was first discovered in 1779 by Jan Ingenhousz.

Photosynthesis is vital for climate processes, as it captures carbon dioxide from the air and then binds carbon in plants and further in soils and harvested products. Cereals alone are estimated to bind 3,825 Tg (teragrams) or 3.825 Pg (petagrams) of carbon dioxide every year, i.e. 3.825 billion metric tons.[12]
$
10
Question 1:
A: What is the primary byproduct of oxygenic photosynthesis?
B: Carbon dioxide
C: Sulfur
D: Hydrogen sulfide
E: Oxygen
Answer: E

Question 2:
A: Which organisms are referred to as photoautotrophs?
B: Bacteria performing anoxygenic photosynthesis
C: Plants, algae, and cyanobacteria
D: Archaea using retinal photopigments
E: Organisms using hydrogen sulfide as a reductant
Answer: C

Question 3:
A: What process captures carbon dioxide from the air?
B: Cellular respiration
C: Photosynthesis
D: Oxidative phosphorylation
E: Hydrogen sulfide splitting
Answer: C

Question 4:
A: What are the two compounds that serve as short-term stores of energy in photosynthesis?
B: ATP and NADPH
C: Ribulose bisphosphate and glucose
D: Retinal and rhodopsin
E: Sulfur and carbon dioxide
Answer: A

Question 5:
A: What pigment absorbs the red and blue spectrums of light in plants?
B: Chlorophyll
C: Porphyrin
D: Ribulose bisphosphate
E: Retinal
Answer: B

Question 6:
A: What process binds carbon in plants and further in soils and harvested products?
B: Cellular respiration
C: Hydrogen sulfide splitting
D: Photosynthesis
E: Oxidative phosphorylation
Answer: D

Question 7:
A: Which organisms probably evolved early in the history of life and used hydrogen or hydrogen sulfide as sources of electrons?
B: Cyanobacteria
C: Plants
D: Archaea
E: Bacteria performing anoxygenic photosynthesis
Answer: E

Question 8:
A: What is the approximate global rate of energy capture by photosynthesis?
B: 13 terawatts
C: 130 terawatts
D: 1.3 terawatts
E: 8 terawatts
Answer: C

Question 9:
A: Who first discovered that plants receive some energy from light?
B: Jan Ingenhousz
C: Photosynthetic organisms
D: Cyanobacteria
E: Archaea
Answer: B

Question 10:
A: Which organisms use retinal and microbial rhodopsin derivatives to absorb green light and synthesize ATP?
B: Plants
C: Cyanobacteria
D: Archaea
E: Bacteria performing anoxygenic photosynthesis
Answer: D
@
Cellular respiration is the process by which biological fuels are oxidised in the presence of an inorganic electron acceptor, such as oxygen, to drive the bulk production of adenosine triphosphate (ATP), which contains energy. Cellular respiration may be described as a set of metabolic reactions and processes that take place in the cells of organisms to convert chemical energy from nutrients into ATP, and then release waste products.[1]

The reactions involved in respiration are catabolic reactions, which break large molecules into smaller ones, producing large amounts of energy (ATP). Respiration is one of the key ways a cell releases chemical energy to fuel cellular activity. The overall reaction occurs in a series of biochemical steps, some of which are redox reactions. Although cellular respiration is technically a combustion reaction, it is an unusual one because of the slow, controlled release of energy from the series of reactions.

Nutrients that are commonly used by animal and plant cells in respiration include sugar, amino acids and fatty acids, and the most common oxidizing agent is molecular oxygen (O2). The chemical energy stored in ATP (the bond of its third phosphate group to the rest of the molecule can be broken allowing more stable products to form, thereby releasing energy for use by the cell) can then be used to drive processes requiring energy, including biosynthesis, locomotion or transportation of molecules across cell membranes.
$
10
Question 1:
A: What is the primary purpose of cellular respiration?
B: To produce nutrients
C: To break down ATP
D: To convert chemical energy into ATP
E: To store chemical energy
Answer: D

Question 2:
A: Which type of reactions are involved in cellular respiration?
B: Anabolic reactions
C: Catabolic reactions
D: Redox reactions
E: Combustion reactions
Answer: C

Question 3:
A: What is the oxidizing agent commonly used in cellular respiration?
B: Fatty acids
C: Amino acids
D: Sugar
E: Molecular oxygen (O2)
Answer: E

Question 4:
A: What is the primary waste product of cellular respiration?
B: ATP
C: Oxygen (O2)
D: Nutrients
E: Carbon dioxide (CO2)
Answer: E

Question 5:
A: What is the role of ATP in cellular respiration?
B: To store energy
C: To transport molecules across cell membranes
D: To break down nutrients
E: To release energy for cellular processes
Answer: E

Question 6:
A: What is the main purpose of catabolic reactions in cellular respiration?
B: To build large molecules from smaller ones
C: To release energy by breaking down large molecules
D: To produce oxygen (O2)
E: To store ATP
Answer: C

Question 7:
A: Which molecules are commonly used by cells in cellular respiration?
B: Oxygen (O2) and carbon dioxide (CO2)
C: Glucose and water
D: Sugar, amino acids, and fatty acids
E: Proteins and lipids
Answer: D

Question 8:
A: What type of reaction is cellular respiration considered?
B: An unusual combustion reaction
C: Anabolic reaction
D: An exothermic reaction
E: A rapid combustion reaction
Answer: A

Question 9:
A: What is the ultimate purpose of releasing energy in cellular respiration?
B: To fuel cellular activity
C: To produce more ATP
D: To store energy as nutrients
E: To convert ATP into oxygen (O2)
Answer: A

Question 10:
A: Which of the following is NOT a common nutrient used in cellular respiration?
B: Sugar
C: Oxygen (O2)
D: Amino acids
E: Fatty acids
Answer: C
@
Oxygen is the chemical element with the symbol O and atomic number 8. It is a member of the chalcogen group in the periodic table, a highly reactive nonmetal, and an oxidizing agent that readily forms oxides with most elements as well as with other compounds. Oxygen is Earth's most abundant element, and after hydrogen and helium, it is the third-most abundant element in the universe. At standard temperature and pressure, two atoms of the element bind to form dioxygen, a colorless and odorless diatomic gas with the formula O
2. Diatomic oxygen gas currently constitutes 20.95% of the Earth's atmosphere, though this has changed considerably over long periods of time. Oxygen makes up almost half of the Earth's crust in the form of oxides.[3]

All plants, animals, and fungi need oxygen for cellular respiration, which extracts energy by the reaction of oxygen with molecules derived from food and produces carbon dioxide as a waste product. In tetrapods breathing brings oxygen into the lungs where gas exchange takes place, carbon dioxide diffuses out of the blood, and oxygen diffuses into the blood. The body's circulatory system transports the oxygen to the cells, where cellular respiration takes place.[4][5]

Many major classes of organic molecules in living organisms contain oxygen atoms, such as proteins, nucleic acids, carbohydrates, and fats, as do the major constituent inorganic compounds of animal shells, teeth, and bone. Most of the mass of living organisms is oxygen as a component of water, the major constituent of lifeforms. Oxygen is continuously replenished in Earth's atmosphere by photosynthesis, which uses the energy of sunlight to produce oxygen from water and carbon dioxide. Oxygen is too chemically reactive to remain a free element in air without being continuously replenished by the photosynthetic action of living organisms. Another form (allotrope) of oxygen, ozone (O
3), strongly absorbs ultraviolet UVB radiation and the high-altitude ozone layer helps protect the biosphere from ultraviolet radiation. However, ozone present at the surface is a byproduct of smog and thus a pollutant.

Oxygen was isolated by Michael Sendivogius before 1604, but it is commonly believed that the element was discovered independently by Carl Wilhelm Scheele, in Uppsala, in 1773 or earlier, and Joseph Priestley in Wiltshire, in 1774. Priority is often given for Priestley because his work was published first. Priestley, however, called oxygen "dephlogisticated air", and did not recognize it as a chemical element. The name oxygen was coined in 1777 by Antoine Lavoisier, who first recognized oxygen as a chemical element and correctly characterized the role it plays in combustion.

Common uses of oxygen include production of steel, plastics and textiles, brazing, welding and cutting of steels and other metals, rocket propellant, oxygen therapy, and life support systems in aircraft, submarines, spaceflight and diving.
$
10
Question: What is the chemical symbol for oxygen?
A: O
B: H
C: C
D: He
E: N
Answer: A

Question: In the periodic table, which group does oxygen belong to?
A: Noble gases
B: Alkali metals
C: Halogens
D: Chalcogens
E: Transition metals
Answer: D

Question: What is the most abundant element in the Earth's atmosphere after hydrogen and helium?
A: Nitrogen
B: Carbon
C: Oxygen
D: Helium
E: Hydrogen
Answer: C

Question: What is the chemical formula for diatomic oxygen gas?
A: O
B: O3
C: H2O
D: CO2
E: O2
Answer: E

Question: What percentage of the Earth's atmosphere is currently composed of diatomic oxygen gas?
A: 10.05%
B: 20.95%
C: 50.00%
D: 75.45%
E: 90.10%
Answer: B

Question: Which process extracts energy by the reaction of oxygen with molecules derived from food?
A: Photosynthesis
B: Combustion
C: Respiration
D: Digestion
E: Fermentation
Answer: C

Question: What is the primary role of the body's circulatory system in relation to oxygen?
A: Transporting carbon dioxide to the cells
B: Transporting oxygen out of the lungs
C: Transporting oxygen to the cells
D: Producing oxygen from water and carbon dioxide
E: Transporting oxygen to the atmosphere
Answer: C

Question: Which major classes of organic molecules in living organisms contain oxygen atoms?
A: Lipids and sugars
B: Proteins and nucleic acids
C: Carbohydrates and fats
D: Amino acids and vitamins
E: Minerals and water
Answer: C

Question: What is the major constituent of lifeforms that contains oxygen as a component?
A: Carbon
B: Water
C: Nitrogen
D: Calcium
E: Phosphorus
Answer: B

Question: Which scientist first recognized oxygen as a chemical element and coined the name "oxygen"?
A: Michael Sendivogius
B: Carl Wilhelm Scheele
C: Joseph Priestley
D: Antoine Lavoisier
E: Michael Faraday
Answer: D
@
A fungus (pl: fungi[2] or funguses[3]) is any member of the group of eukaryotic organisms that includes microorganisms such as yeasts and molds, as well as the more familiar mushrooms. These organisms are classified as a kingdom,[4] separately from the other eukaryotic kingdoms, which, by one traditional classification, includes Plantae, Animalia, Protozoa, and Chromista.

A characteristic that places fungi in a different kingdom from plants, bacteria, and some protists is chitin in their cell walls. Fungi, like animals, are heterotrophs; they acquire their food by absorbing dissolved molecules, typically by secreting digestive enzymes into their environment. Fungi do not photosynthesize. Growth is their means of mobility, except for spores (a few of which are flagellated), which may travel through the air or water. Fungi are the principal decomposers in ecological systems. These and other differences place fungi in a single group of related organisms, named the Eumycota (true fungi or Eumycetes), that share a common ancestor (i.e. they form a monophyletic group), an interpretation that is also strongly supported by molecular phylogenetics. This fungal group is distinct from the structurally similar myxomycetes (slime molds) and oomycetes (water molds). The discipline of biology devoted to the study of fungi is known as mycology (from the Greek μύκης mykes, mushroom). In the past mycology was regarded as a branch of botany, although it is now known that fungi are genetically more closely related to animals than to plants.

Abundant worldwide, most fungi are inconspicuous because of the small size of their structures, and their cryptic lifestyles in soil or on dead matter. Fungi include symbionts of plants, animals, or other fungi and also parasites. They may become noticeable when fruiting, either as mushrooms or as molds. Fungi perform an essential role in the decomposition of organic matter and have fundamental roles in nutrient cycling and exchange in the environment. They have long been used as a direct source of human food, in the form of mushrooms and truffles; as a leavening agent for bread; and in the fermentation of various food products, such as wine, beer, and soy sauce. Since the 1940s, fungi have been used for the production of antibiotics, and, more recently, various enzymes produced by fungi are used industrially and in detergents. Fungi are also used as biological pesticides to control weeds, plant diseases, and insect pests. Many species produce bioactive compounds called mycotoxins, such as alkaloids and polyketides, that are toxic to animals, including humans. The fruiting structures of a few species contain psychotropic compounds and are consumed recreationally or in traditional spiritual ceremonies. Fungi can break down manufactured materials and buildings, and become significant pathogens of humans and other animals. Losses of crops due to fungal diseases (e.g., rice blast disease) or food spoilage can have a large impact on human food supplies and local economies.

The fungus kingdom encompasses an enormous diversity of taxa with varied ecologies, life cycle strategies, and morphologies ranging from unicellular aquatic chytrids to large mushrooms. However, little is known of the true biodiversity of the fungus kingdom, which has been estimated at 2.2 million to 3.8 million species.[5] Of these, only about 148,000 have been described,[6] with over 8,000 species known to be detrimental to plants and at least 300 that can be pathogenic to humans.[7] Ever since the pioneering 18th and 19th century taxonomical works of Carl Linnaeus, Christiaan Hendrik Persoon, and Elias Magnus Fries, fungi have been classified according to their morphology (e.g., characteristics such as spore color or microscopic features) or physiology. Advances in molecular genetics have opened the way for DNA analysis to be incorporated into taxonomy, which has sometimes challenged the historical groupings based on morphology and other traits. Phylogenetic studies published in the first decade of the 21st century have helped reshape the classification within the fungi kingdom, which is divided into one subkingdom, seven phyla, and ten subphyla.
$
10
Question: What is the primary characteristic that distinguishes fungi from plants, bacteria, and some protists?
A: Chitin in their cell walls
B: Photosynthesis
C: Mobility through flagellated spores
D: Heterotrophic nutrition
E: Molecular phylogenetics
Answer: A

Question: Which kingdom includes fungi as one of its members?
A: Animalia
B: Plantae
C: Protozoa
D: Chromista
E: Fungi
Answer: E

Question: What is the discipline of biology devoted to the study of fungi called?
A: Botany
B: Zoology
C: Mycology
D: Myxomycology
E: Oomycology
Answer: C

Question: What is the principal role of fungi in ecological systems?
A: Photosynthesis
B: Predation
C: Decomposition
D: Mutualism
E: Parasitism
Answer: C

Question: Which group of related organisms shares a common ancestor and is distinct from myxomycetes and oomycetes?
A: Myxomycota
B: Oomycota
C: Eumycota
D: Protozoa
E: Chromista
Answer: C

Question: What is the estimated number of species within the fungus kingdom?
A: 2,000 to 3,000 species
B: 5,000 to 6,000 species
C: 100,000 to 200,000 species
D: 2.2 million to 3.8 million species
E: 8,000 to 10,000 species
Answer: D

Question: How many species within the fungus kingdom have been described?
A: 50,000 species
B: 100,000 species
C: 148,000 species
D: 200,000 species
E: 300,000 species
Answer: C

Question: Which kingdom is genetically more closely related to fungi than to plants?
A: Plantae
B: Animalia
C: Protozoa
D: Chromista
E: None of the above
Answer: B

Question: What do fungi use to acquire their food?
A: Photosynthesis
B: Digestive enzymes
C: Predation
D: Absorption of sunlight
E: Respiratory pigments
Answer: B

Question: What role do fungi play in the fermentation of various food products such as wine, beer, and soy sauce?
A: Predators
B: Decomposers
C: Producers
D: Leavening agents
E: Photosynthesizers
Answer: D
@
A cell wall is a structural layer surrounding some types of cells, just outside the cell membrane. It can be tough, flexible, and sometimes rigid. It provides the cell with both structural support and protection, and also acts as a filtering mechanism.[1] Cell walls are absent in many eukaryotes, including animals, but are present in some other ones like fungi, algae and plants, and in most prokaryotes (except mollicute bacteria). A major function is to act as pressure vessels, preventing over-expansion of the cell when water enters.

The composition of cell walls varies between taxonomic group and species and may depend on cell type and developmental stage. The primary cell wall of land plants is composed of the polysaccharides cellulose, hemicelluloses and pectin. Often, other polymers such as lignin, suberin or cutin are anchored to or embedded in plant cell walls. Algae possess cell walls made of glycoproteins and polysaccharides such as carrageenan and agar that are absent from land plants. In bacteria, the cell wall is composed of peptidoglycan. The cell walls of archaea have various compositions, and may be formed of glycoprotein S-layers, pseudopeptidoglycan, or polysaccharides. Fungi possess cell walls made of the N-acetylglucosamine polymer chitin. Unusually, diatoms have a cell wall composed of biogenic silica.[2]

A plant cell wall was first observed and named (simply as a "wall") by Robert Hooke in 1665.[3] However, "the dead excrusion product of the living protoplast" was forgotten, for almost three centuries, being the subject of scientific interest mainly as a resource for industrial processing or in relation to animal or human health.[4]

In 1804, Karl Rudolphi and J.H.F. Link proved that cells had independent cell walls.[5][6] Before, it had been thought that cells shared walls and that fluid passed between them this way.

The mode of formation of the cell wall was controversial in the 19th century. Hugo von Mohl (1853, 1858) advocated the idea that the cell wall grows by apposition. Carl Nägeli (1858, 1862, 1863) believed that the growth of the wall in thickness and in area was due to a process termed intussusception. Each theory was improved in the following decades: the apposition (or lamination) theory by Eduard Strasburger (1882, 1889), and the intussusception theory by Julius Wiesner (1886).[7]

In 1930, Ernst Münch coined the term apoplast in order to separate the "living" symplast from the "dead" plant region, the latter of which included the cell wall.[8]

By the 1980s, some authors suggested replacing the term "cell wall", particularly as it was used for plants, with the more precise term "extracellular matrix", as used for animal cells,[9][4]: 168  but others preferred the older term.[10]
$
10
Question: What is the primary function of a cell wall in organisms that possess it?
A: Energy production
B: Cellular respiration
C: Structural support and protection
D: Oxygen transport
E: DNA replication
Answer: C

Question: Which organisms are among those that possess cell walls?
A: Animals
B: Bacteria
C: Fungi
D: Protozoa
E: Algae
Answer: C and E

Question: What is the primary component of the primary cell wall in land plants?
A: Lignin
B: Peptidoglycan
C: Chitin
D: Cellulose
E: Agar
Answer: D

Question: Who first observed and named the plant cell wall in 1665?
A: Karl Rudolphi
B: J.H.F. Link
C: Hugo von Mohl
D: Carl Nägeli
E: Robert Hooke
Answer: E

Question: What did Karl Rudolphi and J.H.F. Link prove in 1804 about cells and their walls?
A: Cells have shared walls.
B: Cells have no walls.
C: Cells have independent cell walls.
D: Cells have fluid-filled walls.
E: Cells have symplastic walls.
Answer: C

Question: Which scientist believed that the growth of the cell wall occurs by apposition?
A: Eduard Strasburger
B: Julius Wiesner
C: Carl Nägeli
D: Hugo von Mohl
E: Ernst Münch
Answer: A

Question: What term was coined by Ernst Münch in 1930 to separate the "living" symplast from the "dead" plant region?
A: Apoplast
B: Extracellular matrix
C: Intussusception
D: Polysaccharide
E: Glycoprotein
Answer: A

Question: In the 1980s, some authors suggested replacing the term "cell wall" with what more precise term for plants?
A: Plasma membrane
B: Cytoplasm
C: Extracellular matrix
D: Lipid bilayer
E: Apoplast
Answer: C

Question: Which of the following is NOT a component of the primary cell wall in land plants?
A: Cellulose
B: Lignin
C: Hemicelluloses
D: Pectin
E: Suberin
Answer: E

Question: What is the composition of the cell wall in bacteria?
A: Cellulose
B: Chitin
C: Glycoprotein S-layers
D: Peptidoglycan
E: Biogenic silica
Answer: D
@
The eukaryotes (/juːˈkærioʊts, -əts/) constitute the domain of Eukaryota, organisms whose cells have a nucleus. All animals, plants, fungi, and many unicellular organisms are eukaryotes. They constitute a major group of life forms alongside the two groups of prokaryotes: the Bacteria and the Archaea. Eukaryotes represent a small minority of the number of organisms, but due to their generally much larger size, their collective global biomass is much larger than that of prokaryotes.

The eukaryotes seemingly emerged in the Archaea, within the Asgard archaea. This implies that there are only two domains of life, Bacteria and Archaea, with eukaryotes incorporated among the Archaea. Eukaryotes emerged approximately 2.2 billion years ago, during the Proterozoic eon, likely as flagellated cells. These were created by symbiogenesis between an anaerobic Asgard archaean and an aerobic proteobacterium, which formed the mitochondria. A second episode of symbiogenesis with a cyanobacterium created the plants, with chloroplasts. The oldest-known eukaryote fossils, multicellular planktonic organisms belonging to the Gabonionta, were discovered in Gabon in 2023, dating back to 2.1 billion years ago.

Eukaryotic cells contain membrane-bound organelles such as the nucleus, the endoplasmic reticulum, and the Golgi apparatus. Eukaryotes may be either unicellular or multicellular. In comparison, prokaryotes are typically unicellular. Unicellular eukaryotes are sometimes called protists. Eukaryotes can reproduce both asexually through mitosis and sexually through meiosis and gamete fusion (fertilisation).

Nucleus
The defining feature of eukaryotes is that their cells have nuclei. This gives them their name, from the Greek εὖ (eu, "well" or "good") and κάρυον (karyon, "nut" or "kernel", here meaning "nucleus").[17] Eukaryotic cells have a variety of internal membrane-bound structures, called organelles, and a cytoskeleton which defines the cell's organization and shape. The nucleus stores the cell's DNA, which is divided into linear bundles called chromosomes;[18] these are separated into two matching sets by a microtubular spindle during nuclear division, in the distinctively eukaryotic process of mitosis.[19]

Biochemistry
Eukaryotes differ from prokaryotes in multiple ways, with unique biochemical pathways such as sterane synthesis.[20] The eukaryotic signature proteins have no homology to proteins in other domains of life, but appear to be universal among eukaryotes. They include the proteins of the cytoskeleton, the complex transcription machinery, the membrane-sorting systems, the nuclear pore, and some enzymes in the biochemical pathways.[21]
$
10
Question: What is the defining feature of eukaryotic cells?
A: Membrane-bound organelles
B: Prokaryotic signature proteins
C: Nucleus
D: Cytoplasm
E: Linear bundles called chromosomes
Answer: C

Question: Eukaryotes emerged through symbiogenesis involving an anaerobic Asgard archaean and which other microorganism?
A: Cyanobacterium
B: Proteobacterium
C: Bacteriophage
D: Mycoplasma
E: Archaea
Answer: B

Question: What is the term for unicellular eukaryotes?
A: Plants
B: Animals
C: Protists
D: Fungi
E: Bacteria
Answer: C

Question: What gives eukaryotes their name, which is derived from Greek words?
A: Cell membrane
B: Mitochondria
C: Nucleus
D: Cytoskeleton
E: Organelles
Answer: C

Question: In eukaryotic cells, where is the cell's DNA primarily stored?
A: Mitochondria
B: Cytoskeleton
C: Nucleus
D: Golgi apparatus
E: Endoplasmic reticulum
Answer: C

Question: What is the collective global biomass of eukaryotes compared to prokaryotes?
A: Much smaller
B: Slightly smaller
C: About the same
D: Slightly larger
E: Much larger
Answer: E

Question: Which eon did eukaryotes emerge during, approximately 2.2 billion years ago?
A: Hadean eon
B: Archean eon
C: Proterozoic eon
D: Paleozoic eon
E: Mesozoic eon
Answer: C

Question: What process allows eukaryotes to reproduce sexually?
A: Meiosis
B: Mitosis
C: Symbiogenesis
D: Fertilization
E: Gamete fusion
Answer: A

Question: What is the term for the oldest-known eukaryote fossils discovered in Gabon in 2023?
A: Prokaryota
B: Archaea
C: Gabonionta
D: Protists
E: Asgard archaea
Answer: C

Question: Which unique biochemical pathway is mentioned as a difference between eukaryotes and prokaryotes?
A: Sterane synthesis
B: Glycolysis
C: Krebs cycle
D: Photosynthesis
E: Fermentation
Answer: A
@
The cell nucleus (from Latin nucleus or nuculeus 'kernel, seed'; pl: nuclei) is a membrane-bound organelle found in eukaryotic cells. Eukaryotic cells usually have a single nucleus, but a few cell types, such as mammalian red blood cells, have no nuclei, and a few others including osteoclasts have many. The main structures making up the nucleus are the nuclear envelope, a double membrane that encloses the entire organelle and isolates its contents from the cellular cytoplasm; and the nuclear matrix, a network within the nucleus that adds mechanical support.

The cell nucleus contains nearly all of the cell's genome. Nuclear DNA is often organized into multiple chromosomes – long strands of DNA dotted with various proteins, such as histones, that protect and organize the DNA. The genes within these chromosomes are structured in such a way to promote cell function. The nucleus maintains the integrity of genes and controls the activities of the cell by regulating gene expression.

Because the nuclear envelope is impermeable to large molecules, nuclear pores are required to regulate nuclear transport of molecules across the envelope. The pores cross both nuclear membranes, providing a channel through which larger molecules must be actively transported by carrier proteins while allowing free movement of small molecules and ions. Movement of large molecules such as proteins and RNA through the pores is required for both gene expression and the maintenance of chromosomes. Although the interior of the nucleus does not contain any membrane-bound subcompartments, a number of nuclear bodies exist, made up of unique proteins, RNA molecules, and particular parts of the chromosomes. The best-known of these is the nucleolus, involved in the assembly of ribosomes.
$
10
Question: Which organelle is described as being membrane-bound and found in eukaryotic cells?
A: Golgi apparatus
B: Mitochondria
C: Endoplasmic reticulum
D: Cell nucleus
E: Lysosome
Answer: D

Question: What is the main function of the nuclear envelope in the cell nucleus?
A: Regulating gene expression
B: Providing mechanical support
C: Synthesizing proteins
D: Facilitating cell division
E: Storing genetic information
Answer: B

Question: What is the network within the nucleus that provides mechanical support called?
A: Nuclear envelope
B: Nuclear matrix
C: Nucleolus
D: Histones
E: Nuclear pores
Answer: B

Question: What is the term for the long strands of DNA dotted with various proteins, such as histones?
A: Nuclear pores
B: Nuclear envelope
C: Chromosomes
D: Nuclear matrix
E: Nucleolus
Answer: C

Question: How is the integrity of genes maintained in the cell nucleus?
A: By the nuclear matrix
B: By the nucleolus
C: By histone proteins
D: By the nuclear envelope
E: By nuclear pores
Answer: C

Question: What is the function of nuclear pores in the cell nucleus?
A: Synthesizing proteins
B: Regulating gene expression
C: Providing mechanical support
D: Facilitating the movement of molecules
E: Storing genetic information
Answer: D

Question: Which organelle is involved in the assembly of ribosomes and is mentioned in the subject text?
A: Mitochondria
B: Endoplasmic reticulum
C: Lysosome
D: Nucleolus
E: Golgi apparatus
Answer: D

Question: In which part of the cell nucleus are nuclear bodies made up of unique proteins, RNA molecules, and particular parts of the chromosomes found?
A: Nuclear envelope
B: Nuclear matrix
C: Nucleolus
D: Histones
E: Nucleus interior
Answer: E

Question: What is the term for the strands of DNA dotted with various proteins found within the cell nucleus?
A: Nuclear pores
B: Nuclear envelope
C: Chromosomes
D: Nuclear matrix
E: Nucleolus
Answer: C

Question: Which type of cells, described in the subject text, have no nuclei?
A: Osteoclasts
B: Red blood cells
C: Neurons
D: Muscle cells
E: Skin cells
Answer: B
@
Deoxyribonucleic acid (/diːˈɒksɪˌraɪboʊnjuːˌkliːɪk, -ˌkleɪ-/ i;[1] DNA) is a polymer composed of two polynucleotide chains that coil around each other to form a double helix. The polymer carries genetic instructions for the development, functioning, growth and reproduction of all known organisms and many viruses. DNA and ribonucleic acid (RNA) are nucleic acids. Alongside proteins, lipids and complex carbohydrates (polysaccharides), nucleic acids are one of the four major types of macromolecules that are essential for all known forms of life.

The two DNA strands are known as polynucleotides as they are composed of simpler monomeric units called nucleotides.[2][3] Each nucleotide is composed of one of four nitrogen-containing nucleobases (cytosine [C], guanine [G], adenine [A] or thymine [T]), a sugar called deoxyribose, and a phosphate group. The nucleotides are joined to one another in a chain by covalent bonds (known as the phosphodiester linkage) between the sugar of one nucleotide and the phosphate of the next, resulting in an alternating sugar-phosphate backbone. The nitrogenous bases of the two separate polynucleotide strands are bound together, according to base pairing rules (A with T and C with G), with hydrogen bonds to make double-stranded DNA. The complementary nitrogenous bases are divided into two groups, pyrimidines and purines. In DNA, the pyrimidines are thymine and cytosine; the purines are adenine and guanine.

Both strands of double-stranded DNA store the same biological information. This information is replicated when the two strands separate. A large part of DNA (more than 98% for humans) is non-coding, meaning that these sections do not serve as patterns for protein sequences. The two strands of DNA run in opposite directions to each other and are thus antiparallel. Attached to each sugar is one of four types of nucleobases (or bases). It is the sequence of these four nucleobases along the backbone that encodes genetic information. RNA strands are created using DNA strands as a template in a process called transcription, where DNA bases are exchanged for their corresponding bases except in the case of thymine (T), for which RNA substitutes uracil (U).[4] Under the genetic code, these RNA strands specify the sequence of amino acids within proteins in a process called translation.

Within eukaryotic cells, DNA is organized into long structures called chromosomes. Before typical cell division, these chromosomes are duplicated in the process of DNA replication, providing a complete set of chromosomes for each daughter cell. Eukaryotic organisms (animals, plants, fungi and protists) store most of their DNA inside the cell nucleus as nuclear DNA, and some in the mitochondria as mitochondrial DNA or in chloroplasts as chloroplast DNA.[5] In contrast, prokaryotes (bacteria and archaea) store their DNA only in the cytoplasm, in circular chromosomes. Within eukaryotic chromosomes, chromatin proteins, such as histones, compact and organize DNA. These compacting structures guide the interactions between DNA and other proteins, helping control which parts of the DNA are transcribed.
$
10
Question: What are the two major types of nucleic acids mentioned in the subject text?
A: Proteins and lipids
B: DNA and RNA
C: Polysaccharides and nucleotides
D: Carbohydrates and lipids
E: Amino acids and nucleobases
Answer: B

Question: What is the name of the sugar found in nucleotides in DNA?
A: Glucose
B: Sucrose
C: Ribose
D: Deoxyribose
E: Fructose
Answer: D

Question: What type of bonds connect the nucleotides in a DNA strand?
A: Hydrogen bonds
B: Ionic bonds
C: Covalent bonds
D: Van der Waals forces
E: Metallic bonds
Answer: C

Question: Which nitrogenous base pairs with thymine in DNA?
A: Adenine
B: Cytosine
C: Guanine
D: Uracil
E: None of the above
Answer: A

Question: What is the complementary base for cytosine in DNA?
A: Guanine
B: Thymine
C: Adenine
D: Uracil
E: Cytosine
Answer: A

Question: What process involves the creation of RNA strands using DNA strands as templates?
A: Translation
B: Replication
C: Transcription
D: Reproduction
E: Duplication
Answer: C

Question: In eukaryotic cells, where is most of the DNA stored?
A: In the cell cytoplasm
B: In chloroplasts
C: In mitochondria
D: In the cell nucleus
E: In the ribosomes
Answer: D

Question: What is the name of the process by which chromosomes are duplicated before cell division?
A: Transcription
B: Replication
C: Translation
D: Translocation
E: Mutation
Answer: B

Question: What is the term for the structures that compact and organize DNA within eukaryotic chromosomes?
A: Ribosomes
B: Mitochondria
C: Histones
D: Nucleotides
E: Chromatids
Answer: C

Question: In which type of cells are chromosomes stored inside the cell nucleus?
A: Prokaryotic cells
B: Eukaryotic cells
C: Mitochondrial cells
D: Chloroplastic cells
E: Archaeal cells
Answer: B
@
In chemistry, a hydrogen bond (or H-bond) is a primarily electrostatic force of attraction between a hydrogen (H) atom which is covalently bound to a more electronegative "donor" atom or group (Dn), and another electronegative atom bearing a lone pair of electrons—the hydrogen bond acceptor (Ac). Such an interacting system is generally denoted Dn−H···Ac, where the solid line denotes a polar covalent bond, and the dotted or dashed line indicates the hydrogen bond.[5] The most frequent donor and acceptor atoms are the period 2 elements nitrogen (N), oxygen (O), and fluorine (F).

Hydrogen bonds can be intermolecular (occurring between separate molecules) or intramolecular (occurring among parts of the same molecule).[6][7][8][9] The energy of a hydrogen bond depends on the geometry, the environment, and the nature of the specific donor and acceptor atoms and can vary between 1 and 40 kcal/mol.[10] This makes them somewhat stronger than a van der Waals interaction, and weaker than fully covalent or ionic bonds. This type of bond can occur in inorganic molecules such as water and in organic molecules like DNA and proteins. Hydrogen bonds are responsible for holding materials such as paper and felted wool together, and for causing separate sheets of paper to stick together after becoming wet and subsequently drying.

The hydrogen bond is responsible for many of the physical and chemical properties of compounds of N, O, and F that seem unusual compared with other similar structures. In particular, intermolecular hydrogen bonding is responsible for the high boiling point of water (100 °C) compared to the other group-16 hydrides that have much weaker hydrogen bonds.[11] Intramolecular hydrogen bonding is partly responsible for the secondary and tertiary structures of proteins and nucleic acids.

Hydrogen bonds can vary in strength from weak (1–2 kJ/mol) to strong (161.5 kJ/mol in the bifluoride ion, HF
−
2
).[17][18] Typical enthalpies in vapor include:[19]

F−H···:F− (161.5 kJ/mol or 38.6 kcal/mol), illustrated uniquely by HF
−
2
O−H···:N (29 kJ/mol or 6.9 kcal/mol), illustrated water-ammonia
O−H···:O (21 kJ/mol or 5.0 kcal/mol), illustrated water-water, alcohol-alcohol
N−H···:N (13 kJ/mol or 3.1 kcal/mol), illustrated by ammonia-ammonia
N−H···:O (8 kJ/mol or 1.9 kcal/mol), illustrated water-amide
OH
+
3
···:OH2 (18 kJ/mol[20] or 4.3 kcal/mol)
The strength of intermolecular hydrogen bonds is most often evaluated by measurements of equilibria between molecules containing donor and/or acceptor units, most often in solution.[21] The strength of intramolecular hydrogen bonds can be studied with equilibria between conformers with and without hydrogen bonds. The most important method for the identification of hydrogen bonds also in complicated molecules is crystallography, sometimes also NMR-spectroscopy. Structural details, in particular distances between donor and acceptor which are smaller than the sum of the van der Waals radii can be taken as indication of the hydrogen bond strength.[citation needed]

One scheme gives the following somewhat arbitrary classification: those that are 15 to 40 kcal/mol, 5 to 15 kcal/mol, and >0 to 5 kcal/mol are considered strong, moderate, and weak, respectively.
$
10
Question: What is the primary force of attraction in a hydrogen bond?
A: Covalent bond
B: Ionic bond
C: Van der Waals interaction
D: Electrostatic force
E: Hydrophobic interaction
Answer: D

Question: What type of atoms are most frequently involved in hydrogen bonding as both donors and acceptors?
A: Carbon (C) and sulfur (S)
B: Oxygen (O), nitrogen (N), and fluorine (F)
C: Sodium (Na) and potassium (K)
D: Silicon (Si) and phosphorus (P)
E: Hydrogen (H) and helium (He)
Answer: B

Question: What type of hydrogen bonds occur between separate molecules?
A: Intramolecular hydrogen bonds
B: Covalent hydrogen bonds
C: Strong hydrogen bonds
D: Weak hydrogen bonds
E: Intermolecular hydrogen bonds
Answer: E

Question: What is the typical range of energy for hydrogen bonds?
A: 0.1 to 1 kcal/mol
B: 1 to 10 kcal/mol
C: 10 to 40 kcal/mol
D: 40 to 100 kcal/mol
E: 100 to 500 kcal/mol
Answer: C

Question: What is the main role of hydrogen bonds in holding materials like paper and felted wool together?
A: Breaking chemical bonds
B: Covalent bonding
C: Ionic bonding
D: Van der Waals interactions
E: Interacting with water molecules
Answer: D

Question: What unusual property of water is attributed to intermolecular hydrogen bonding?
A: High melting point
B: Low boiling point
C: Low heat capacity
D: High solubility in non-polar solvents
E: High boiling point
Answer: E

Question: What type of hydrogen bond is partly responsible for the secondary and tertiary structures of proteins and nucleic acids?
A: Intramolecular hydrogen bond
B: Covalent hydrogen bond
C: Van der Waals interaction
D: Electrostatic force
E: Hydrophobic interaction
Answer: A

Question: How is the strength of intermolecular hydrogen bonds most often evaluated?
A: By crystallography
B: By NMR-spectroscopy
C: By measuring equilibria between molecules in solution
D: By calculating van der Waals radii
E: By measuring bond distances in covalent compounds
Answer: C

Question: Which classification scheme is used to categorize the strength of hydrogen bonds?
A: Weak, moderate, strong
B: Strong, covalent, ionic
C: Van der Waals, electrostatic, hydrophobic
D: High, medium, low
E: Intramolecular, intermolecular, intracellular
Answer: A

Question: What is the energy range for strong hydrogen bonds according to the classification scheme mentioned in the subject text?
A: 1 to 5 kcal/mol
B: 5 to 15 kcal/mol
C: 10 to 40 kcal/mol
D: 15 to 40 kcal/mol
E: 40 to 100 kcal/mol
Answer: D
@
Crystallography is the experimental science of determining the arrangement of atoms in crystalline solids. Crystallography is a fundamental subject in the fields of materials science and solid-state physics (condensed matter physics). The word crystallography is derived from the Ancient Greek word κρύσταλλος (krústallos; "clear ice, rock-crystal"), with its meaning extending to all solids with some degree of transparency, and γράφειν (gráphein; "to write"). In July 2012, the United Nations recognised the importance of the science of crystallography by proclaiming that 2014 would be the International Year of Crystallography.[1]

Before the development of X-ray diffraction crystallography (see below), the study of crystals was based on physical measurements of their geometry using a goniometer.[2] This involved measuring the angles of crystal faces relative to each other and to theoretical reference axes (crystallographic axes), and establishing the symmetry of the crystal in question. The position in 3D space of each crystal face is plotted on a stereographic net such as a Wulff net or Lambert net. The pole to each face is plotted on the net. Each point is labelled with its Miller index. The final plot allows the symmetry of the crystal to be established.

Crystallographic methods now depend on analysis of the diffraction patterns of a sample targeted by a beam of some type. X-rays are most commonly used; other beams used include electrons or neutrons. Crystallographers often explicitly state the type of beam used, as in the terms X-ray crystallography, neutron diffraction and electron diffraction. These three types of radiation interact with the specimen in different ways.

X-rays interact with the spatial distribution of electrons in the sample.
Electrons are charged particles and therefore interact with the total charge distribution of both the atomic nuclei and the electrons of the sample.
Neutrons are scattered by the atomic nuclei through the strong nuclear forces, but in addition, the magnetic moment of neutrons is non-zero. They are therefore also scattered by magnetic fields. When neutrons are scattered from hydrogen-containing materials, they produce diffraction patterns with high noise levels. However, the material can sometimes be treated to substitute deuterium for hydrogen. Because of these different forms of interaction, the three types of radiation are suitable for different crystallographic studies.
The following sections mainly describe the use of X-rays. See these links for further information on using electrons for diffraction, crystallographic imaging, in transmission, reflection or for surfaces. For addition details on using neutrons see neutron diffraction.
$
10
Question: What is the primary objective of crystallography?
A: To determine the optical properties of crystals
B: To study the geometry of crystals
C: To analyze the symmetry of crystal faces
D: To determine the arrangement of atoms in crystalline solids
E: To investigate the electrical conductivity of crystals
Answer: D

Question: What is the origin of the word "crystallography"?
A: Latin and Greek roots meaning "solid matter study"
B: Arabic origin meaning "clear ice study"
C: Chinese origin meaning "atomic arrangement science"
D: Greek roots meaning "rock-crystal writing"
E: French origin meaning "solid structure analysis"
Answer: D

Question: What did crystallographers use before the development of X-ray diffraction crystallography to study crystals?
A: Stereographic nets
B: Goniometers
C: Neutron beams
D: Lambert nets
E: Electron microscopes
Answer: B

Question: Which of the following beams is most commonly used in crystallography?
A: Proton beams
B: Electron beams
C: Neutron beams
D: X-rays
E: Alpha particles
Answer: D

Question: How do X-rays primarily interact with the specimen in crystallography?
A: By scattering from the atomic nuclei
B: By interacting with the total charge distribution of both atomic nuclei and electrons
C: By scattering from magnetic fields
D: By producing high noise levels
E: By substituting deuterium for hydrogen
Answer: B

Question: What is the International Year of Crystallography?
A: 2007
B: 2012
C: 2014
D: 2017
E: 2020
Answer: C

Question: What is the term for the spatial distribution of electrons in a crystal?
A: Atomic distribution
B: Charge distribution
C: Magnetic distribution
D: Neutron distribution
E: X-ray distribution
Answer: B

Question: Which type of radiation is scattered by magnetic fields in crystallography?
A: X-rays
B: Electrons
C: Neutrons
D: Alpha particles
E: Proton beams
Answer: C

Question: In which sections of crystallography are X-rays most commonly used?
A: Electron diffraction
B: Neutron diffraction
C: Crystallographic imaging
D: In transmission
E: X-ray crystallography
Answer: E

Question: What is the term for the technique of using neutrons for crystallography?
A: Electron diffraction
B: X-ray crystallography
C: Proton diffraction
D: Neutron diffraction
E: Neutron imaging
Answer: D
@
The electron (
e−
 or 
β−
) is a subatomic particle with a negative one elementary electric charge.[13] Electrons belong to the first generation of the lepton particle family,[14] and are generally thought to be elementary particles because they have no known components or substructure.[1] The electron's mass is approximately 1/1836 that of the proton.[15] Quantum mechanical properties of the electron include an intrinsic angular momentum (spin) of a half-integer value, expressed in units of the reduced Planck constant, ħ. Being fermions, no two electrons can occupy the same quantum state, per the Pauli exclusion principle.[14] Like all elementary particles, electrons exhibit properties of both particles and waves: They can collide with other particles and can be diffracted like light. The wave properties of electrons are easier to observe with experiments than those of other particles like neutrons and protons because electrons have a lower mass and hence a longer de Broglie wavelength for a given energy.

Electrons play an essential role in numerous physical phenomena, such as electricity, magnetism, chemistry, and thermal conductivity; they also participate in gravitational, electromagnetic, and weak interactions.[16] Since an electron has charge, it has a surrounding electric field; if that electron is moving relative to an observer, the observer will observe it to generate a magnetic field. Electromagnetic fields produced from other sources will affect the motion of an electron according to the Lorentz force law. Electrons radiate or absorb energy in the form of photons when they are accelerated. Laboratory instruments are capable of trapping individual electrons as well as electron plasma by the use of electromagnetic fields. Special telescopes can detect electron plasma in outer space. Electrons are involved in many applications, such as tribology or frictional charging, electrolysis, electrochemistry, battery technologies, electronics, welding, cathode-ray tubes, photoelectricity, photovoltaic solar panels, electron microscopes, radiation therapy, lasers, gaseous ionization detectors, and particle accelerators.

Interactions involving electrons with other subatomic particles are of interest in fields such as chemistry and nuclear physics. The Coulomb force interaction between the positive protons within atomic nuclei and the negative electrons without allows the composition of the two known as atoms. Ionization or differences in the proportions of negative electrons versus positive nuclei changes the binding energy of an atomic system. The exchange or sharing of the electrons between two or more atoms is the main cause of chemical bonding.[17] In 1838, British natural philosopher Richard Laming first hypothesized the concept of an indivisible quantity of electric charge to explain the chemical properties of atoms.[3] Irish physicist George Johnstone Stoney named this charge 'electron' in 1891, and J. J. Thomson and his team of British physicists identified it as a particle in 1897 during the cathode-ray tube experiment.[5] Electrons can also participate in nuclear reactions, such as nucleosynthesis in stars, where they are known as beta particles. Electrons can be created through beta decay of radioactive isotopes and in high-energy collisions, for instance, when cosmic rays enter the atmosphere. The antiparticle of the electron is called the positron; it is identical to the electron, except that it carries electrical charge of the opposite sign. When an electron collides with a positron, both particles can be annihilated, producing gamma ray photons.
$
10
Question: What is the elementary electric charge of an electron?
A: Positive one
B: Negative one
C: Positive two
D: Negative two
E: Zero
Answer: B

Question: What is the mass of an electron relative to a proton?
A: Approximately 1/2
B: Approximately 1/1836
C: Approximately 1/1000
D: Approximately 2/3
E: Approximately 1
Answer: B

Question: What is the intrinsic angular momentum (spin) value of an electron?
A: Zero
B: 1/2
C: 1
D: 2
E: 3/2
Answer: B

Question: According to the Pauli exclusion principle, how many electrons can occupy the same quantum state?
A: One
B: Two
C: Three
D: Four
E: Five
Answer: A

Question: Why are the wave properties of electrons easier to observe with experiments compared to other particles like neutrons and protons?
A: Electrons have a higher mass.
B: Electrons have a shorter de Broglie wavelength.
C: Electrons have no wave properties.
D: Electrons have a lower mass and longer de Broglie wavelength for a given energy.
E: Electrons have a higher energy.
Answer: D

Question: What role do electrons play in electricity?
A: They generate a magnetic field.
B: They participate in gravitational interactions.
C: They emit photons.
D: They trap individual electrons.
E: They carry electric charge and contribute to electric current.
Answer: E

Question: What happens when electrons are accelerated and radiate or absorb energy?
A: They create a strong magnetic field.
B: They lose mass.
C: They generate a gravitational field.
D: They emit or absorb photons.
E: They become stationary.
Answer: D

Question: What is the antiparticle of an electron?
A: Proton
B: Neutron
C: Positron
D: Photon
E: Beta particle
Answer: C

Question: What is the main cause of chemical bonding between atoms?
A: Gravitational force
B: Electromagnetic interactions
C: Neutron exchange
D: Beta decay
E: Nuclear reactions
Answer: B

Question: Who named the elementary electric charge 'electron' in 1891?
A: George Johnstone Stoney
B: J. J. Thomson
C: Richard Laming
D: George Thomson
E: Robert Millikan
Answer: A
@
An electron microscope is a microscope that uses a beam of electrons as a source of illumination. They use electron optics that are analogous to the glass lenses of an optical light microscope. As the wavelength of an electron can be up to 100,000 times shorter than that of visible light, electron microscopes have a higher resolution of about 0.1 nm, which compares to about 200 nm for light microscopes. Electron microscope may refer to:

Transmission electron microscopy (TEM) where swift electrons go through a thin sample
Scanning transmission electron microscopy (STEM) is similar to TEM with a scanned electron probe
Scanning electron microscope (SEM) is similar the STEM, but with thick samples
Electron microprobe similar to a SEM, but more for chemical analysis
Ultrafast scanning electron microscopy, version of SEM that can operate very fast
Low-energy electron microscopy (LEEM), used to image surfaces
Photoemission electron microscopy (PEEM) is similar to LEEM using electrons produced at surfaces by photons
Additional details can be found in the above. This articles contains some general information mainly about transmission electron microscopes.

Many developments laid the groundwork of the electron optics used in microscopes.[1] One significant step was the work of Hertz in 1883[2] who made a cathode-ray tube with electrostatic and magnetic deflection, demonstrating manipulation of the direction of an electron beam. Others were focusing of the electrons by an axial magnetic field by Emil Wiechert in 1899,[3] improved oxide-coated cathodes which produced more electrons by Arthur Wehnelt in 1905[4] and the development of the electromagnetic lens in 1926 by Hans Busch.[5] According to Dennis Gabor, the physicist Leó Szilárd tried in 1928 to convince him to build an electron microscope, for which Szilárd had filed a patent.[6]

To this day the issue of who invented the transmission electron microscope is controversial.[7][8][9][10] In 1928, at the Technical University of Berlin, Adolf Matthias (Professor of High Voltage Technology and Electrical Installations) appointed Max Knoll to lead a team of researchers to advance research on electron beams and cathode-ray oscilloscopes. The team consisted of several PhD students including Ernst Ruska. In 1931, Max Knoll and Ernst Ruska[11][12] successfully generated magnified images of mesh grids placed over an anode aperture. The device, a replicate of which is shown in the figure, used two magnetic lenses to achieve higher magnifications, the first electron microscope. (Max Knoll died in 1969, so did not receive a share of the Nobel Prize in 1986.)

Apparently independent of this effort was work at Siemens-Schuckert by Reinhold Rüdenberg. According to patent law (U.S. Patent No. 2058914[13] and 2070318,[14] both filed in 1932), he is the inventor of the electron microscope, but it is not clear when he had a working instrument. He stated in a very brief article in 1932[15] that Siemens had been working on this for some years before the patents were filed in 1932, claiming that his effort was parallel to the university development. He died in 1961, so similar to Max Knoll, was not eligible for a share of the Nobel Prize.

In the following year, 1933, Ruska and Knoll built the first electron microscope that exceeded the resolution attainable with an optical (light) microscope.[16] Four years later, in 1937, Siemens financed the work of Ernst Ruska and Bodo von Borries, and employed Helmut Ruska, Ernst's brother, to develop applications for the microscope, especially with biological specimens.[16][17] Also in 1937, Manfred von Ardenne pioneered the scanning electron microscope.[18] Siemens produced the first commercial electron microscope in 1938.[19] The first North American electron microscopes were constructed in the 1930s, at the Washington State University by Anderson and Fitzsimmons [20] and at the University of Toronto by Eli Franklin Burton and students Cecil Hall, James Hillier, and Albert Prebus. Siemens produced a transmission electron microscope (TEM) in 1939.[21] Although current transmission electron microscopes are capable of two million-power magnification, as scientific instruments they remain similar but with improved optics.
$
10
Question: Which type of electron microscope is used to image surfaces?
A: Transmission electron microscopy (TEM)
B: Scanning transmission electron microscopy (STEM)
C: Scanning electron microscope (SEM)
D: Electron microprobe
E: Ultrafast scanning electron microscopy
Answer: C

Question: What is the typical resolution of an electron microscope?
A: Approximately 1 nm
B: Approximately 10 nm
C: Approximately 100 nm
D: Approximately 0.1 nm
E: Approximately 200 nm
Answer: D

Question: Who made a cathode-ray tube with electrostatic and magnetic deflection in 1883, demonstrating manipulation of the direction of an electron beam?
A: Max Knoll
B: Reinhold Rüdenberg
C: Ernst Ruska
D: Hertz
E: Dennis Gabor
Answer: D

Question: Who is considered to have built the first electron microscope that exceeded the resolution attainable with an optical microscope in 1933?
A: Reinhold Rüdenberg
B: Hertz
C: Max Knoll
D: Ernst Ruska
E: Helmut Ruska
Answer: D

Question: In which year did Siemens produce the first commercial electron microscope?
A: 1933
B: 1937
C: 1938
D: 1939
E: 1940
Answer: C

Question: What type of lens did Hans Busch develop in 1926?
A: Magnetic lens
B: Electromagnetic lens
C: Optical lens
D: Electron lens
E: Photographic lens
Answer: B

Question: Who is credited with pioneering the scanning electron microscope in 1937?
A: Max Knoll
B: Reinhold Rüdenberg
C: Ernst Ruska
D: Manfred von Ardenne
E: Dennis Gabor
Answer: D

Question: What was the first electron microscope built by Max Knoll and Ernst Ruska in 1931 known for?
A: Generating magnified images of biological specimens
B: Achieving high magnifications using two magnetic lenses
C: Its ability to operate very fast
D: Its use of electron microprobe technology
E: Scanning surfaces with atomic precision
Answer: B

Question: In what year did Adolf Matthias appoint Max Knoll to lead a team of researchers at the Technical University of Berlin?
A: 1928
B: 1931
C: 1933
D: 1937
E: 1938
Answer: A

Question: Who is considered the inventor of the electron microscope according to U.S. patent law?
A: Max Knoll
B: Reinhold Rüdenberg
C: Ernst Ruska
D: Hertz
E: Manfred von Ardenne
Answer: B
@
A chemical bond is a lasting attraction between atoms or ions that enables the formation of molecules, crystals, and other structures. The bond may result from the electrostatic force between oppositely charged ions as in ionic bonds, or through the sharing of electrons as in covalent bonds. The strength of chemical bonds varies considerably; there are "strong bonds" or "primary bonds" such as covalent, ionic and metallic bonds, and "weak bonds" or "secondary bonds" such as dipole–dipole interactions, the London dispersion force, and hydrogen bonding.

Since opposite electric charges attract, the negatively charged electrons surrounding the nucleus and the positively charged protons within a nucleus attract each other. Electrons shared between two nuclei will be attracted to both of them. "Constructive quantum mechanical wavefunction interference"[1] stabilizes the paired nuclei (see Theories of chemical bonding). Bonded nuclei maintain an optimal distance (the bond distance) balancing attractive and repulsive effects explained quantitatively by quantum theory.[2][3]

The atoms in molecules, crystals, metals and other forms of matter are held together by chemical bonds, which determine the structure and properties of matter.

All bonds can be described by quantum theory, but, in practice, simplified rules and other theories allow chemists to predict the strength, directionality, and polarity of bonds.[4] The octet rule and VSEPR theory are examples. More sophisticated theories are valence bond theory, which includes orbital hybridization[5] and resonance,[6] and molecular orbital theory[7] which includes the linear combination of atomic orbitals and ligand field theory. Electrostatics are used to describe bond polarities and the effects they have on chemical substances.

Strong chemical bonds are the intramolecular forces that hold atoms together in molecules. A strong chemical bond is formed from the transfer or sharing of electrons between atomic centers and relies on the electrostatic attraction between the protons in nuclei and the electrons in the orbitals.

The types of strong bond differ due to the difference in electronegativity of the constituent elements. Electronegativity is the tendency for an atom of a given chemical element to attract shared electrons when forming a chemical bond, where the higher the associated electronegativity then the more it attracts electrons. Electronegativity serves as a simple way to quantitatively estimate the bond energy, which characterizes a bond along the continuous scale from covalent to ionic bonding. A large difference in electronegativity leads to more polar (ionic) character in the bond.
$
10
Question: What type of bond results from the sharing of electrons?
A: Ionic bond
B: Covalent bond
C: Metallic bond
D: Dipole–dipole bond
E: London dispersion bond
Answer: B

Question: What are "strong bonds" in chemistry also known as?
A: Intramolecular forces
B: Intermolecular forces
C: Metallic bonds
D: Dipole–dipole interactions
E: London dispersion forces
Answer: A

Question: What stabilizes the paired nuclei in a chemical bond according to quantum theory?
A: Repulsive effects
B: Constructive quantum mechanical wavefunction interference
C: Ionic attraction
D: Metallic bonding
E: Dipole–dipole interactions
Answer: B

Question: Which theory includes orbital hybridization and resonance as its components?
A: VSEPR theory
B: Molecular orbital theory
C: Valence bond theory
D: Ligand field theory
E: Octet rule theory
Answer: C

Question: What is the tendency for an atom to attract shared electrons when forming a chemical bond called?
A: Bond energy
B: Quantum effect
C: Electron distribution
D: Electronegativity
E: Covalent character
Answer: D

Question: Which type of bond characterizes a bond with a large difference in electronegativity?
A: Covalent bond
B: Ionic bond
C: Metallic bond
D: Dipole–dipole bond
E: London dispersion bond
Answer: B

Question: What theory includes the linear combination of atomic orbitals and ligand field theory?
A: Valence bond theory
B: Molecular orbital theory
C: VSEPR theory
D: Resonance theory
E: Octet rule theory
Answer: B

Question: Which type of bond relies on the electrostatic attraction between protons in nuclei and electrons in orbitals?
A: Covalent bond
B: Ionic bond
C: Metallic bond
D: Dipole–dipole bond
E: London dispersion bond
Answer: A

Question: What serves as a simple way to quantitatively estimate bond energy and characterizes a bond on a continuous scale from covalent to ionic bonding?
A: Quantum theory
B: Electronegativity
C: Bond strength
D: Orbital hybridization
E: Valence bond theory
Answer: B

Question: Which theory uses electrostatics to describe bond polarities and their effects on chemical substances?
A: Octet rule theory
B: VSEPR theory
C: Valence bond theory
D: Molecular orbital theory
E: Ligand field theory
Answer: A
@
A metal (from Ancient Greek μέταλλον métallon 'mine, quarry, metal') is a material that, when freshly prepared, polished, or fractured, shows a lustrous appearance, and conducts electricity and heat relatively well. Metals are typically ductile (can be drawn into wires) and malleable (they can be hammered into thin sheets). These properties are the result of the metallic bond between the atoms or molecules of the metal.

A metal may be a chemical element such as iron; an alloy such as stainless steel; or a molecular compound such as polymeric sulfur nitride.[1]

In physics, a metal is generally regarded as any substance capable of conducting electricity at a temperature of absolute zero.[2] Many elements and compounds that are not normally classified as metals become metallic under high pressures. For example, the nonmetal iodine gradually becomes a metal at a pressure of between 40 and 170 thousand times atmospheric pressure. Equally, some materials regarded as metals can become nonmetals. Sodium, for example, becomes a nonmetal at pressure of just under two million times atmospheric pressure.

In chemistry, two elements that would otherwise qualify (in physics) as brittle metals—arsenic and antimony—are commonly instead recognised as metalloids due to their chemistry (predominantly non-metallic for arsenic, and balanced between metallicity and nonmetallicity for antimony). Around 95 of the 118 elements in the periodic table are metals (or are likely to be such). The number is inexact as the boundaries between metals, nonmetals, and metalloids fluctuate slightly due to a lack of universally accepted definitions of the categories involved.

In astrophysics the term "metal" is cast more widely to refer to all chemical elements in a star that are heavier than helium, and not just traditional metals. In this sense the first four "metals" collecting in stellar cores through nucleosynthesis are carbon, nitrogen, oxygen, and neon, all of which are strictly non-metals in chemistry. A star fuses lighter atoms, mostly hydrogen and helium, into heavier atoms over its lifetime. Used in that sense, the metallicity of an astronomical object is the proportion of its matter made up of the heavier chemical elements.[3][4]

Metals, as chemical elements, comprise 25% of the Earth's crust and are present in many aspects of modern life. The strength and resilience of some metals has led to their frequent use in, for example, high-rise building and bridge construction, as well as most vehicles, many home appliances, tools, pipes, and railroad tracks. Precious metals were historically used as coinage, but in the modern era, coinage metals have extended to at least 23 of the chemical elements.[5]

The history of refined metals is thought to begin with the use of copper about 11,000 years ago. Gold, silver, iron (as meteoric iron), lead, and brass were likewise in use before the first known appearance of bronze in the fifth millennium BCE. Subsequent developments include the production of early forms of steel; the discovery of sodium—the first light metal—in 1809; the rise of modern alloy steels; and, since the end of World War II, the development of more sophisticated alloys.
$
10
Question: What is the property of metals that allows them to be drawn into wires?
A: Ductility
B: Malleability
C: Conductivity
D: Luster
E: Brittleness
Answer: A

Question: Which chemical element is given as an example of a metal in the subject text?
A: Iron
B: Sodium
C: Iodine
D: Carbon
E: Oxygen
Answer: A

Question: At what pressure does iodine become a metal?
A: 40 times atmospheric pressure
B: 170 thousand times atmospheric pressure
C: 2 million times atmospheric pressure
D: 95 times atmospheric pressure
E: 118 times atmospheric pressure
Answer: B

Question: Why are arsenic and antimony commonly recognized as metalloids instead of brittle metals in chemistry?
A: Due to their metallic appearance
B: Because they have high electrical conductivity
C: Because they have a lustrous appearance
D: Due to their chemistry, which is predominantly non-metallic
E: Because they can be easily hammered into thin sheets
Answer: D

Question: In astrophysics, what term refers to all chemical elements in a star that are heavier than helium?
A: Metalloids
B: Non-metals
C: Alloys
D: Metallicity
E: Metallurgy
Answer: D

Question: What proportion of the Earth's crust do metals comprise?
A: 5%
B: 10%
C: 15%
D: 25%
E: 50%
Answer: D

Question: What were the first four elements considered "metals" in astrophysics, despite being non-metals in chemistry?
A: Hydrogen, helium, lithium, beryllium
B: Carbon, nitrogen, oxygen, neon
C: Sodium, potassium, calcium, magnesium
D: Iron, nickel, copper, zinc
E: Gold, silver, platinum, palladium
Answer: B

Question: What is the term used in astrophysics to describe the proportion of an astronomical object's matter made up of heavier chemical elements?
A: Metallurgy
B: Metallicity
C: Metallography
D: Metallurgics
E: Metallode
Answer: B

Question: What were some of the early metals used by humans before the appearance of bronze?
A: Gold, silver, iron, lead, and brass
B: Copper, tin, zinc, aluminum, and nickel
C: Platinum, palladium, mercury, and tungsten
D: Sodium, potassium, calcium, and magnesium
E: Uranium, thorium, radium, and plutonium
Answer: A

Question: When did the history of refined metals begin with the use of copper?
A: About 100 years ago
B: About 1,000 years ago
C: About 5,000 years ago
D: About 11,000 years ago
E: About 50,000 years ago
Answer: D
@
Density (volumetric mass density or specific mass) is a substance's mass per unit of volume. The symbol most often used for density is ρ (the lower case Greek letter rho), although the Latin letter D can also be used. Mathematically, density is defined as mass divided by volume:[1]

�
=
�
�
,
{\displaystyle \rho ={\frac {m}{V}},}
where ρ is the density, m is the mass, and V is the volume. In some cases (for instance, in the United States oil and gas industry), density is loosely defined as its weight per unit volume,[2] although this is scientifically inaccurate – this quantity is more specifically called specific weight.
For a pure substance the density has the same numerical value as its mass concentration. Different materials usually have different densities, and density may be relevant to buoyancy, purity and packaging. Osmium and iridium are the densest known elements at standard conditions for temperature and pressure.

To simplify comparisons of density across different systems of units, it is sometimes replaced by the dimensionless quantity "relative density" or "specific gravity", i.e. the ratio of the density of the material to that of a standard material, usually water. Thus a relative density less than one relative to water means that the substance floats in water.

The density of a material varies with temperature and pressure. This variation is typically small for solids and liquids but much greater for gases. Increasing the pressure on an object decreases the volume of the object and thus increases its density. Increasing the temperature of a substance (with a few exceptions) decreases its density by increasing its volume. In most materials, heating the bottom of a fluid results in convection of the heat from the bottom to the top, due to the decrease in the density of the heated fluid, which causes it to rise relative to denser unheated material.

The reciprocal of the density of a substance is occasionally called its specific volume, a term sometimes used in thermodynamics. Density is an intensive property in that increasing the amount of a substance does not increase its density; rather it increases its mass.

Other conceptually comparable quantities or ratios include specific density, relative density (specific gravity), and specific weight.
$
10
Question: How is density mathematically defined?
A: ρ = m / V
B: ρ = V / m
C: ρ = m + V
D: ρ = m - V
E: ρ = m * V
Answer: A

Question: Which element is mentioned as one of the densest known elements at standard conditions for temperature and pressure?
A: Hydrogen
B: Oxygen
C: Osmium
D: Carbon
E: Nitrogen
Answer: C

Question: What is the dimensionless quantity that represents the ratio of the density of a material to that of a standard material, usually water?
A: Relative weight
B: Absolute density
C: Specific weight
D: Specific gravity
E: Relative density
Answer: D

Question: How does increasing pressure affect the density of an object?
A: It decreases the density
B: It increases the density
C: It has no effect on density
D: It depends on the object's shape
E: It turns the object into a gas
Answer: B

Question: What effect does increasing the temperature of a substance typically have on its density?
A: It decreases the density
B: It increases the density
C: It has no effect on density
D: It depends on the substance
E: It turns the substance into a solid
Answer: A

Question: What term is used to describe the reciprocal of the density of a substance?
A: Specific volume
B: Relative weight
C: Absolute density
D: Specific gravity
E: Relative volume
Answer: A

Question: Which property does increasing the amount of a substance NOT increase?
A: Mass
B: Density
C: Volume
D: Temperature
E: Specific volume
Answer: B

Question: What is the term used in thermodynamics to describe the reciprocal of density?
A: Specific volume
B: Relative density
C: Specific weight
D: Absolute density
E: Relative volume
Answer: A

Question: What is the scientific symbol most often used to represent density?
A: D
B: M
C: V
D: ρ (rho)
E: δ (delta)
Answer: D

Question: Which term is used to describe the ratio of the density of a material to that of a standard material, usually water?
A: Specific weight
B: Absolute density
C: Relative density
D: Relative weight
E: Specific gravity
Answer: C
@
Iridium is a chemical element with the symbol Ir and atomic number 77. A very hard, brittle, silvery-white transition metal of the platinum group, it is considered the second-densest naturally occurring metal (after osmium) with a density of 22.56 g/cm3 (0.815 lb/cu in) as defined by experimental X-ray crystallography.[a] It is one of the most corrosion-resistant metals, even at temperatures as high as 2,000 °C (3,630 °F). However, corrosion-resistance is not quantifiable in absolute terms; although only certain molten salts and halogens are corrosive to solid iridium, finely divided iridium dust is much more reactive and can be flammable, whereas gold dust is not flammable but can be attacked by substances that iridium resists, such as aqua regia.

Iridium was discovered in 1803 among insoluble impurities in natural platinum. Smithson Tennant, the primary discoverer, named it after the Greek goddess Iris, personification of the rainbow, because of the striking and diverse colors of its salts. Iridium is one of the rarest elements in Earth's crust, with estimated annual production and consumption of only 7.3 tonnes (16 thousand pounds) in 2018.[8] 191Ir and 193Ir are the only two naturally occurring isotopes of iridium, as well as the only stable isotopes; the latter is the more abundant.

The dominant uses of iridium are the metal itself and its alloys, as in high-performance spark plugs, crucibles for recrystallization of semiconductors at high temperatures, and electrodes for the production of chlorine in the chloralkali process. Important compounds of iridium are chlorides and iodides in industrial catalysis. Iridium is a component of some OLEDs.

Iridium is found in meteorites in much higher abundance than in the Earth's crust.[9] For this reason, the unusually high abundance of iridium in the clay layer at the Cretaceous–Paleogene boundary gave rise to the Alvarez hypothesis that the impact of a massive extraterrestrial object caused the extinction of dinosaurs and many other species 66 million years ago, now known to be produced by the impact that formed the Chicxulub crater. Similarly, an iridium anomaly in core samples from the Pacific Ocean suggested the Eltanin impact of about 2.5 million years ago.[10]

It is thought that the total amount of iridium in the planet Earth is much higher than that observed in crustal rocks, but as with other platinum-group metals, the high density and tendency of iridium to bond with iron caused most iridium to descend below the crust when the planet was young and still molten.

A member of the platinum group metals, iridium is white, resembling platinum, but with a slight yellowish cast. Because of its hardness, brittleness, and very high melting point, solid iridium is difficult to machine, form, or work; thus powder metallurgy is commonly employed instead.[11] It is the only metal to maintain good mechanical properties in air at temperatures above 1,600 °C (2,910 °F).[12] It has the 10th highest boiling point among all elements and becomes a superconductor at temperatures below 0.14 K (−273.010 °C; −459.418 °F).[13]
$
10
Question: What is the atomic number of iridium?
A: 22
B: 77
C: 55
D: 193
E: 16
Answer: B

Question: What is the second-densest naturally occurring metal, following osmium?
A: Gold
B: Silver
C: Iridium
D: Platinum
E: Aluminum
Answer: C

Question: Who is credited with discovering iridium in 1803?
A: Albert Einstein
B: Isaac Newton
C: Smithson Tennant
D: Marie Curie
E: Galileo Galilei
Answer: C

Question: Why was iridium named after the Greek goddess Iris?
A: Due to its rainbow-like appearance
B: Because it was discovered during a rainbow
C: It was named after a famous scientist named Iris
D: Iris discovered iridium
E: There is no specific reason for the name
Answer: A

Question: How many naturally occurring isotopes of iridium are there?
A: 5
B: 2
C: 10
D: 0
E: 1
Answer: B

Question: What is the dominant use of iridium in the form of alloys?
A: Jewelry
B: High-performance spark plugs
C: Electrical wiring
D: Coins
E: Cooking utensils
Answer: B

Question: Which event in Earth's history is associated with an iridium anomaly at the Cretaceous-Paleogene boundary?
A: Formation of the Himalayas
B: Extinction of dinosaurs
C: First appearance of humans
D: Formation of the Grand Canyon
E: Rise of the Roman Empire
Answer: B

Question: Why did most iridium descend below the Earth's crust when the planet was young?
A: Because it was less dense than other elements
B: Due to its high reactivity with other elements
C: Because of its tendency to bond with iron
D: It was attracted to the Earth's core
E: It didn't descend, but remained in the crust
Answer: C

Question: What is the highest boiling point among all elements?
A: Mercury
B: Oxygen
C: Iridium
D: Gold
E: Hydrogen
Answer: C

Question: At what temperature does iridium become a superconductor?
A: 100 K
B: 50 K
C: 0.14 K
D: 273.15 K
E: 500 K
Answer: C
@
Curium is a transuranic, radioactive chemical element with the symbol Cm and atomic number 96. This actinide element was named after eminent scientists Marie and Pierre Curie, both known for their research on radioactivity. Curium was first intentionally made by the team of Glenn T. Seaborg, Ralph A. James, and Albert Ghiorso in 1944, using the cyclotron at Berkeley. They bombarded the newly discovered element plutonium (the isotope 239Pu) with alpha particles. This was then sent to the Metallurgical Laboratory at University of Chicago where a tiny sample of curium was eventually separated and identified. The discovery was kept secret until after the end of World War II. The news was released to the public in November 1947. Most curium is produced by bombarding uranium or plutonium with neutrons in nuclear reactors – one tonne of spent nuclear fuel contains ~20 grams of curium.

Curium is a hard, dense, silvery metal with a high melting and boiling point for an actinide. It is paramagnetic at ambient conditions, but becomes antiferromagnetic upon cooling, and other magnetic transitions are also seen in many curium compounds. In compounds, curium usually has valence +3 and sometimes +4; the +3 valence is predominant in solutions. Curium readily oxidizes, and its oxides are a dominant form of this element. It forms strongly fluorescent complexes with various organic compounds, but there is no evidence of its incorporation into bacteria and archaea. If it gets into the human body, curium accumulates in bones, lungs, and liver, where it promotes cancer.

All known isotopes of curium are radioactive and have small critical mass for a nuclear chain reaction. They mostly emit α-particles; radioisotope thermoelectric generators can use the heat from this process, but this is hindered by the rarity and high cost of curium. Curium is used in making heavier actinides and the 238Pu radionuclide for power sources in artificial cardiac pacemakers and RTGs for spacecraft. It served as the α-source in the alpha particle X-ray spectrometers of several space probes, including the Sojourner, Spirit, Opportunity, and Curiosity Mars rovers and the Philae lander on comet 67P/Churyumov–Gerasimenko, to analyze the composition and structure of the surface.
$
10
Question: Who were Marie and Pierre Curie, after whom curium is named?
A: Famous musicians
B: Renowned scientists
C: Ancient philosophers
D: Fictional characters
E: Political leaders
Answer: B

Question: How was curium first intentionally made?
A: By mining it from the Earth's crust
B: By extracting it from uranium deposits
C: By bombarding plutonium with alpha particles
D: By heating uranium in a furnace
E: By using a chemical reaction
Answer: C

Question: What is the primary location where curium is produced today?
A: Laboratories
B: Nuclear power plants
C: Solar farms
D: Wind turbines
E: Oil refineries
Answer: B

Question: What is the predominant valence of curium in solutions?
A: +1
B: +2
C: +3
D: +4
E: +5
Answer: C

Question: Where does curium accumulate in the human body if it is ingested?
A: Muscles
B: Brain
C: Skin
D: Bones, lungs, and liver
E: Heart
Answer: D

Question: Which type of radiation is mostly emitted by all known isotopes of curium?
A: Beta particles
B: Gamma rays
C: Neutrons
D: Alpha particles
E: X-rays
Answer: D

Question: What is the hindrance to using curium in radioisotope thermoelectric generators (RTGs)?
A: Its low radioactivity
B: Its abundance in nature
C: Its low cost
D: Its rarity and high cost
E: Its high melting point
Answer: D

Question: In which space probes' alpha particle X-ray spectrometers has curium been used to analyze the composition and structure of the surface?
A: None
B: Voyager 1 and 2
C: Hubble Space Telescope
D: Sojourner, Spirit, Opportunity, and Curiosity Mars rovers, and Philae lander
E: International Space Station
Answer: D

Question: What element was bombarded with alpha particles to create curium?
A: Uranium
B: Plutonium
C: Neptunium
D: Americium
E: Thorium
Answer: B

Question: Why was the discovery of curium kept secret until after World War II?
A: To protect the element from being stolen
B: To avoid interference with military operations
C: To prevent panic among the public
D: To keep scientific discoveries confidential
E: There was no specific reason; it was not intentionally kept secret
Answer: B
@
Cancer is a group of diseases involving abnormal cell growth with the potential to invade or spread to other parts of the body.[2][7] These contrast with benign tumors, which do not spread.[7] Possible signs and symptoms include a lump, abnormal bleeding, prolonged cough, unexplained weight loss, and a change in bowel movements.[1] While these symptoms may indicate cancer, they can also have other causes.[1] Over 100 types of cancers affect humans.[7]

Tobacco use is the cause of about 22% of cancer deaths.[2] Another 10% are due to obesity, poor diet, lack of physical activity or excessive alcohol consumption.[2][8][9] Other factors include certain infections, exposure to ionizing radiation, and environmental pollutants.[3] In the developing world, 15% of cancers are due to infections such as Helicobacter pylori, hepatitis B, hepatitis C, human papillomavirus infection, Epstein–Barr virus and human immunodeficiency virus (HIV).[2] These factors act, at least partly, by changing the genes of a cell.[10] Typically, many genetic changes are required before cancer develops.[10] Approximately 5–10% of cancers are due to inherited genetic defects.[11] Cancer can be detected by certain signs and symptoms or screening tests.[2] It is then typically further investigated by medical imaging and confirmed by biopsy.[12]

The risk of developing certain cancers can be reduced by not smoking, maintaining a healthy weight, limiting alcohol intake, eating plenty of vegetables, fruits, and whole grains, vaccination against certain infectious diseases, limiting consumption of processed meat and red meat, and limiting exposure to direct sunlight.[13][14] Early detection through screening is useful for cervical and colorectal cancer.[15] The benefits of screening for breast cancer are controversial.[15][16] Cancer is often treated with some combination of radiation therapy, surgery, chemotherapy and targeted therapy.[2][4] Pain and symptom management are an important part of care.[2] Palliative care is particularly important in people with advanced disease.[2] The chance of survival depends on the type of cancer and extent of disease at the start of treatment.[10] In children under 15 at diagnosis, the five-year survival rate in the developed world is on average 80%.[17] For cancer in the United States, the average five-year survival rate is 66% for all ages.[5]

In 2015, about 90.5 million people worldwide had cancer.[18] In 2019, annual cancer cases grew by 23.6 million people and there were 10 million deaths worldwide, representing over the previous decade increases of 26% and 21%, respectively.[6][19]

The most common types of cancer in males are lung cancer, prostate cancer, colorectal cancer, and stomach cancer.[20] In females, the most common types are breast cancer, colorectal cancer, lung cancer, and cervical cancer.[10] If skin cancer other than melanoma were included in total new cancer cases each year, it would account for around 40% of cases.[21][22] In children, acute lymphoblastic leukemia and brain tumors are most common, except in Africa, where non-Hodgkin lymphoma occurs more often.[17] In 2012, about 165,000 children under 15 years of age were diagnosed with cancer.[20] The risk of cancer increases significantly with age, and many cancers occur more commonly in developed countries.[10] Rates are increasing as more people live to an old age and as lifestyle changes occur in the developing world.[23] The global total economic costs of cancer were estimated at US$1.16 trillion (equivalent to $1.56 trillion in 2022) per year as of 2010.[24]
$
10
Question: What is the term for a group of diseases involving abnormal cell growth with the potential to invade or spread to other parts of the body?
A: Aberrant conditions
B: Proliferative disorders
C: Benign tumors
D: Cancers
E: Unusual cell states
Answer: D

Question: What percentage of cancer deaths are caused by tobacco use?
A: 5%
B: 10%
C: 15%
D: 22%
E: 50%
Answer: D

Question: Which infection is NOT mentioned as a factor contributing to cancer in the developing world?
A: Helicobacter pylori
B: Hepatitis B
C: Influenza
D: Epstein–Barr virus
E: Human immunodeficiency virus (HIV)
Answer: C

Question: What is the first step to confirm the presence of cancer after initial signs and symptoms are observed?
A: Surgery
B: Medical imaging
C: Biopsy
D: Radiation therapy
E: Palliative care
Answer: C

Question: How can the risk of developing certain cancers be reduced?
A: Smoking and maintaining a healthy weight
B: Limiting alcohol intake and consuming processed meat
C: Avoiding vaccinations and excessive sunlight
D: Eating plenty of vegetables and fruits
E: Engaging in excessive physical activity
Answer: B

Question: What is a controversial aspect of screening for breast cancer?
A: It is too expensive.
B: It is not effective.
C: It can lead to false positives.
D: It has no risks.
E: It is universally recommended.
Answer: C

Question: What is an essential part of cancer care that focuses on managing pain and symptoms?
A: Palliative care
B: Surgery
C: Radiation therapy
D: Chemotherapy
E: Targeted therapy
Answer: A

Question: In children under 15 at diagnosis, what is the average five-year survival rate for cancer in the developed world?
A: 40%
B: 50%
C: 60%
D: 70%
E: 80%
Answer: E

Question: What percentage of the global total economic costs did cancer represent as of 2010?
A: 0.16%
B: 1.16%
C: 10%
D: 50%
E: 100%
Answer: B

Question: What are the most common types of cancer in males?
A: Breast cancer, colorectal cancer, and lung cancer
B: Liver cancer, pancreatic cancer, and stomach cancer
C: Prostate cancer, lung cancer, and stomach cancer
D: Kidney cancer, bladder cancer, and skin cancer
E: Leukemia, lymphoma, and brain tumors
Answer: C
@
Radiation therapy or radiotherapy, often abbreviated RT, RTx, or XRT, is a treatment using ionizing radiation, generally provided as part of cancer therapy to either kill or control the growth of malignant cells. It is normally delivered by a linear particle accelerator. Radiation therapy may be curative in a number of types of cancer if they are localized to one area of the body, and have not spread to other parts. It may also be used as part of adjuvant therapy, to prevent tumor recurrence after surgery to remove a primary malignant tumor (for example, early stages of breast cancer). Radiation therapy is synergistic with chemotherapy, and has been used before, during, and after chemotherapy in susceptible cancers. The subspecialty of oncology concerned with radiotherapy is called radiation oncology. A physician who practices in this subspecialty is a radiation oncologist.

Radiation therapy is commonly applied to the cancerous tumor because of its ability to control cell growth. Ionizing radiation works by damaging the DNA of cancerous tissue leading to cellular death. To spare normal tissues (such as skin or organs which radiation must pass through to treat the tumor), shaped radiation beams are aimed from several angles of exposure to intersect at the tumor, providing a much larger absorbed dose there than in the surrounding healthy tissue. Besides the tumour itself, the radiation fields may also include the draining lymph nodes if they are clinically or radiologically involved with the tumor, or if there is thought to be a risk of subclinical malignant spread. It is necessary to include a margin of normal tissue around the tumor to allow for uncertainties in daily set-up and internal tumor motion. These uncertainties can be caused by internal movement (for example, respiration and bladder filling) and movement of external skin marks relative to the tumor position.

Radiation oncology is the medical specialty concerned with prescribing radiation, and is distinct from radiology, the use of radiation in medical imaging and diagnosis. Radiation may be prescribed by a radiation oncologist with intent to cure or for adjuvant therapy. It may also be used as palliative treatment (where cure is not possible and the aim is for local disease control or symptomatic relief) or as therapeutic treatment (where the therapy has survival benefit and can be curative).[1] It is also common to combine radiation therapy with surgery, chemotherapy, hormone therapy, immunotherapy or some mixture of the four. Most common cancer types can be treated with radiation therapy in some way.

The precise treatment intent (curative, adjuvant, neoadjuvant therapeutic, or palliative) will depend on the tumor type, location, and stage, as well as the general health of the patient. Total body irradiation (TBI) is a radiation therapy technique used to prepare the body to receive a bone marrow transplant. Brachytherapy, in which a radioactive source is placed inside or next to the area requiring treatment, is another form of radiation therapy that minimizes exposure to healthy tissue during procedures to treat cancers of the breast, prostate, and other organs. Radiation therapy has several applications in non-malignant conditions, such as the treatment of trigeminal neuralgia, acoustic neuromas, severe thyroid eye disease, pterygium, pigmented villonodular synovitis, and prevention of keloid scar growth, vascular restenosis, and heterotopic ossification.[1][2][3][4] The use of radiation therapy in non-malignant conditions is limited partly by worries about the risk of radiation-induced cancers.
$
10
Question: What is the medical specialty concerned with prescribing radiation for cancer treatment?
A: Radiology
B: Oncology
C: Radiation therapy
D: Radiation oncology
E: Radiologic oncology
Answer: D

Question: What is the primary mechanism by which ionizing radiation kills cancerous tissue?
A: It cools down the tissue.
B: It reduces blood flow to the tumor.
C: It promotes cellular growth.
D: It damages the DNA of the cancerous tissue.
E: It increases oxygen levels in the tumor.
Answer: D

Question: In radiation therapy, why are radiation beams aimed from multiple angles at the tumor?
A: To cool the tumor down
B: To increase blood flow to the tumor
C: To create a higher dose of radiation in the surrounding healthy tissue
D: To minimize the absorbed dose in the tumor
E: To provide a larger absorbed dose in the tumor while sparing normal tissues
Answer: E

Question: What is the term for the radiation fields that may include draining lymph nodes if they are involved with the tumor or if there is a risk of subclinical malignant spread?
A: Adjacent fields
B: External fields
C: Tumor-centric fields
D: Intraoperative fields
E: Intercellular fields
Answer: B

Question: What is the primary role of radiation therapy in cancer treatment when used with chemotherapy?
A: To cure cancer
B: To reduce tumor size
C: To control cell growth
D: To cool the body
E: To improve overall health
Answer: C

Question: In what way can radiation therapy be combined with other cancer treatments?
A: With acupuncture therapy
B: With homeopathic remedies
C: With herbal supplements
D: With massage therapy
E: With surgery, chemotherapy, hormone therapy, or immunotherapy
Answer: E

Question: What is the term for radiation therapy used when cure is not possible, and the aim is for local disease control or symptomatic relief?
A: Palliative treatment
B: Curative treatment
C: Adjuvant therapy
D: Neoadjuvant therapeutic treatment
E: Total body irradiation
Answer: A

Question: Which radiation therapy technique prepares the body to receive a bone marrow transplant?
A: Brachytherapy
B: Total body irradiation (TBI)
C: External beam therapy
D: Radiosurgery
E: Intraoperative radiation therapy
Answer: B

Question: Besides cancer treatment, what is one non-malignant condition for which radiation therapy is used?
A: Common cold
B: Influenza
C: Heart disease
D: Trigeminal neuralgia
E: Arthritis
Answer: D

Question: What limits the use of radiation therapy in non-malignant conditions?
A: Lack of trained personnel
B: High cost
C: Risk of radiation-induced cancers
D: Poor patient compliance
E: Limited availability of radiation machines
Answer: C
@
Keloid, also known as keloid disorder and keloidal scar,[1] is the formation of a type of scar which, depending on its maturity, is composed mainly of either type III (early) or type I (late) collagen. It is a result of an overgrowth of granulation tissue (collagen type 3) at the site of a healed skin injury which is then slowly replaced by collagen type 1. Keloids are firm, rubbery lesions or shiny, fibrous nodules, and can vary from pink to the color of the person's skin or red to dark brown in color. A keloid scar is benign and not contagious, but sometimes accompanied by severe itchiness, pain,[2] and changes in texture. In severe cases, it can affect movement of skin. In the United States keloid scars are seen 15 times more frequently in people of sub-Saharan African descent than in people of European descent.[citation needed] There is a higher tendency to develop a keloid among those with a family history of keloids and people between the ages of 10 and 30 years.[citation needed]

Keloids should not be confused with hypertrophic scars, which are raised scars that do not grow beyond the boundaries of the original wound.

Keloids expand in claw-like growths over normal skin.[3] They have the capability to hurt with a needle-like pain or to itch, the degree of sensation varying from person to person.[citation needed]

Keloids form within scar tissue. Collagen, used in wound repair, tends to overgrow in this area, sometimes producing a lump many times larger than that of the original scar. They can also range in color from pink to red.[4] Although they usually occur at the site of an injury, keloids can also arise spontaneously. They can occur at the site of a piercing and even from something as simple as a pimple or scratch. They can occur as a result of severe acne or chickenpox scarring, infection at a wound site, repeated trauma to an area, excessive skin tension during wound closure or a foreign body in a wound. Keloids can sometimes be sensitive to chlorine. If a keloid appears when someone is still growing, the keloid can continue to grow as well.[citation needed]
$
10
Question: What type of collagen mainly composes early-stage keloids?
A: Type III
B: Type I
C: Type II
D: Type IV
E: Type V
Answer: A

Question: What distinguishes hypertrophic scars from keloids?
A: Hypertrophic scars are contagious.
B: Hypertrophic scars are itchy.
C: Hypertrophic scars do not grow beyond the original wound.
D: Hypertrophic scars expand in claw-like growths.
E: Hypertrophic scars are pink to red in color.
Answer: C

Question: Which ethnic group in the United States is more prone to keloid scars?
A: People of European descent
B: People of Asian descent
C: People of Native American descent
D: People of sub-Saharan African descent
E: People of Hispanic descent
Answer: D

Question: What can keloids be sensitive to in some cases?
A: Sunlight
B: Water
C: Chlorine
D: Cold temperatures
E: Antibiotics
Answer: C

Question: What happens to the collagen composition in a mature keloid?
A: It remains mainly as type III collagen.
B: It transforms into type II collagen.
C: It is replaced by type I collagen.
D: It becomes type IV collagen.
E: It changes to type V collagen.
Answer: C

Question: At what age range do people have a higher tendency to develop keloids?
A: 1 to 10 years
B: 20 to 40 years
C: 30 to 50 years
D: 10 to 30 years
E: 50 to 70 years
Answer: D

Question: What are some potential symptoms of keloids?
A: Fever and chills
B: Swelling and numbness
C: Severe itchiness and pain
D: Muscle weakness and fatigue
E: Vision problems and headaches
Answer: C

Question: How do keloids typically expand over normal skin?
A: In flat layers
B: In circular patterns
C: In star-like shapes
D: In claw-like growths
E: In linear formations
Answer: D

Question: Besides injuries, what can trigger the formation of keloids?
A: Drinking alcohol
B: Smoking cigarettes
C: Excessive sun exposure
D: Wearing tight clothing
E: Eating spicy foods
Answer: D

Question: What role does collagen play in the formation of keloids?
A: Collagen is absent in keloids.
B: Collagen is the cause of keloid formation.
C: Collagen helps reduce the size of keloids.
D: Collagen overgrows in the scar tissue of keloids.
E: Collagen breaks down in mature keloids.
Answer: D
@
Medical imaging is the technique and process of imaging the interior of a body for clinical analysis and medical intervention, as well as visual representation of the function of some organs or tissues (physiology). Medical imaging seeks to reveal internal structures hidden by the skin and bones, as well as to diagnose and treat disease. Medical imaging also establishes a database of normal anatomy and physiology to make it possible to identify abnormalities. Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging.

Measurement and recording techniques that are not primarily designed to produce images, such as electroencephalography (EEG), magnetoencephalography (MEG), electrocardiography (ECG), and others, represent other technologies that produce data susceptible to representation as a parameter graph versus time or maps that contain data about the measurement locations. In a limited comparison, these technologies can be considered forms of medical imaging in another discipline of medical instrumentation.

As of 2010, 5 billion medical imaging studies had been conducted worldwide.[1] Radiation exposure from medical imaging in 2006 made up about 50% of total ionizing radiation exposure in the United States.[2] Medical imaging equipment is manufactured using technology from the semiconductor industry, including CMOS integrated circuit chips, power semiconductor devices, sensors such as image sensors (particularly CMOS sensors) and biosensors, and processors such as microcontrollers, microprocessors, digital signal processors, media processors and system-on-chip devices. As of 2015, annual shipments of medical imaging chips amount to 46 million units and $1.1 billion.[3]

Medical imaging is often perceived to designate the set of techniques that noninvasively produce images of the internal aspect of the body. In this restricted sense, medical imaging can be seen as the solution to mathematical inverse problems. This means that cause (the properties of living tissue) is inferred from effect (the observed signal). In the case of medical ultrasound, the probe consists of ultrasonic pressure waves and echoes that go inside the tissue to show the internal structure. In the case of projectional radiography, the tube uses X-ray radiation, which is absorbed at different rates by different tissue types such as bone, muscle, and fat.

The term "noninvasive" is used to denote a procedure where no instrument is introduced into a patient's body, which is the case for most imaging techniques used.
$
10
Question: What does medical imaging seek to reveal?
A: External structures of the body
B: Internal structures hidden by the skin and bones
C: The properties of living tissue
D: Abnormalities in blood circulation
E: The electrical activity of the brain
Answer: B

Question: Which of the following is NOT considered a form of medical imaging?
A: Electroencephalography (EEG)
B: Magnetoencephalography (MEG)
C: Electrocardiography (ECG)
D: Ultrasound imaging
E: Projectional radiography
Answer: C

Question: What percentage of total ionizing radiation exposure in the United States did medical imaging account for in 2006?
A: 10%
B: 25%
C: 50%
D: 75%
E: 90%
Answer: C

Question: What technology is often used in the manufacturing of medical imaging equipment?
A: Fiber optics
B: Vacuum tubes
C: Microcontrollers
D: Mechanical gears
E: Hydraulic systems
Answer: C

Question: How can medical imaging be perceived in a restricted sense?
A: As a solution to mathematical direct problems
B: As a way to introduce instruments into a patient's body
C: As a method to visualize external structures only
D: As a technique that uses invasive procedures
E: As the observation of patient's vital signs
Answer: A

Question: In medical ultrasound, what does the probe consist of?
A: X-ray radiation
B: Ultrasonic pressure waves and echoes
C: Magnetic resonance imaging
D: Electrical currents
E: Gamma rays
Answer: B

Question: What does the term "noninvasive" mean in the context of medical imaging?
A: The use of invasive instruments in imaging
B: The introduction of radiation into the body
C: The use of X-ray radiation
D: A procedure where no instrument is introduced into a patient's body
E: The administration of medication during imaging
Answer: D

Question: What is the main goal of medical imaging?
A: To replace surgery as a diagnostic tool
B: To observe patient's vital signs
C: To introduce instruments into the body for therapy
D: To create mathematical inverse problems
E: To diagnose and treat disease noninvasively
Answer: E

Question: Which technology is NOT mentioned as a component used in manufacturing medical imaging equipment?
A: Image sensors
B: Microprocessors
C: Fiber optics
D: Power semiconductor devices
E: System-on-chip devices
Answer: C

Question: What type of radiation is used in projectional radiography?
A: Ultrasonic waves
B: Infrared radiation
C: X-ray radiation
D: Gamma rays
E: Microwave radiation
Answer: C
@
A microprocessor is a computer processor where the data processing logic and control is included on a single integrated circuit (IC), or a small number of ICs. The microprocessor contains the arithmetic, logic, and control circuitry required to perform the functions of a computer's central processing unit (CPU). The IC is capable of interpreting and executing program instructions and performing arithmetic operations.[1] The microprocessor is a multipurpose, clock-driven, register-based, digital integrated circuit that accepts binary data as input, processes it according to instructions stored in its memory, and provides results (also in binary form) as output. Microprocessors contain both combinational logic and sequential digital logic, and operate on numbers and symbols represented in the binary number system.

The integration of a whole CPU onto a single or a few integrated circuits using Very-Large-Scale Integration (VLSI) greatly reduced the cost of processing power. Integrated circuit processors are produced in large numbers by highly automated metal–oxide–semiconductor (MOS) fabrication processes, resulting in a relatively low unit price. Single-chip processors increase reliability because there are fewer electrical connections that could fail. As microprocessor designs improve, the cost of manufacturing a chip (with smaller components built on a semiconductor chip the same size) generally stays the same according to Rock's law.

Before microprocessors, small computers had been built using racks of circuit boards with many medium- and small-scale integrated circuits, typically of TTL type. Microprocessors combined this into one or a few large-scale ICs. While there is disagreement over who deserves credit for the invention of the microprocessor, the first commercially available microprocessor was the Intel 4004, designed by Federico Faggin and introduced in 1971.[2]

Continued increases in microprocessor capacity have since rendered other forms of computers almost completely obsolete (see history of computing hardware), with one or more microprocessors used in everything from the smallest embedded systems and handheld devices to the largest mainframes and supercomputers.

A microprocessor is related but distinct from a system on a chip, microcontroller, and digital signal processor.

The complexity of an integrated circuit is bounded by physical limitations on the number of transistors that can be put onto one chip, the number of package terminations that can connect the processor to other parts of the system, the number of interconnections it is possible to make on the chip, and the heat that the chip can dissipate. Advancing technology makes more complex and powerful chips feasible to manufacture.

A minimal hypothetical microprocessor might include only an arithmetic logic unit (ALU), and a control logic section. The ALU performs addition, subtraction, and operations such as AND or OR. Each operation of the ALU sets one or more flags in a status register, which indicate the results of the last operation (zero value, negative number, overflow, or others). The control logic retrieves instruction codes from memory and initiates the sequence of operations required for the ALU to carry out the instruction. A single operation code might affect many individual data paths, registers, and other elements of the processor.
$
10
Question: What is the main function of a microprocessor?
A: Storing program instructions
B: Controlling input devices
C: Executing program instructions
D: Generating graphical output
E: Managing power supply
Answer: C

Question: What kind of data does a microprocessor typically accept as input?
A: Decimal numbers
B: Hexadecimal numbers
C: Binary data
D: Octal numbers
E: Floating-point numbers
Answer: C

Question: How have integrated circuit processors affected the cost of processing power?
A: They have significantly increased the cost.
B: They have had no impact on the cost.
C: They have slightly increased the cost.
D: They have greatly reduced the cost.
E: They have kept the cost constant.
Answer: D

Question: What was the first commercially available microprocessor?
A: Intel 8080
B: Intel 4004
C: Intel 8086
D: AMD Ryzen
E: Motorola 6800
Answer: B

Question: What concept in microprocessor development is mentioned as an explanation for the constant unit price of manufacturing chips with smaller components?
A: Moore's Law
B: Rock's Law
C: Turing's Law
D: Fibonacci's Law
E: Ohm's Law
Answer: B

Question: What does VLSI stand for in the context of microprocessor integration?
A: Very Large System Integration
B: Variable Logic and System Integration
C: Very Large Semiconductor Interconnect
D: Very Low-Speed Integration
E: Very-Large-Scale Integration
Answer: E

Question: What does ALU stand for in the context of microprocessors?
A: Arithmetic Logic Unit
B: Advanced Language Unit
C: Algorithmic Logic Unit
D: Analytical Logic Unit
E: Array Logic Unit
Answer: A

Question: What role does the control logic section play in a microprocessor?
A: It performs arithmetic operations.
B: It sets flags in a status register.
C: It retrieves instruction codes from memory.
D: It accepts binary data as input.
E: It dissipates heat from the chip.
Answer: C

Question: What does a status register in a microprocessor indicate?
A: The manufacturer of the chip
B: The temperature of the chip
C: The number of transistors on the chip
D: The results of the last operation
E: The power supply voltage
Answer: D

Question: What physical limitations bound the complexity of an integrated circuit?
A: The number of operations the ALU can perform
B: The number of package terminations
C: The size of the control logic section
D: The number of input devices
E: The type of interconnections on the chip
Answer: B
@
A graphics processing unit (GPU) is a specialized electronic circuit initially designed to accelerate computer graphics and image processing (either on a video card or embedded on the motherboards, mobile phones, personal computers, workstations, and game consoles). After their initial design, GPUs were found to be useful for non-graphic calculations involving embarrassingly parallel problems due to their parallel structure. Other non-graphical uses include the training of neural networks and cryptocurrency mining.
Modern GPUs use most of their transistors to do calculations related to 3D computer graphics. In addition to the 3D hardware, today's GPUs include basic 2D acceleration and framebuffer capabilities (usually with a VGA compatibility mode). Newer cards such as AMD/ATI HD5000–HD7000 lack dedicated 2D acceleration; it has to be emulated by 3D hardware. GPUs were initially used to accelerate the memory-intensive work of texture mapping and rendering polygons. They later added units[clarification needed] to accelerate geometric calculations such as the rotation and translation of vertices into different coordinate systems. Recent developments in GPUs include support for programmable shaders which can manipulate vertices and textures with many of the same operations that are supported by CPUs, oversampling and interpolation techniques to reduce aliasing, and very high-precision color spaces.

Several factors of GPU construction affect the performance of the card for real-time rendering, such as the size of the connector pathways in the semiconductor device fabrication, the clock signal frequency, and the number and size of various on-chip memory caches. Performance is also affected by the number of streaming multiprocessors (SM) for NVidia GPUs, or compute units (CU) for AMD GPUs, which describe the number of core on-silicon processor units within the GPU chip that perform the core calculations, typically working in parallel with other SM/CUs on the GPU. GPU performance is typically measured in floating point operations per second (FLOPS); GPUs in the 2010s and 2020s typically deliver performance measured in teraflops (TFLOPS). This is an estimated performance measure, as other factors can affect the actual display rate.[64]
$
10
Question: What is the primary purpose of a graphics processing unit (GPU)?
A: Accelerating computer graphics and image processing
B: Providing basic 2D acceleration for operating systems
C: Enhancing audio processing in computers
D: Assisting with network data encryption
E: Running virtual reality simulations
Answer: A

Question: In addition to graphics-related functions, what other tasks can modern GPUs perform effectively?
A: Audio processing
B: Network routing
C: Cryptocurrency mining
D: Word processing
E: Virtual machine emulation
Answer: C

Question: What kind of calculations do GPUs primarily handle in the context of 3D computer graphics?
A: Geometric calculations
B: Audio synthesis
C: Cryptographic operations
D: Text recognition
E: Network packet analysis
Answer: A

Question: What term describes the parallel structure of GPUs that makes them suitable for non-graphic calculations?
A: Embarrassingly sequential
B: Single-threaded
C: Sequential architecture
D: Embarrassingly parallel
E: Multithreaded
Answer: D

Question: What role does programmable shaders play in modern GPUs?
A: Enhancing 2D acceleration
B: Accelerating cryptographic operations
C: Manipulating vertices and textures
D: Rendering polygons
E: Providing VGA compatibility
Answer: C

Question: What performance metric is often used to measure GPU performance?
A: Gigahertz (GHz)
B: Floating point operations per second (FLOPS)
C: Pixels per second
D: Frames per second (FPS)
E: Bits per second (bps)
Answer: B

Question: What components of GPU construction can affect its real-time rendering performance?
A: Number of CPU cores
B: Size of the power supply
C: Clock signal frequency
D: Network bandwidth
E: Type of storage drive
Answer: C

Question: What does the abbreviation TFLOPS stand for in the context of GPU performance measurement?
A: Terabyte FLOP standard
B: Teraflop synchronization
C: Terrestrial floating point system
D: Teraflop supersampling
E: Teraflop per second
Answer: E

Question: What units are used to describe the number of core on-silicon processor units within a GPU chip?
A: Streaming multiprocessors (SM)
B: Clock cycles
C: Compute units (CU)
D: Instruction sets
E: Cache sizes
Answer: A

Question: What kind of memory caches can affect GPU performance?
A: Disk caches
B: CPU caches
C: Network caches
D: On-chip memory caches
E: RAM caches
Answer: D
@
Machine learning (ML) is an umbrella term for solving problems for which development of algorithms by human programmers would be cost-prohibitive, and instead the problems are solved by helping machines "discover" their "own" algorithms,[1] without needing to be explicitly told what to do by any human-developed algorithms.[2] Recently, generative artificial neural networks have been able to surpass results of many previous approaches.[3][4] Machine-learning approaches have been applied to large language models, computer vision, speech recognition, email filtering, agriculture and medicine, where it is too costly to develop algorithms to perform the needed tasks.[5][6]

The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis through unsupervised learning.[8][9]

ML is known in its application across business problems under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.

The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[10][11] The synonym self-teaching computers was also used in this time period.[12][13]

By the early 1960s an experimental "learning machine" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively "trained" by a human operator/teacher to recognize patterns and equipped with a "goof" button to cause it to re-evaluate incorrect decisions.[14] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[15] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[16] In 1981 a report was given on using teaching strategies so that a neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[17]

Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E."[18] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper "Computing Machinery and Intelligence", in which the question "Can machines think?" is replaced with the question "Can machines do what we (as thinking entities) can do?".[19]

Modern-day machine learning has two objectives, one is to classify data based on models which have been developed, the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.[20]
$
10
Question: What is the primary reason for using machine learning in solving problems?
A: Reducing the need for human programmers
B: Developing complex algorithms quickly
C: Eliminating the need for data
D: Enhancing human-developed algorithms
E: Reducing machine learning costs
Answer: A

Question: Which term is synonymous with machine learning in its early usage?
A: Reinforcement learning
B: Self-teaching computers
C: Predictive analytics
D: Cybertron
E: Data mining
Answer: B

Question: What mathematical foundations underlie machine learning?
A: Statistical analysis
B: Calculus and differential equations
C: Linear algebra and geometry
D: Mathematical optimization
E: Probability theory
Answer: D

Question: Who coined the term "machine learning" in 1959?
A: Alan Turing
B: Raytheon Company
C: Tom M. Mitchell
D: Arthur Samuel
E: Nilsson
Answer: D

Question: What is one of the objectives of modern-day machine learning?
A: Replacing human decision-making entirely
B: Generating new algorithms automatically
C: Training models to classify data
D: Eliminating all human involvement in computing
E: Developing complex mathematical theories
Answer: C

Question: What did Raytheon Company's "learning machine," Cybertron, analyze using rudimentary reinforcement learning in the 1960s?
A: Weather patterns
B: Stock market data
C: Sonar signals and speech patterns
D: Human behavior
E: Natural language
Answer: C

Question: What is data mining's focus within the context of machine learning?
A: Developing algorithms
B: Predictive analytics
C: Statistical analysis
D: Exploratory data analysis through unsupervised learning
E: Reinforcement learning
Answer: D

Question: How does machine learning relate to business problem-solving?
A: By providing a cost-effective way to develop algorithms
B: By replacing human decision-makers
C: By automating all decision-making processes
D: By eliminating the need for data analysis
E: By relying solely on computational statistics
Answer: A

Question: What purpose does computational statistics serve in machine learning?
A: Developing complex algorithms
B: Providing mathematical foundations
C: Replacing human programmers
D: Predicting future outcomes
E: Eliminating the need for data
Answer: B

Question: According to Tom M. Mitchell's definition, what does it mean for a computer program to "learn"?
A: It becomes conscious.
B: It improves its performance with experience.
C: It duplicates human thought processes.
D: It generates complex algorithms.
E: It relies on unsupervised learning.
Answer: B
@
A neural network can refer to either a neural circuit of biological neurons (sometimes also called a biological neural network), or a network of artificial neurons or nodes in the case of an artificial neural network.[1] Artificial neural networks are used for solving artificial intelligence (AI) problems; they model connections of biological neurons as weights between nodes. A positive weight reflects an excitatory connection, while negative values mean inhibitory connections. All inputs are modified by a weight and summed. This activity is referred to as a linear combination. Finally, an activation function controls the amplitude of the output. For example, an acceptable range of output is usually between 0 and 1, or it could be −1 and 1.

These artificial networks may be used for predictive modeling, adaptive control and applications where they can be trained via a dataset. Self-learning resulting from experience can occur within networks, which can derive conclusions from a complex and seemingly unrelated set of information.[2]

A biological neural network is composed of a group of chemically connected or functionally associated neurons. A single neuron may be connected to many other neurons and the total number of neurons and connections in a network may be extensive. Connections, called synapses, are usually formed from axons to dendrites, though dendrodendritic synapses[3] and other connections are possible. Apart from electrical signalling, there are other forms of signalling that arise from neurotransmitter diffusion.

Artificial intelligence, cognitive modelling, and neural networks are information processing paradigms inspired by how biological neural systems process data. Artificial intelligence and cognitive modelling try to simulate some properties of biological neural networks. In the artificial intelligence field, artificial neural networks have been applied successfully to speech recognition, image analysis and adaptive control, in order to construct software agents (in computer and video games) or autonomous robots.

Historically, digital computers evolved from the von Neumann model, and operate via the execution of explicit instructions via access to memory by a number of processors. On the other hand, the origins of neural networks are based on efforts to model information processing in biological systems. Unlike the von Neumann model, neural network computing does not separate memory and processing.

Neural network theory has served to identify better how the neurons in the brain function and provide the basis for efforts to create artificial intelligence.
$
10
Question: What is the role of an activation function in an artificial neural network?
A: To control the amplitude of the output
B: To connect biological neurons
C: To execute explicit instructions
D: To simulate neurotransmitter diffusion
E: To form synapses
Answer: A

Question: In artificial neural networks, what do positive weights between nodes represent?
A: Inhibitory connections
B: Amplitude control
C: Excitatory connections
D: Activation functions
E: Self-learning
Answer: C

Question: How do artificial neural networks model connections between nodes?
A: Through electrical signaling
B: By separating memory and processing
C: Using explicit instructions
D: With excitatory and inhibitory connections
E: Via access to memory
Answer: D

Question: What is the primary application of artificial neural networks in the field of artificial intelligence?
A: Constructing software agents for computer games
B: Creating autonomous robots
C: Modeling biological neural networks
D: Simulating neurotransmitter diffusion
E: Accessing memory in digital computers
Answer: A

Question: What do connections called synapses typically involve in biological neural networks?
A: Axons to dendrites
B: Amplitude control
C: Excitatory connections
D: Inhibitory connections
E: Access to memory
Answer: A

Question: Which type of signaling arises from neurotransmitter diffusion in biological neural networks?
A: Electrical signaling
B: Dendrodendritic signaling
C: Synaptic signaling
D: Axonal signaling
E: Linear combination signaling
Answer: C

Question: What is the primary difference between digital computers and neural network computing?
A: Digital computers use explicit instructions; neural network computing does not.
B: Digital computers simulate neurotransmitter diffusion; neural network computing does not.
C: Digital computers separate memory and processing; neural network computing does not.
D: Digital computers connect biological neurons; neural network computing does not.
E: Digital computers employ inhibitory connections; neural network computing does not.
Answer: C

Question: In an artificial neural network, what does self-learning result from?
A: The amplitude of the output
B: Excitatory connections
C: Dendrodendritic synapses
D: Experience and training via a dataset
E: Inhibitory connections
Answer: D

Question: What is the function of an artificial neural network in adaptive control?
A: To form synapses between nodes
B: To control neurotransmitter diffusion
C: To execute explicit instructions
D: To access memory in digital computers
E: To derive conclusions from complex information
Answer: E

Question: What paradigms are inspired by how biological neural systems process data?
A: Cognitive modeling and digital computing
B: Neural network theory and image analysis
C: Artificial intelligence and image recognition
D: Artificial intelligence, cognitive modeling, and neural networks
E: Accessing memory and neurotransmitter diffusion
Answer: D
@
The preliminary theoretical base for contemporary neural networks was independently proposed by Alexander Bain[4] (1873) and William James[5] (1890). In their work, both thoughts and body activity resulted from interactions among neurons within the brain.

For Bain,[4] every activity led to the firing of a certain set of neurons. When activities were repeated, the connections between those neurons strengthened. According to his theory, this repetition was what led to the formation of memory. The general scientific community at the time was skeptical of Bain's[4] theory because it required what appeared to be an inordinate number of neural connections within the brain. It is now apparent that the brain is exceedingly complex and that the same brain “wiring” can handle multiple problems and inputs.

James'[5] theory was similar to Bain's,[4] however, he suggested that memories and actions resulted from electrical currents flowing among the neurons in the brain. His model, by focusing on the flow of electrical currents, did not require individual neural connections for each memory or action.

C. S. Sherrington[7] (1898) conducted experiments to test James' theory. He ran electrical currents down the spinal cords of rats. However, instead of demonstrating an increase in electrical current as projected by James, Sherrington found that the electrical current strength decreased as the testing continued over time. Importantly, this work led to the discovery of the concept of habituation.

Wilhelm Lenz (1920) and Ernst Ising (1925) created and analyzed the Ising model[8] which is essentially a non-learning artificial recurrent neural network (RNN) consisting of neuron-like threshold elements.[9] In 1972, Shun'ichi Amari made this architecture adaptive.[10][9] His learning RNN was popularised by John Hopfield in 1982.[11] McCulloch and Pitts[12] (1943) also created a computational model for neural networks based on mathematics and algorithms. They called this model threshold logic. These early models paved the way for neural network research to split into two distinct approaches. One approach focused on biological processes in the brain and the other focused on the application of neural networks to artificial intelligence.

In the late 1940s psychologist Donald Hebb[13] created a hypothesis of learning based on the mechanism of neural plasticity that is now known as Hebbian learning. Hebbian learning is considered to be a 'typical' unsupervised learning rule and its later variants were early models for long term potentiation. These ideas started being applied to computational models in 1948 with Turing's B-type machines.

Farley and Clark[14] (1954) first used computational machines, then called calculators, to simulate a Hebbian network at MIT. Other neural network computational machines were created by Rochester, Holland, Habit, and Duda[15] (1956).

Frank Rosenblatt[16] (1958) created the perceptron, an algorithm for pattern recognition based on a two-layer learning computer network using simple addition and subtraction. With mathematical notation, Rosenblatt also described circuitry not in the basic perceptron, such as the exclusive-or circuit.

Some say that neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert[17] (1969). They discovered two key issues with the computational machines that processed neural networks. The first issue was that single-layer neural networks were incapable of processing the exclusive-or circuit. The second significant issue was that computers were not sophisticated enough to effectively handle the long run time required by large neural networks. However, by the time this book came out, methods for training multilayer perceptrons (MLPs) were already known. The first deep learning MLP was published by Alexey Grigorevich Ivakhnenko and Valentin Lapa in 1965.[18][19][9] The first deep learning MLP trained by stochastic gradient descent[20] was published in 1967 by Shun'ichi Amari.[21][9] In computer experiments conducted by Amari's student Saito, a five layer MLP with two modifiable layers learned useful internal representations to classify non-linearily separable pattern classes.[9]

Neural network research was boosted when computers achieved greater processing power. Also key in later advances was the backpropagation algorithm. It is an efficient application of the Leibniz chain rule (1673)[22] to networks of differentiable nodes.[9] It is also known as the reverse mode of automatic differentiation or reverse accumulation, due to Seppo Linnainmaa (1970).[23][24][25][26][9] The term "back-propagating errors" was introduced in 1962 by Frank Rosenblatt,[27][9] but he did not have an implementation of this procedure, although Henry J. Kelley had a continuous precursor of backpropagation[28] already in 1960 in the context of control theory.[9] In 1982, Paul Werbos applied backpropagation to MLPs in the way that has become standard.[29]

In the late 1970s to early 1980s, interest briefly emerged in theoretically investigating the Ising model by Wilhelm Lenz (1920) and Ernst Ising (1925)[8] in relation to Cayley tree topologies and large neural networks. In 1981, the Ising model was solved exactly by Peter Barth for the general case of closed Cayley trees (with loops) with an arbitrary branching ratio[30] and found to exhibit unusual phase transition behavior in its local-apex and long-range site-site correlations.[31][32]

The parallel distributed processing of the mid-1980s became popular under the name connectionism. The text by Rumelhart and McClelland[33] (1986) provided a full exposition on the use of connectionism in computers to simulate neural processes.

Neural networks, as used in artificial intelligence, have traditionally been viewed as simplified models of neural processing in the brain, even though the relation between this model and brain biological architecture is debated, as it is not clear to what degree artificial neural networks mirror brain function.[34]
$
10
Question: Who independently proposed the preliminary theoretical base for contemporary neural networks?
A: Alexander Bain and Charles Sherrington
B: William James and Donald Hebb
C: Wilhelm Lenz and Ernst Ising
D: C. S. Sherrington and John Hopfield
E: Alexander Bain and William James
Answer: E

Question: What is the theory behind Alexander Bain's idea of memory formation related to neural connections?
A: Electrical currents flow among neurons to form memories.
B: Repetition strengthens connections between neurons.
C: Every activity leads to the firing of specific neurons.
D: Memories result from the interaction of neurotransmitters.
E: Electrical currents decrease with repeated activities.
Answer: B

Question: What was the result of C. S. Sherrington's experiments testing William James' theory on electrical currents in neural networks?
A: The electrical current strength increased over time.
B: Electrical currents did not affect neural networks.
C: Electrical current strength decreased over time.
D: Habituation was not observed.
E: Sherrington focused on biological neurons.
Answer: C

Question: What did Frank Rosenblatt create in 1958 related to neural networks?
A: An algorithm for pattern recognition called the perceptron
B: A computational machine known as the calculator
C: A model for neural plasticity called Hebbian learning
D: The concept of backpropagation for neural networks
E: An efficient application of the Leibniz chain rule
Answer: A

Question: According to Marvin Minsky and Seymour Papert, what were the key issues with single-layer neural networks?
A: They were too powerful for computer systems.
B: They could not process the exclusive-or circuit.
C: They required individual neural connections for each memory.
D: They had excessive run times.
E: They were too complex for practical use.
Answer: B

Question: How was the term "back-propagating errors" introduced?
A: By Frank Rosenblatt in 1958
B: By Henry J. Kelley in 1960
C: By Paul Werbos in 1982
D: By Seppo Linnainmaa in 1970
E: By Alexey Grigorevich Ivakhnenko in 1965
Answer: A

Question: What did Peter Barth solve exactly in 1981 related to the Ising model?
A: The relation between artificial neural networks and brain architecture
B: The use of connectionism in computers
C: The application of backpropagation to MLPs
D: The behavior of local-apex and long-range correlations in closed Cayley trees
E: The mechanism of neural plasticity
Answer: D

Question: What is the term "connectionism" associated with in the mid-1980s?
A: The development of backpropagation
B: The use of artificial neural networks in AI
C: The investigation of the Ising model
D: The use of computational machines for Hebbian networks
E: The role of electrical currents in neural networks
Answer: B

Question: How have neural networks been traditionally viewed in artificial intelligence?
A: As accurate models of neural processing in the brain
B: As entirely unrelated to brain biological architecture
C: As the primary source of backpropagation algorithms
D: As the foundation of habituation theory
E: As a way to simulate neurotransmitter diffusion
Answer: A

Question: What was the primary focus of early neural network research?
A: Simulating neurotransmitter diffusion
B: Understanding the relation between AI and brain function
C: Investigating habituation theory
D: Modeling neural processing in the brain
E: Applying backpropagation to computational models
Answer: D
@
While initially research had been concerned mostly with the electrical characteristics of neurons, a particularly important part of the investigation in recent years has been the exploration of the role of neuromodulators such as dopamine, acetylcholine, and serotonin on behaviour and learning.[citation needed]

Biophysical models, such as BCM theory, have been important in understanding mechanisms for synaptic plasticity, and have had applications in both computer science and neuroscience. Research is ongoing in understanding the computational algorithms used in the brain, with some recent biological evidence for radial basis networks and neural backpropagation as mechanisms for processing data.[citation needed]

Computational devices have been created in CMOS for both biophysical simulation and neuromorphic computing. More recent efforts show promise for creating nanodevices for very large scale principal components analyses and convolution.[45] If successful, these efforts could usher in a new era of neural computing that is a step beyond digital computing,[46] because it depends on learning rather than programming and because it is fundamentally analog rather than digital even though the first instantiations may in fact be with CMOS digital devices.

Between 2009 and 2012, the recurrent neural networks and deep feedforward neural networks developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning.[47] For example, multi-dimensional long short term memory (LSTM)[48][49] won three competitions in connected handwriting recognition at the 2009 International Conference on Document Analysis and Recognition (ICDAR), without any prior knowledge about the three different languages to be learned.

Variants of the back-propagation algorithm, as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto, can be used to train deep, highly nonlinear neural architectures,[50] similar to the 1980 Neocognitron by Kunihiko Fukushima,[51] and the "standard architecture of vision",[52] inspired by the simple and complex cells identified by David H. Hubel and Torsten Wiesel in the primary visual cortex.

Radial basis function and wavelet networks have also been introduced. These can be shown to offer best approximation properties and have been applied in nonlinear system identification and classification applications.[37]

Deep learning feedforward networks alternate convolutional layers and max-pooling layers, topped by several pure classification layers. Fast GPU-based implementations of this approach have won several pattern recognition contests, including the IJCNN 2011 Traffic Sign Recognition Competition[53] and the ISBI 2012 Segmentation of Neuronal Structures in Electron Microscopy Stacks challenge.[54] Such neural networks also were the first artificial pattern recognizers to achieve human-competitive or even superhuman performance[55] on benchmarks such as traffic sign recognition (IJCNN 2012), or the MNIST handwritten digits problem of Yann LeCun and colleagues at NYU.

Analytical and computational techniques derived from statistical physics of disordered systems, can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks.[56]
$
10
Question: What has been a focus of research in recent years related to the role of neuromodulators?
A: Investigating the electrical characteristics of neurons
B: Exploring the impact of biophysical models
C: Understanding the computational algorithms used in the brain
D: Studying the effects of neuromodulators like dopamine and serotonin on behavior and learning
E: Developing computational devices for neuromorphic computing
Answer: D

Question: Which theory has been important in understanding mechanisms for synaptic plasticity?
A: CMOS theory
B: Backpropagation theory
C: BCM theory
D: Radial basis theory
E: Wavelet theory
Answer: C

Question: What are some potential applications of nanodevices in neural computing?
A: Computer science and neuroscience
B: Principal components analyses and convolution
C: Digital computing and programming
D: Synaptic plasticity and biophysical simulation
E: Neural backpropagation and biophysical simulation
Answer: B

Question: Which research group won multiple international competitions in pattern recognition and machine learning between 2009 and 2012?
A: The group led by David H. Hubel
B: The group led by Kunihiko Fukushima
C: The group led by Geoff Hinton
D: The group led by Yann LeCun
E: The group led by Jürgen Schmidhuber
Answer: E

Question: What type of neural networks have won pattern recognition contests and achieved human-competitive performance?
A: Pure classification networks
B: Deep feedforward networks
C: Recurrent neural networks
D: Radial basis function networks
E: Neocognitron networks
Answer: B

Question: What were the first artificial pattern recognizers to achieve human-competitive or superhuman performance?
A: Networks inspired by David H. Hubel and Torsten Wiesel
B: Wavelet networks
C: Networks developed by Geoff Hinton and colleagues
D: Neocognitron networks
E: Deep feedforward networks
Answer: E

Question: What has been extended to large-scale problems, including machine learning, using techniques from statistical physics of disordered systems?
A: CMOS technology
B: Biophysical simulation
C: The weight space of deep neural networks
D: Principal components analyses
E: Wavelet networks
Answer: C

Question: Which approach consists of alternating convolutional layers and max-pooling layers in neural networks?
A: Backpropagation approach
B: Radial basis approach
C: Deep learning feedforward approach
D: Unsupervised approach
E: Analytical approach
Answer: C

Question: What is a potential advantage of neural computing over digital computing?
A: Learning-based approach
B: Analog processing
C: Pure classification
D: Fast GPU-based implementation
E: Biophysical simulation
Answer: A

Question: Who identified simple and complex cells in the primary visual cortex and inspired the "standard architecture of vision"?
A: David H. Hubel and Torsten Wiesel
B: Kunihiko Fukushima
C: Geoff Hinton and colleagues
D: Yann LeCun
E: Jürgen Schmidhuber
Answer: A
@
In statistics, classification is the problem of identifying which of a set of categories (sub-populations) an observation (or observations) belongs to. Examples are assigning a given email to the "spam" or "non-spam" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.).

Often, the individual observations are analyzed into a set of quantifiable properties, known variously as explanatory variables or features. These properties may variously be categorical (e.g. "A", "B", "AB" or "O", for blood type), ordinal (e.g. "large", "medium" or "small"), integer-valued (e.g. the number of occurrences of a particular word in an email) or real-valued (e.g. a measurement of blood pressure). Other classifiers work by comparing observations to previous observations by means of a similarity or distance function.

An algorithm that implements classification, especially in a concrete implementation, is known as a classifier. The term "classifier" sometimes also refers to the mathematical function, implemented by a classification algorithm, that maps input data to a category.

Terminology across fields is quite varied. In statistics, where classification is often done with logistic regression or a similar procedure, the properties of observations are termed explanatory variables (or independent variables, regressors, etc.), and the categories to be predicted are known as outcomes, which are considered to be possible values of the dependent variable. In machine learning, the observations are often known as instances, the explanatory variables are termed features (grouped into a feature vector), and the possible categories to be predicted are classes. Other fields may use different terminology: e.g. in community ecology, the term "classification" normally refers to cluster analysis.

Classification and clustering are examples of the more general problem of pattern recognition, which is the assignment of some sort of output value to a given input value. Other examples are regression, which assigns a real-valued output to each input; sequence labeling, which assigns a class to each member of a sequence of values (for example, part of speech tagging, which assigns a part of speech to each word in an input sentence); parsing, which assigns a parse tree to an input sentence, describing the syntactic structure of the sentence; etc.

A common subclass of classification is probabilistic classification. Algorithms of this nature use statistical inference to find the best class for a given instance. Unlike other algorithms, which simply output a "best" class, probabilistic algorithms output a probability of the instance being a member of each of the possible classes. The best class is normally then selected as the one with the highest probability. However, such an algorithm has numerous advantages over non-probabilistic classifiers:

It can output a confidence value associated with its choice (in general, a classifier that can do this is known as a confidence-weighted classifier).
Correspondingly, it can abstain when its confidence of choosing any particular output is too low.
Because of the probabilities which are generated, probabilistic classifiers can be more effectively incorporated into larger machine-learning tasks, in a way that partially or completely avoids the problem of error propagation.
$
10
Question: What is the primary goal of classification in statistics and machine learning?
A: Identifying patterns
B: Assigning a real-valued output
C: Assigning a part of speech to words
D: Assigning categories to observations
E: Determining similarity between observations
Answer: D

Question: What term is often used to describe the quantifiable properties of individual observations?
A: Independent variables
B: Instances
C: Classes
D: Features
E: Outcomes
Answer: D

Question: In the context of classification algorithms, what does the term "classifier" refer to?
A: A mathematical function that maps input data to a category
B: A set of observations used for training
C: A specific type of explanatory variable
D: A similarity or distance function
E: A feature vector
Answer: A

Question: In the field of machine learning, what are observations often referred to as?
A: Explanatory variables
B: Instances
C: Features
D: Outcomes
E: Classes
Answer: B

Question: What is the term used in statistics for the possible values of the dependent variable that are to be predicted?
A: Explanatory variables
B: Instances
C: Features
D: Outcomes
E: Independent variables
Answer: D

Question: What broader problem does classification belong to?
A: Sequence labeling
B: Regression
C: Pattern recognition
D: Clustering
E: Parsing
Answer: C

Question: What do probabilistic classification algorithms output for each instance?
A: A parse tree
B: A confidence value
C: A real-valued output
D: A sequence of values
E: A similarity measure
Answer: B

Question: What is the advantage of probabilistic classifiers over non-probabilistic ones?
A: They generate parse trees.
B: They assign real-valued outputs.
C: They abstain when confidence is low.
D: They use distance functions.
E: They perform clustering.
Answer: C

Question: What is another term for probabilistic classifiers that can output a confidence value?
A: Explanatory classifiers
B: Confidence-weighted classifiers
C: Independent classifiers
D: Sequential classifiers
E: Similarity classifiers
Answer: B

Question: How can probabilistic classifiers be effectively incorporated into larger machine-learning tasks?
A: By using parse trees
B: By avoiding error propagation
C: By assigning real-valued outputs
D: By using distance functions
E: By performing sequence labeling
Answer: B
@
In statistics, the logistic model (or logit model) is a statistical model that models the probability of an event taking place by having the log-odds for the event be a linear combination of one or more independent variables. In regression analysis, logistic regression[1] (or logit regression) is estimating the parameters of a logistic model (the coefficients in the linear combination). Formally, in binary logistic regression there is a single binary dependent variable, coded by an indicator variable, where the two values are labeled "0" and "1", while the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value). The corresponding probability of the value labeled "1" can vary between 0 (certainly the value "0") and 1 (certainly the value "1"), hence the labeling;[2] the function that converts log-odds to probability is the logistic function, hence the name. The unit of measurement for the log-odds scale is called a logit, from logistic unit, hence the alternative names. See § Background and § Definition for formal mathematics, and § Example for a worked example.

Binary variables are widely used in statistics to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc. (see § Applications), and the logistic model has been the most commonly used model for binary regression since about 1970.[3] Binary variables can be generalized to categorical variables when there are more than two possible values (e.g. whether an image is of a cat, dog, lion, etc.), and the binary logistic regression generalized to multinomial logistic regression. If the multiple categories are ordered, one can use the ordinal logistic regression (for example the proportional odds ordinal logistic model[4]). See § Extensions for further extensions. The logistic regression model itself simply models probability of output in terms of input and does not perform statistical classification (it is not a classifier), though it can be used to make a classifier, for instance by choosing a cutoff value and classifying inputs with probability greater than the cutoff as one class, below the cutoff as the other; this is a common way to make a binary classifier.

Analogous linear models for binary variables with a different sigmoid function instead of the logistic function (to convert the linear combination to a probability) can also be used, most notably the probit model; see § Alternatives. The defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio. More abstractly, the logistic function is the natural parameter for the Bernoulli distribution, and in this sense is the "simplest" way to convert a real number to a probability. In particular, it maximizes entropy (minimizes added information), and in this sense makes the fewest assumptions of the data being modeled; see § Maximum entropy.

The parameters of a logistic regression are most commonly estimated by maximum-likelihood estimation (MLE). This does not have a closed-form expression, unlike linear least squares; see § Model fitting. Logistic regression by MLE plays a similarly basic role for binary or categorical responses as linear regression by ordinary least squares (OLS) plays for scalar responses: it is a simple, well-analyzed baseline model; see § Comparison with linear regression for discussion. The logistic regression as a general statistical model was originally developed and popularized primarily by Joseph Berkson,[5] beginning in Berkson (1944), where he coined "logit"; see § History.
$
10
Question: What is the logistic model primarily used for in statistics?
A: Modeling the probability of an event
B: Estimating linear combinations of variables
C: Performing statistical classification
D: Calculating odds ratios
E: Converting real numbers to probabilities
Answer: A

Question: In binary logistic regression, what type of dependent variable is typically used?
A: Ordinal variable
B: Continuous variable
C: Multinomial variable
D: Binary variable
E: Categorical variable
Answer: D

Question: What is the logistic function used for in logistic regression?
A: Estimating linear combinations
B: Converting linear combinations to probabilities
C: Maximizing entropy
D: Calculating odds ratios
E: Performing statistical classification
Answer: B

Question: What is the unit of measurement for the log-odds scale in logistic regression called?
A: Likelihood
B: Logit
C: Log-odds
D: Indicator
E: Sigmoid
Answer: B

Question: What does logistic regression maximize in terms of entropy?
A: Information added
B: Log-odds
C: Linear combinations
D: Odds ratios
E: Logit
Answer: A

Question: What is the logistic regression used to model in terms of probability?
A: Output in terms of input
B: Independent variables
C: Scalar responses
D: Ordinal variables
E: Continuous variables
Answer: A

Question: What is the common method for estimating the parameters of a logistic regression?
A: Linear least squares
B: Maximum-likelihood estimation (MLE)
C: Ordinary least squares (OLS)
D: Sigmoid function
E: Odds ratio estimation
Answer: B

Question: What role does logistic regression play in modeling binary or categorical responses?
A: Complex statistical analysis
B: Baseline model
C: Maximum entropy estimation
D: Probit estimation
E: Multinomial regression
Answer: B

Question: What was the term "logit" coined by Joseph Berkson used for in logistic regression?
A: Maximum entropy estimation
B: Odds ratio calculation
C: Logistic function
D: Likelihood estimation
E: Log-odds scale
Answer: E

Question: What alternative linear model uses a different sigmoid function instead of the logistic function in logistic regression?
A: Maximum-likelihood estimation (MLE)
B: Probit model
C: Linear least squares
D: Binary logistic regression
E: Multinomial logistic regression
Answer: B
@
Chemical engineering is an engineering field which deals with the study of operation and design of chemical plants as well as methods of improving production. Chemical engineers develop economical commercial processes to convert raw materials into useful products. Chemical engineering uses principles of chemistry, physics, mathematics, biology, and economics to efficiently use, produce, design, transport and transform energy and materials. The work of chemical engineers can range from the utilization of nanotechnology and nanomaterials in the laboratory to large-scale industrial processes that convert chemicals, raw materials, living cells, microorganisms, and energy into useful forms and products. Chemical engineers are involved in many aspects of plant design and operation, including safety and hazard assessments, process design and analysis, modeling, control engineering, chemical reaction engineering, nuclear engineering, biological engineering, construction specification, and operating instructions.

Chemical engineers typically hold a degree in Chemical Engineering or Process Engineering. Practicing engineers may have professional certification and be accredited members of a professional body. Such bodies include the Institution of Chemical Engineers (IChemE) or the American Institute of Chemical Engineers (AIChE). In India the equivalent body is the Indian Institute of Chemical Engineers (IIChE) which also conducts collaborative events with AIChE and ICheE. A degree in chemical engineering is directly linked with all of the other engineering disciplines, to various extents.

Plant design and construction
Chemical engineering design concerns the creation of plans, specifications, and economic analyses for pilot plants, new plants, or plant modifications. Design engineers often work in a consulting role, designing plants to meet clients' needs. Design is limited by several factors, including funding, government regulations, and safety standards. These constraints dictate a plant's choice of process, materials, and equipment.[23]

Plant construction is coordinated by project engineers and project managers,[24] depending on the size of the investment. A chemical engineer may do the job of project engineer full-time or part of the time, which requires additional training and job skills or act as a consultant to the project group. In the USA the education of chemical engineering graduates from the Baccalaureate programs accredited by ABET do not usually stress project engineering education, which can be obtained by specialized training, as electives, or from graduate programs. Project engineering jobs are some of the largest employers for chemical engineers.[25]
$
10
Question: What principles does chemical engineering utilize in its processes?
A: Physics and chemistry
B: Physics, mathematics, and biology
C: Chemistry, biology, and economics
D: Mathematics and economics
E: Biology and mathematics
Answer: B

Question: What does chemical engineering primarily aim to do with raw materials?
A: Transport them efficiently
B: Convert them into useful products
C: Store them safely
D: Analyze their composition
E: Separate them into components
Answer: B

Question: Which professional body accredits chemical engineers in the United States?
A: Institution of Chemical Engineers (IChemE)
B: American Institute of Chemical Engineers (AIChE)
C: Indian Institute of Chemical Engineers (IIChE)
D: European Federation of Chemical Engineering (EFCE)
E: Institution of Chemical Engineers Australia (IChemE Aus)
Answer: B

Question: What do design engineers often create plans and specifications for in chemical engineering?
A: Safety procedures
B: Pilot plants
C: Regulatory documents
D: Marketing campaigns
E: Research experiments
Answer: B

Question: What factors limit the design of chemical plants?
A: Government regulations and safety standards
B: Funding and marketing strategies
C: Marketing strategies and government regulations
D: Safety standards and technology limitations
E: Funding and government regulations
Answer: A

Question: What is the primary role of project engineers in chemical plant construction?
A: Designing plant modifications
B: Coordinating safety assessments
C: Managing financial aspects
D: Ensuring regulatory compliance
E: Overseeing the construction process
Answer: E

Question: Which of the following engineering disciplines is most closely related to chemical engineering?
A: Electrical engineering
B: Civil engineering
C: Mechanical engineering
D: Environmental engineering
E: Computer engineering
Answer: D

Question: What kind of training or education might be required for chemical engineers to become project engineers in the USA?
A: Additional training and job skills
B: A master's degree in engineering
C: Certification from AIChE
D: Graduate-level courses in project management
E: Specialized training in electrical engineering
Answer: A

Question: What professional organization conducts collaborative events with IIChE and AIChE in India?
A: Institution of Chemical Engineers (IChemE)
B: American Institute of Chemical Engineers (AIChE)
C: Indian Institute of Chemical Engineers (IIChE)
D: European Federation of Chemical Engineering (EFCE)
E: Institution of Chemical Engineers Australia (IChemE Aus)
Answer: C

Question: What type of projects are some of the largest employers for chemical engineers?
A: Research and development
B: Plant design and construction
C: Consulting and advisory
D: Regulatory compliance
E: Laboratory analysis
Answer: B
@
Crystallization is the process by which solid forms, where the atoms or molecules are highly organized into a structure known as a crystal. Some ways by which crystals form are precipitating from a solution, freezing, or more rarely deposition directly from a gas. Attributes of the resulting crystal depend largely on factors such as temperature, air pressure, and in the case of liquid crystals, time of fluid evaporation.

Crystallization occurs in two major steps. The first is nucleation, the appearance of a crystalline phase from either a supercooled liquid or a supersaturated solvent. The second step is known as crystal growth, which is the increase in the size of particles and leads to a crystal state. An important feature of this step is that loose particles form layers at the crystal's surface and lodge themselves into open inconsistencies such as pores, cracks, etc.

The majority of minerals and organic molecules crystallize easily, and the resulting crystals are generally of good quality, i.e. without visible defects. However, larger biochemical particles, like proteins, are often difficult to crystallize. The ease with which molecules will crystallize strongly depends on the intensity of either atomic forces (in the case of mineral substances), intermolecular forces (organic and biochemical substances) or intramolecular forces (biochemical substances).

Crystallization is also a chemical solid–liquid separation technique, in which mass transfer of a solute from the liquid solution to a pure solid crystalline phase occurs. In chemical engineering, crystallization occurs in a crystallizer. Crystallization is therefore related to precipitation, although the result is not amorphous or disordered, but a crystal.

The crystallization process consists of two major events, nucleation and crystal growth which are driven by thermodynamic properties as well as chemical properties. Nucleation is the step where the solute molecules or atoms dispersed in the solvent start to gather into clusters, on the microscopic scale (elevating solute concentration in a small region), that become stable under the current operating conditions. These stable clusters constitute the nuclei. Therefore, the clusters need to reach a critical size in order to become stable nuclei. Such critical size is dictated by many different factors (temperature, supersaturation, etc.). It is at the stage of nucleation that the atoms or molecules arrange in a defined and periodic manner that defines the crystal structure – note that "crystal structure" is a special term that refers to the relative arrangement of the atoms or molecules, not the macroscopic properties of the crystal (size and shape), although those are a result of the internal crystal structure.

The crystal growth is the subsequent size increase of the nuclei that succeed in achieving the critical cluster size. Crystal growth is a dynamic process occurring in equilibrium where solute molecules or atoms precipitate out of solution, and dissolve back into solution. Supersaturation is one of the driving forces of crystallization, as the solubility of a species is an equilibrium process quantified by Ksp. Depending upon the conditions, either nucleation or growth may be predominant over the other, dictating crystal size.

Many compounds have the ability to crystallize with some having different crystal structures, a phenomenon called polymorphism. Certain polymorphs may be metastable, meaning that although it is not in thermodynamic equilibrium, it is kinetically stable and requires some input of energy to initiate a transformation to the equilibrium phase. Each polymorph is in fact a different thermodynamic solid state and crystal polymorphs of the same compound exhibit different physical properties, such as dissolution rate, shape (angles between facets and facet growth rates), melting point, etc. For this reason, polymorphism is of major importance in industrial manufacture of crystalline products. Additionally, crystal phases can sometimes be interconverted by varying factors such as temperature, such as in the transformation of anatase to rutile phases of titanium dioxide.
$
10
Question: What is the first major step in the crystallization process?
A: Crystal growth
B: Deposition from a gas
C: Nucleation
D: Solvent evaporation
E: Precipitation from a solution
Answer: C

Question: What factors influence the attributes of resulting crystals in the crystallization process?
A: Time of fluid evaporation and atmospheric pressure
B: Temperature, air pressure, and time of fluid evaporation
C: Pressure and solute concentration
D: Temperature and solute concentration
E: Temperature and atmospheric pressure
Answer: B

Question: In chemical engineering, what is crystallization often related to?
A: Evaporation
B: Precipitation
C: Deposition
D: Filtration
E: Dissolution
Answer: B

Question: What are the two major events in the crystallization process?
A: Evaporation and nucleation
B: Deposition and crystal growth
C: Nucleation and evaporation
D: Nucleation and crystal growth
E: Deposition and dissolution
Answer: D

Question: What is the term for the step in crystallization where solute molecules or atoms start to gather into clusters that become stable nuclei?
A: Precipitation
B: Deposition
C: Supersaturation
D: Nucleation
E: Crystallization
Answer: D

Question: What is the critical size that clusters must reach in order to become stable nuclei in the nucleation step of crystallization?
A: It is determined by the solubility of the solute.
B: It is dictated by temperature and pressure.
C: It is the size at which the crystal becomes visible to the naked eye.
D: It is always the same for all solutes.
E: It is not relevant to the nucleation process.
Answer: A

Question: What is the subsequent size increase of nuclei that have reached the critical cluster size called?
A: Precipitation
B: Nucleation
C: Deposition
D: Crystal growth
E: Supersaturation
Answer: D

Question: What phenomenon occurs when different crystal structures of the same compound exhibit different physical properties?
A: Nucleation
B: Polymorphism
C: Deposition
D: Supersaturation
E: Crystallization
Answer: B

Question: What is the term for a crystal phase that is not in thermodynamic equilibrium but is kinetically stable?
A: Polymorph
B: Equilibrium state
C: Nucleus
D: Supersaturated solution
E: Amorphous phase
Answer: A

Question: What can interconvert crystal phases of the same compound?
A: Temperature
B: Polymorphism
C: Nucleation
D: Deposition
E: Supersaturation
Answer: A
@
In an aqueous solution, precipitation is the process of transforming a dissolved substance into an insoluble solid from a supersaturated solution.[1][2] The solid formed is called the precipitate.[3] In case of an inorganic chemical reaction leading to precipitation, the chemical reagent causing the solid to form is called the precipitant.[4]

The clear liquid remaining above the precipitated or the centrifuged solid phase is also called the supernate or supernatant.

The notion of precipitation can also be extended to other domains of chemistry (organic chemistry and biochemistry) and even be applied to the solid phases (e.g. metallurgy and alloys) when solid impurities segregate from a solid phase.

The precipitation of a compound may occur when its concentration exceeds its solubility. This can be due to temperature changes, solvent evaporation, or by mixing solvents. Precipitation occurs more rapidly from a strongly supersaturated solution.

The formation of a precipitate can be caused by a chemical reaction. When a barium chloride solution reacts with sulphuric acid, a white precipitate of barium sulfate is formed. When a potassium iodide solution reacts with a lead(II) nitrate solution, a yellow precipitate of lead(II) iodide is formed.

An important stage of the precipitation process is the onset of nucleation. The creation of a solid particle implies the formation of an interface with the solution. This involves energy changes depending on the dissolution reaction free energy (endothermic or exothermic process accompanied by an entropy increase) and the relative surface energy developed between the solid and the solution. If energy changes are not favorable, or without suitable nucleation sites, no precipitation occurs and the solution remain supersaturated.
$
10
Question: What is the term for the clear liquid that remains above the precipitated solid phase?
A: Precipitate
B: Supernate
C: Solvent
D: Supersaturation
E: Nucleation
Answer: B

Question: What is the process of transforming a dissolved substance into an insoluble solid from a supersaturated solution called?
A: Solubility
B: Precipitation
C: Nucleation
D: Supernatant
E: Supersaturation
Answer: B

Question: What is the solid formed in the process of precipitation called?
A: Solvent
B: Supersaturation
C: Nucleation
D: Precipitate
E: Supernate
Answer: D

Question: Under what conditions does precipitation occur more rapidly?
A: In a dilute solution
B: In a strongly supersaturated solution
C: At high temperatures
D: In the absence of chemical reactions
E: With increased agitation
Answer: B

Question: What is the chemical reagent causing the solid to form in a precipitation reaction called?
A: Nucleation
B: Supersaturation
C: Precipitate
D: Solvent
E: Precipitant
Answer: E

Question: When can precipitation of a compound occur?
A: When the solution is cooled
B: When the solution is well-mixed
C: When the solubility of the compound decreases
D: When the solution is heated
E: When the solution remains supersaturated
Answer: E

Question: What happens at the onset of nucleation during the precipitation process?
A: The solubility of the compound increases.
B: A chemical reaction occurs.
C: The solid forms an interface with the solution.
D: Energy changes become unfavorable.
E: The solution becomes more diluted.
Answer: C

Question: In a reaction between barium chloride and sulfuric acid, what type of precipitate is formed?
A: White precipitate of barium sulfate
B: Yellow precipitate of lead(II) iodide
C: Green precipitate of copper oxide
D: Red precipitate of iron chloride
E: Blue precipitate of zinc carbonate
Answer: A

Question: What term is used to describe the process when solid impurities segregate from a solid phase?
A: Supersaturation
B: Nucleation
C: Precipitation
D: Solubility
E: Segregation
Answer: E

Question: What factors can cause precipitation to occur in a solution?
A: Mixing solvents
B: Decreasing the solubility of a compound
C: Increasing the temperature
D: Adding more solvent
E: Diluting the solution
Answer: A
@
Ion implantation is a low-temperature process by which ions of one element are accelerated into a solid target, thereby changing the physical, chemical, or electrical properties of the target. Ion implantation is used in semiconductor device fabrication and in metal finishing, as well as in materials science research. The ions can alter the elemental composition of the target (if the ions differ in composition from the target) if they stop and remain in the target. Ion implantation also causes chemical and physical changes when the ions impinge on the target at high energy. The crystal structure of the target can be damaged or even destroyed by the energetic collision cascades, and ions of sufficiently high energy (tens of MeV) can cause nuclear transmutation.

Ion implantation equipment typically consists of an ion source, where ions of the desired element are produced, an accelerator, where the ions are electrostatically accelerated to a high energy or using radiofrequency, and a target chamber, where the ions impinge on a target, which is the material to be implanted. Thus ion implantation is a special case of particle radiation. Each ion is typically a single atom or molecule, and thus the actual amount of material implanted in the target is the integral over time of the ion current. This amount is called the dose. The currents supplied by implants are typically small (micro-amperes), and thus the dose which can be implanted in a reasonable amount of time is small. Therefore, ion implantation finds application in cases where the amount of chemical change required is small.

Typical ion energies are in the range of 10 to 500 keV (1,600 to 80,000 aJ). Energies in the range 1 to 10 keV (160 to 1,600 aJ) can be used, but result in a penetration of only a few nanometers or less. Energies lower than this result in very little damage to the target, and fall under the designation ion beam deposition. Higher energies can also be used: accelerators capable of 5 MeV (800,000 aJ) are common. However, there is often great structural damage to the target, and because the depth distribution is broad (Bragg peak), the net composition change at any point in the target will be small.

The energy of the ions, as well as the ion species and the composition of the target determine the depth of penetration of the ions in the solid: A monoenergetic ion beam will generally have a broad depth distribution. The average penetration depth is called the range of the ions. Under typical circumstances ion ranges will be between 10 nanometers and 1 micrometer. Thus, ion implantation is especially useful in cases where the chemical or structural change is desired to be near the surface of the target. Ions gradually lose their energy as they travel through the solid, both from occasional collisions with target atoms (which cause abrupt energy transfers) and from a mild drag from overlap of electron orbitals, which is a continuous process. The loss of ion energy in the target is called stopping and can be simulated with the binary collision approximation method.

Accelerator systems for ion implantation are generally classified into medium current (ion beam currents between 10 μA and ~2 mA), high current (ion beam currents up to ~30 mA), high energy (ion energies above 200 keV and up to 10 MeV), and very high dose (efficient implant of dose greater than 1016 ions/cm2).[1]
$
10
Question: What process involves accelerating ions into a solid target to change its properties?
A: Electromagnetism
B: Ionization
C: Ion implantation
D: Nuclear fusion
E: Thermodynamics
Answer: C

Question: In which field is ion implantation commonly used?
A: Meteorology
B: Agriculture
C: Semiconductor device fabrication
D: Geology
E: Botany
Answer: C

Question: What happens when ions of high energy impinge on a solid target in ion implantation?
A: They create a vacuum.
B: They cause nuclear transmutation.
C: They create new elements.
D: They generate heat.
E: They produce visible light.
Answer: B

Question: What is the integral over time of the ion current called in ion implantation?
A: Energy
B: Dose
C: Acceleration
D: Current density
E: Charge
Answer: B

Question: At what typical range of energies are ion implantation processes conducted?
A: 1 to 10 keV
B: 10 to 500 keV
C: 1 to 5 MeV
D: 10 MeV to 100 MeV
E: 100 to 500 MeV
Answer: B

Question: What determines the depth of penetration of ions in a solid during ion implantation?
A: The temperature of the target
B: The humidity of the environment
C: The ion current density
D: The energy of the ions, ion species, and target composition
E: The color of the ions
Answer: D

Question: What is the average penetration depth of ions in the solid called?
A: Surface range
B: Penetration radius
C: Ion depth
D: Range of the ions
E: Target thickness
Answer: D

Question: What is the continuous loss of ion energy in a solid called during ion implantation?
A: Drag
B: Halt
C: Bragg peak
D: Impact
E: Stopping
Answer: E

Question: In ion implantation, what is the classification for ion beam currents between 10 μA and ~2 mA?
A: High current
B: Low energy
C: Medium current
D: Very high dose
E: Low dose
Answer: C

Question: What are accelerator systems for ion implantation with ion beam currents up to ~30 mA classified as?
A: Very high dose
B: High energy
C: High current
D: Low current
E: Medium current
Answer: A
@
Organic chemistry is a subdiscipline within chemistry involving the scientific study of the structure, properties, and reactions of organic compounds and organic materials, i.e., matter in its various forms that contain carbon atoms.[1] Study of structure determines their structural formula. Study of properties includes physical and chemical properties, and evaluation of chemical reactivity to understand their behavior. The study of organic reactions includes the chemical synthesis of natural products, drugs, and polymers, and study of individual organic molecules in the laboratory and via theoretical (in silico) study.

The range of chemicals studied in organic chemistry includes hydrocarbons (compounds containing only carbon and hydrogen) as well as compounds based on carbon, but also containing other elements,[1][2][3] especially oxygen, nitrogen, sulfur, phosphorus (included in many biochemicals) and the halogens. Organometallic chemistry is the study of compounds containing carbon–metal bonds.

In addition, contemporary research focuses on organic chemistry involving other organometallics including the lanthanides, but especially the transition metals zinc, copper, palladium, nickel, cobalt, titanium and chromium.

Organic compounds form the basis of all earthly life and constitute the majority of known chemicals. The bonding patterns of carbon, with its valence of four—formal single, double, and triple bonds, plus structures with delocalized electrons—make the array of organic compounds structurally diverse, and their range of applications enormous. They form the basis of, or are constituents of, many commercial products including pharmaceuticals; petrochemicals and agrichemicals, and products made from them including lubricants, solvents; plastics; fuels and explosives. The study of organic chemistry overlaps organometallic chemistry and biochemistry, but also with medicinal chemistry, polymer chemistry, and materials science.[1]
$
10
Question: What does organic chemistry primarily study?
A: Inorganic materials
B: Compounds with carbon atoms
C: Hydrogen-based compounds
D: Geological formations
E: Metallic compounds
Answer: B

Question: What is the primary focus of organometallic chemistry?
A: Hydrocarbon compounds
B: Compounds with carbon–metal bonds
C: Compounds containing nitrogen
D: Geological formations
E: Metallic compounds
Answer: B

Question: Which elements, in addition to carbon, are commonly found in organic compounds?
A: Sodium and potassium
B: Oxygen, nitrogen, sulfur, phosphorus, and halogens
C: Aluminum and silicon
D: Iron and magnesium
E: Chlorine and bromine
Answer: B

Question: What is the valence of carbon, which contributes to the structural diversity of organic compounds?
A: 1
B: 2
C: 3
D: 4
E: 5
Answer: D

Question: What is the study of compounds containing carbon–metal bonds called?
A: Hydrocarbon chemistry
B: Organosulfur chemistry
C: Organometallic chemistry
D: Organonitrogen chemistry
E: Organophosphorus chemistry
Answer: C

Question: Which metals are commonly studied in contemporary organic chemistry, especially in organometallic chemistry?
A: Sodium and potassium
B: Lanthanides and actinides
C: Transition metals like zinc, copper, and palladium
D: Alkaline earth metals like calcium and magnesium
E: Noble gases like helium and neon
Answer: C

Question: What is the main contribution of organic compounds to commercial products?
A: Creating electronics
B: Manufacturing textiles
C: Producing food
D: Serving as building materials
E: Forming the basis of various products like pharmaceuticals and plastics
Answer: E

Question: What makes the bonding patterns of carbon in organic compounds diverse?
A: Valence of four and the presence of single, double, and triple bonds
B: Valence of six and the presence of single, double, and triple bonds
C: Valence of two and the presence of single, double, and triple bonds
D: Valence of four and the absence of double bonds
E: Valence of four and the presence of only single bonds
Answer: A

Question: What scientific disciplines does the study of organic chemistry overlap with?
A: Geography and geology
B: Botany and horticulture
C: Medicinal chemistry and polymer chemistry
D: Cosmology and astronomy
E: Oceanography and marine biology
Answer: C

Question: What are some products made from organic compounds?
A: Rockets and jet engines
B: Building materials and construction equipment
C: Perfumes and cosmetics
D: Radios and televisions
E: Lubricants, solvents, plastics, fuels, and explosives
Answer: E
@
The history of chemistry represents a time span from ancient history to the present. By 1000 BC, civilizations used technologies that would eventually form the basis of the various branches of chemistry. Examples include the discovery of fire, extracting metals from ores, making pottery and glazes, fermenting beer and wine, extracting chemicals from plants for medicine and perfume, rendering fat into soap, making glass, and making alloys like bronze.

The protoscience of chemistry, alchemy, was unsuccessful in explaining the nature of matter and its transformations. However, by performing experiments and recording the results, alchemists set the stage for modern chemistry.

The history of chemistry is intertwined with the history of thermodynamics, especially through the work of Willard Gibbs.[1]

Arguably the first chemical reaction used in a controlled manner was fire. However, for millennia fire was seen simply as a mystical force that could transform one substance into another (burning wood, or boiling water) while producing heat and light. Fire affected many aspects of early societies. These ranged from the simplest facets of everyday life, such as cooking and habitat heating and lighting, to more advanced uses, such as making pottery and bricks and melting of metals to make tools. It was fire that led to the discovery of glass and the purification of metals; this was followed by the rise of metallurgy.[2]

A 100,000-year-old ochre-processing workshop was found at Blombos Cave in South Africa. It indicates that early humans had an elementary knowledge of chemistry. Paintings drawn by early humans consisting of early humans mixing animal blood with other liquids found on cave walls also indicate a small knowledge of chemistry.[3][4]

The earliest recorded metal employed by humans seems to be gold, which can be found free or "native". Small amounts of natural gold have been found in Spanish caves used during the late Paleolithic period, around 40,000 BC.[5]

Silver, copper, tin and meteoric iron can also be found native, allowing a limited amount of metalworking in ancient cultures.[6] Egyptian weapons made from meteoric iron in about 3000 BC were highly prized as "daggers from Heaven".[7]

During the early stages of metallurgy, methods of purification of metals were sought, and gold, known in ancient Egypt as early as 2900 BC, became a precious metal.
$
10
Question: Which civilization is known to have used fire in various ways, including for cooking, making pottery, and melting metals?
A: Mesopotamia
B: Ancient Egypt
C: South Africa
D: Paleolithic societies
E: Ancient China
Answer: D

Question: What is the name of the protoscience that preceded modern chemistry and involved experimental work by alchemists?
A: Geology
B: Alchemy
C: Thermodynamics
D: Metallurgy
E: Physics
Answer: B

Question: What early metal, found in Spanish caves from the late Paleolithic period, was one of the first metals used by humans?
A: Copper
B: Silver
C: Iron
D: Gold
E: Tin
Answer: D

Question: What significant discovery resulted from the use of fire in early societies?
A: Invention of writing systems
B: Creation of complex tools
C: Development of advanced mathematics
D: Discovery of glass and purification of metals
E: Introduction of agriculture
Answer: D

Question: What 100,000-year-old archaeological find in South Africa suggests that early humans had some knowledge of chemistry?
A: Ochre-processing workshop
B: Cave paintings
C: Advanced tools
D: Pottery kilns
E: Metal artifacts
Answer: A

Question: Which of the following elements was NOT found in native form and required some form of extraction or purification by ancient cultures?
A: Gold
B: Silver
C: Copper
D: Tin
E: Meteoric iron
Answer: C

Question: What metals could be found in their native form, allowing limited metalworking by ancient cultures?
A: Copper and iron
B: Silver and gold
C: Tin and lead
D: Iron and meteoric iron
E: Aluminum and zinc
Answer: B

Question: What work by Willard Gibbs is mentioned in relation to the history of chemistry?
A: Discovery of fire
B: Development of advanced mathematics
C: Study of thermodynamics
D: Invention of glass
E: Alchemical experiments
Answer: C

Question: In which civilization were weapons made from meteoric iron considered highly valuable?
A: Ancient Greece
B: Mesopotamia
C: Ancient Egypt
D: China
E: India
Answer: C

Question: What cave wall paintings indicate an early knowledge of chemistry among early humans?
A: Depictions of animal hunting
B: Images of early tools
C: Drawings of celestial bodies
D: Paintings of chemical reactions
E: Mixtures of animal blood with other liquids
Answer: E
@
The control of fire by early humans was a critical technology enabling the evolution of humans. Fire provided a source of warmth and lighting, protection from predators (especially at night), a way to create more advanced hunting tools, and a method for cooking food. These cultural advances allowed human geographic dispersal, cultural innovations, and changes to diet and behavior. Additionally, creating fire allowed human activity to continue into the dark and colder hours of the evening.

Claims for the earliest definitive evidence of control of fire by a member of Homo range from 1.7 to 2.0 million years ago (Mya).[1] Evidence for the "microscopic traces of wood ash" as controlled use of fire by Homo erectus, beginning roughly 1 million years ago, has wide scholarly support.[2][3] Some of the earliest known traces of controlled fire were found at the Daughters of Jacob Bridge, Israel, and dated to ~790,000 years ago.[4] At the site, archaeologists also found the oldest likely evidence of controlled use of fire to cook food ~780,000 years ago.[5][6] However, some studies suggest cooking started ~1.8 million years ago.[7][8][clarification needed]

Flint blades burned in fires roughly 300,000 years ago were found near fossils of early but not entirely modern Homo sapiens in Morocco.[9] Fire was used regularly and systematically by early modern humans to heat treat silcrete stone to increase its flake-ability for the purpose of toolmaking approximately 164,000 years ago at the South African site of Pinnacle Point.[10] Evidence of widespread control of fire by anatomically modern humans dates to approximately 125,000 years ago.[11]

The use and control of fire was a gradual process proceeding through more than one stage. One was a change in habitat, from dense forest, where wildfires were common, to savanna (mixed grass/woodland) where wildfires were of higher intensity.[citation needed][clarification needed] Such a change may have occurred about 3 million years ago, when the savanna expanded in East Africa due to cooler and drier climate.[12][13]

The next stage involved interaction with burned landscapes and foraging in the wake of wildfires, as observed in various wild animals.[12][13] In the African savanna, animals that preferentially forage in recently burned areas include savanna chimpanzees (a variety of Pan troglodytes verus),[12][14] vervet monkeys (Cercopithecus aethiops)[15] and a variety of birds, some of which also hunt insects and small vertebrates in the wake of grass fires.[14][16]

The next step would be to make some use of residual hot spots that occur in the wake of wildfires. For example, foods found in the wake of wildfires tend to be either burned or undercooked. This might have provided incentives to place undercooked foods on a hotspot or to pull food out of the fire if it was in danger of getting burned. This would require familiarity with fire and its behavior.[17][13]

An early step in the control of fire would have been transporting it from burned to unburned areas and lighting them on fire, providing advantages in food acquisition.[13] Maintaining a fire over an extended period of time, as for a season (such as the dry season), may have led to the development of base campsites. Building a hearth or other fire enclosure such as a circle of stones would have been a later development.[18] The ability to make fire, generally with a friction device with hardwood rubbing against softwood (as in a bow drill), was a later development.[12]

Each of these stages could occur at different intensities, ranging from occasional or "opportunistic" to "habitual" to "obligate" (unable to survive without it).[13][18]
$
10
Question: What advantage did fire provide to early humans regarding hunting tools?
A: It made hunting tools more durable
B: It allowed for the creation of more advanced hunting tools
C: It made hunting tools easier to carry
D: It improved the accuracy of hunting tools
E: It made hunting tools unnecessary
Answer: B

Question: What is the earliest known evidence of controlled use of fire by Homo erectus?
A: Approximately 1.7 million years ago
B: Approximately 790,000 years ago
C: Approximately 164,000 years ago
D: Approximately 1.8 million years ago
E: Approximately 125,000 years ago
Answer: B

Question: What major environmental change is thought to have influenced the use of fire by early humans?
A: Expansion of forests
B: Increase in rainfall
C: Cooling and drying of the climate
D: Decrease in grasslands
E: Rising sea levels
Answer: C

Question: How did early modern humans use fire to modify silcrete stone?
A: They used it for cooking
B: They used it to increase its flake-ability for toolmaking
C: They used it as a source of light
D: They used it to build shelter
E: They used it for religious ceremonies
Answer: B

Question: Which type of animals forage in recently burned areas in the African savanna?
A: Hippos
B: Gazelles
C: Giraffes
D: Savanna chimpanzees
E: Elephants
Answer: D

Question: What might have been an early incentive for early humans to control and use fire when it came to food?
A: To increase the nutritional value of food
B: To make food last longer
C: To prevent food from getting burned
D: To enhance the taste of food
E: To make food easier to carry
Answer: C

Question: What is the term for the practice of transporting fire from burned to unburned areas?
A: Fire maintaining
B: Firelighting
C: Fire enclosure
D: Fire transportation
E: Fire carrying
Answer: E

Question: What device was later developed to make fire, involving hardwood rubbing against softwood?
A: Firestarter
B: Flint and steel
C: Fire enclosure
D: Fire circle
E: Bow drill
Answer: E

Question: What term is used to describe the stage where early humans made use of residual hot spots left by wildfires?
A: Fire maintenance
B: Fire advancement
C: Fire creation
D: Fire opportunism
E: Fire transport
Answer: D

Question: What type of fire enclosure, such as a circle of stones, is mentioned as a later development in the control of fire?
A: Fire pit
B: Fire hearth
C: Fire shrine
D: Fire altar
E: Fire camp
Answer: B
@
In paleoanthropology, the hunting hypothesis is the hypothesis that human evolution was primarily influenced by the activity of hunting for relatively large and fast animals, and that the activity of hunting distinguished human ancestors from other hominins.

While it is undisputed that early humans were hunters, the importance of this fact for the final steps in the emergence of the genus Homo out of earlier australopithecines, with its bipedalism and production of stone tools (from about 2.5 million years ago), and eventually also control of fire (from about 1.5 million years ago), is emphasized in the "hunting hypothesis", and de-emphasized in scenarios that stress the omnivore status of humans as their recipe for success, and social interaction, including mating behaviour as essential in the emergence of language and culture.

Advocates of the hunting hypothesis tend to believe that tool use and toolmaking essential to effective hunting were an extremely important part of human evolution, and trace the origin of language and religion to a hunting context.

As societal evidence David Buss cites that modern tribal population deploy hunting as their primary way of acquiring food.[1] The Aka pygmies in the Central African Republic spend 56% of their quest for nourishment hunting, 27% gathering, and 17% processing food. Additionally, the !Kung in Botswana retain 40% of their calories from hunting and this percentage varies from 20% to 90% depending on the season.[2] For physical evidence Buss first looks to the guts of humans and apes. The human gut consists mainly of the small intestines, which are responsible for the rapid breakdown of proteins and absorption of nutrients. The ape's gut is primarily colon, which indicates a vegetarian diet. This structural difference supports the hunting hypothesis in being an evolutionary branching point between modern humans and modern primates. Buss also cites human teeth in that fossilized human teeth have a thin enamel coating with very little heavy wear and tear that would result from a plant diet. The absence of thick enamel also indicates that historically humans have maintained a meat-heavy diet.[2] Buss notes that the bones of animals human ancestors killed found at Olduvai Gorge have cut marks at strategic points on the bones that indicate tool usage and provide evidence for ancestral butchers.[2]

Women are theorized to have participated in hunting, either on their own or as a collective group effort.[3] It is suggested that in the past, women targeted low but guaranteed food, whereas men targeted higher risk higher reward food.[4] The Gathering Hypothesis is a view that states men provided the evolution of the current human through hunting while women contributed via gathering.[5] Though criticized by many, it provides clues that both hunting and gathering were patterns of acquiring food and resources.
$
10
Question: What does the "hunting hypothesis" primarily emphasize as a distinguishing factor in human evolution?
A: Bipedalism
B: Production of stone tools
C: Omnivore status
D: Control of fire
E: Social interaction
Answer: B

Question: According to advocates of the hunting hypothesis, what is the origin of language and religion often traced to?
A: Gathering
B: Mating behavior
C: Tool use and toolmaking for hunting
D: Social interaction
E: Omnivore status
Answer: C

Question: What structural difference between the human gut and the ape's gut supports the hunting hypothesis?
A: Thin enamel coating in human teeth
B: Thick enamel coating in human teeth
C: Rapid breakdown of proteins in the human small intestines
D: Colon in the ape's gut
E: Absorption of nutrients in the human colon
Answer: C

Question: How do modern tribal populations, cited as societal evidence by the hunting hypothesis, primarily acquire food?
A: Gathering
B: Processing food
C: Mating behavior
D: Hunting
E: Social interaction
Answer: D

Question: What is the Gathering Hypothesis's view regarding the roles of men and women in early human food acquisition?
A: Women provided the evolution through hunting, while men contributed via gathering.
B: Men provided both hunting and gathering as patterns of acquiring food and resources.
C: Women targeted higher risk higher reward food, while men targeted low but guaranteed food.
D: Men and women had identical roles in food acquisition.
E: Men focused on gathering, while women focused on hunting.
Answer: A

Question: What is the significance of cut marks found on animal bones at Olduvai Gorge in the context of the hunting hypothesis?
A: Evidence of early tool usage by human ancestors
B: Evidence of plant-based diets of human ancestors
C: Evidence of ritualistic practices among early humans
D: Evidence of plant gathering by early humans
E: Evidence of collaborative hunting by early humans
Answer: A

Question: What percentage of calories do the !Kung in Botswana retain from hunting during different seasons?
A: 20%
B: 27%
C: 40%
D: 56%
E: 90%
Answer: B

Question: According to the hunting hypothesis, what were women theorized to have participated in?
A: Social interaction
B: Gathering only
C: Hunting only
D: Toolmaking for hunting
E: Higher risk higher reward hunting
Answer: C

Question: What aspect of early human food acquisition does the Gathering Hypothesis suggest?
A: Men and women had identical roles in hunting and gathering.
B: Men targeted higher risk higher reward food, while women gathered.
C: Women targeted low but guaranteed food, while men gathered.
D: Men provided the evolution of the current human through gathering, while women contributed via hunting.
E: Both hunting and gathering were patterns of acquiring food and resources.
Answer: E

Question: How do fossilized human teeth provide evidence for the hunting hypothesis?
A: They show signs of extensive wear and tear from a plant-based diet.
B: They have a thick enamel coating.
C: They have cut marks indicating tool usage.
D: They have a thin enamel coating and show little wear and tear.
E: They demonstrate a preference for gathering.
Answer: D
@
Bipedalism is a form of terrestrial locomotion where a tetrapod moves by means of its two rear (or lower) limbs or legs. An animal or machine that usually moves in a bipedal manner is known as a biped /ˈbaɪpɛd/, meaning 'two feet' (from Latin bis 'double' and pes 'foot'). Types of bipedal movement include walking or running (a bipedal gait) and hopping.

Several groups of modern species are habitual bipeds whose normal method of locomotion is two-legged. In the Triassic period some groups of archosaurs (a group that includes crocodiles and dinosaurs) developed bipedalism; among the dinosaurs, all the early forms and many later groups were habitual or exclusive bipeds; the birds are members of a clade of exclusively bipedal dinosaurs, the theropods. Within mammals, habitual bipedalism has evolved multiple times, with the macropods, kangaroo rats and mice, springhare,[4] hopping mice, pangolins and hominin apes (australopithecines, including humans) as well as various other extinct groups evolving the trait independently. A larger number of modern species intermittently or briefly use a bipedal gait. Several lizard species move bipedally when running, usually to escape from threats. Many primate and bear species will adopt a bipedal gait in order to reach food or explore their environment, though there are a few cases where they walk on their hind limbs only. Several arboreal primate species, such as gibbons and indriids, exclusively walk on two legs during the brief periods they spend on the ground. Many animals rear up on their hind legs while fighting or copulating. Some animals commonly stand on their hind legs to reach food, keep watch, threaten a competitor or predator, or pose in courtship, but do not move bipedally.

Zoologists often label behaviors, including bipedalism, as "facultative" (i.e. optional) or "obligate" (the animal has no reasonable alternative). Even this distinction is not completely clear-cut — for example, humans other than infants normally walk and run in biped fashion, but almost all can crawl on hands and knees when necessary. There are even reports of humans who normally walk on all fours with their feet but not their knees on the ground, but these cases are a result of conditions such as Uner Tan syndrome — very rare genetic neurological disorders rather than normal behavior.[10] Even if one ignores exceptions caused by some kind of injury or illness, there are many unclear cases, including the fact that "normal" humans can crawl on hands and knees. This article therefore avoids the terms "facultative" and "obligate", and focuses on the range of styles of locomotion normally used by various groups of animals. Normal humans may be considered "obligate" bipeds because the alternatives are very uncomfortable and usually only resorted to when walking is impossible.
$
10
Question: What is the term used for an animal or machine that usually moves in a bipedal manner?
A: Quadruped
B: Octoped
C: Biped
D: Hexaped
E: Triped
Answer: C

Question: Which clade of dinosaurs includes exclusively bipedal dinosaurs?
A: Sauropods
B: Theropods
C: Ornithopods
D: Ankylosaurs
E: Stegosaurs
Answer: B

Question: Which modern species is an example of a habitual biped within mammals?
A: Kangaroo
B: Cheetah
C: Crocodile
D: Turtle
E: Octopus
Answer: A

Question: What term is used for behaviors that animals can choose to perform or not, including bipedalism?
A: Facultative
B: Mandatory
C: Involuntary
D: Compulsory
E: Obligatory
Answer: A

Question: What is the common bipedal behavior observed in many primate and bear species when they need to reach food or explore their environment?
A: Hopping
B: Skipping
C: Crawling
D: Galloping
E: Walking
Answer: E

Question: In what circumstances do some animals commonly stand on their hind legs?
A: To crawl efficiently
B: To escape from threats
C: To reach food
D: To keep watch
E: To engage in courtship
Answer: C

Question: What term is used for behaviors that animals have no reasonable alternative for, such as bipedalism in humans?
A: Facultative
B: Conditional
C: Optional
D: Obligate
E: Selective
Answer: D

Question: What is the term for an animal that moves by means of its two rear or lower limbs?
A: Quadruped
B: Hexaped
C: Octoped
D: Biped
E: Triped
Answer: D

Question: What is the name of the genetic neurological disorder that can lead to humans walking on all fours with their feet but not their knees on the ground?
A: Uner Tan syndrome
B: Bipedal disorder
C: Crawl-on-all-fours syndrome
D: Quadrupedal syndrome
E: Octopedal disorder
Answer: A

Question: What does the article suggest about "normal" humans in terms of bipedalism?
A: They are obligate bipeds.
B: They are facultative bipeds.
C: They are quadrupeds.
D: They are obligate quadrupeds.
E: They are facultative quadrupeds.
Answer: A
@
In nutrition, biology, and chemistry, fat usually means any ester of fatty acids, or a mixture of such compounds, most commonly those that occur in living beings or in food.[1]

The term often refers specifically to triglycerides (triple esters of glycerol), that are the main components of vegetable oils and of fatty tissue in animals;[2] or, even more narrowly, to triglycerides that are solid or semisolid at room temperature, thus excluding oils. The term may also be used more broadly as a synonym of lipid—any substance of biological relevance, composed of carbon, hydrogen, or oxygen, that is insoluble in water but soluble in non-polar solvents.[1] In this sense, besides the triglycerides, the term would include several other types of compounds like mono- and diglycerides, phospholipids (such as lecithin), sterols (such as cholesterol), waxes (such as beeswax),[1] and free fatty acids, which are usually present in human diet in smaller amounts.[2]

Fats are one of the three main macronutrient groups in human diet, along with carbohydrates and proteins,[1][3] and the main components of common food products like milk, butter, tallow, lard, salt pork, and cooking oils. They are a major and dense source of food energy for many animals and play important structural and metabolic functions, in most living beings, including energy storage, waterproofing, and thermal insulation.[4] The human body can produce the fat it requires from other food ingredients, except for a few essential fatty acids that must be included in the diet. Dietary fats are also the carriers of some flavor and aroma ingredients and vitamins that are not water-soluble.[2]
$
10
Question: What is the main function of fats in the human body?
A: Energy storage
B: Water purification
C: Blood circulation
D: Muscle building
E: Oxygen transport
Answer: A

Question: Which macronutrient group includes fats along with carbohydrates and proteins?
A: Micronutrients
B: Minerals
C: Vitamins
D: Fiber
E: Macronutrients
Answer: E

Question: What is the term for triglycerides that are solid or semisolid at room temperature?
A: Oils
B: Sterols
C: Phospholipids
D: Waxes
E: Liquids
Answer: D

Question: Besides triglycerides, what other types of compounds are included in the term "fat"?
A: Carbohydrates
B: Proteins
C: Minerals
D: Mono- and diglycerides
E: Vitamins
Answer: D

Question: What is the term for any substance of biological relevance, composed of carbon, hydrogen, or oxygen, that is insoluble in water but soluble in non-polar solvents?
A: Lipid
B: Carbohydrate
C: Protein
D: Fiber
E: Mineral
Answer: A

Question: Which essential fatty acids must be included in the diet since the human body cannot produce them?
A: Mono- and diglycerides
B: Phospholipids
C: Sterols
D: Triglycerides
E: Essential fatty acids
Answer: E

Question: What are fats the main components of in common food products?
A: Vegetables
B: Fruits
C: Dairy products
D: Grains
E: Nuts
Answer: C

Question: In addition to providing energy, what other function do fats serve in living beings?
A: Blood purification
B: Muscle development
C: Waterproofing
D: Vision enhancement
E: Bone strengthening
Answer: C

Question: What role do dietary fats play in relation to flavor, aroma ingredients, and certain vitamins?
A: They enhance the sense of taste.
B: They eliminate odors.
C: They increase water solubility.
D: They are carriers of these substances.
E: They inhibit vitamin absorption.
Answer: D

Question: Which of the following is not one of the three main macronutrient groups in human diet?
A: Carbohydrates
B: Fats
C: Proteins
D: Vitamins
E: Macronutrients
Answer: D
@
Dependent and independent variables are variables in mathematical modeling, statistical modeling and experimental sciences. Dependent variables are studied under the supposition or demand that they depend, by some law or rule (e.g., by a mathematical function), on the values of other variables. Independent variables, in turn, are not seen as depending on any other variable in the scope of the experiment in question.[a] In this sense, some common independent variables are time, space, density, mass, fluid flow rate,[1][2] and previous values of some observed value of interest (e.g. human population size) to predict future values (the dependent variable).[3]

Of the two, it is always the dependent variable whose variation is being studied, by altering inputs, also known as regressors in a statistical context. In an experiment, any variable that can be attributed a value without attributing a value to any other variable is called an independent variable. Models and experiments test the effects that the independent variables have on the dependent variables. Sometimes, even if their influence is not of direct interest, independent variables may be included for other reasons, such as to account for their potential confounding effect.

In mathematics, a function is a rule for taking an input (in the simplest case, a number or set of numbers)[5] and providing an output (which may also be a number).[5] A symbol that stands for an arbitrary input is called an independent variable, while a symbol that stands for an arbitrary output is called a dependent variable.[6] The most common symbol for the input is x, and the most common symbol for the output is y; the function itself is commonly written y = f(x).[6][7]

It is possible to have multiple independent variables or multiple dependent variables. For instance, in multivariable calculus, one often encounters functions of the form z = f(x,y), where z is a dependent variable and x and y are independent variables.[8] Functions with multiple outputs are often referred to as vector-valued functions.
$
10
Question: What is the role of independent variables in mathematical modeling?
A: They are variables whose variation is being studied.
B: They are variables that depend on other variables.
C: They are variables that account for potential confounding effects.
D: They are variables that predict future values.
E: They are variables that stand for arbitrary inputs.
Answer: E

Question: In an experiment, what is the term for any variable that can be attributed a value without attributing a value to any other variable?
A: Dependent variable
B: Independent variable
C: Regressor
D: Mathematical function
E: Confounding variable
Answer: B

Question: Which type of variable is studied under the assumption that it depends on the values of other variables?
A: Dependent variable
B: Independent variable
C: Regressor
D: Mathematical function
E: Confounding variable
Answer: A

Question: What is the most common symbol for an independent variable in mathematics?
A: x
B: y
C: z
D: f
E: Multivariable
Answer: A

Question: In mathematical functions, what does the symbol y typically represent?
A: An independent variable
B: A dependent variable
C: A regressor
D: A confounding variable
E: A mathematical rule
Answer: B

Question: What is the term for functions with multiple independent variables or multiple dependent variables?
A: Vector-valued functions
B: Regressor functions
C: Confounding functions
D: Mathematical functions
E: Scalar functions
Answer: A

Question: Which type of variable is altered in experiments to test its effects on other variables?
A: Dependent variable
B: Independent variable
C: Regressor
D: Mathematical function
E: Confounding variable
Answer: A

Question: In multivariable calculus, what type of functions often have the form z = f(x,y)?
A: Scalar-valued functions
B: Vector-valued functions
C: Dependent functions
D: Independent functions
E: Confounding functions
Answer: B

Question: What is the term for symbols that stand for arbitrary outputs in mathematical functions?
A: Independent variables
B: Dependent variables
C: Regressors
D: Confounding variables
E: Mathematical rules
Answer: B

Question: What do models and experiments aim to test regarding independent and dependent variables?
A: The potential confounding effects of independent variables.
B: The mathematical functions that describe their relationship.
C: The effects that independent variables have on dependent variables.
D: The total number of variables in a system.
E: The values of all variables in an experiment.
Answer: C
@
In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon.[1] Choosing informative, discriminating and independent features is a crucial element of effective algorithms in pattern recognition, classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition. The concept of "feature" is related to that of explanatory variable used in statistical techniques such as linear regression.

In feature engineering, two types of features are commonly used: numerical and categorical.

Numerical features are continuous values that can be measured on a scale. Examples of numerical features include age, height, weight, and income. Numerical features can be used in machine learning algorithms directly.[2]

Categorical features are discrete values that can be grouped into categories. Examples of categorical features include gender, color, and zip code. Categorical features typically need to be converted to numerical features before they can be used in machine learning algorithms. This can be done using a variety of techniques, such as one-hot encoding, label encoding, and ordinal encoding.

The type of feature that is used in feature engineering depends on the specific machine learning algorithm that is being used. Some machine learning algorithms, such as decision trees, can handle both numerical and categorical features. Other machine learning algorithms, such as linear regression, can only handle numerical features.

A numeric feature can be conveniently described by a feature vector. One way to achieve binary classification is using a linear predictor function (related to the perceptron) with a feature vector as input. The method consists of calculating the scalar product between the feature vector and a vector of weights, qualifying those observations whose result exceeds a threshold.

Algorithms for classification from a feature vector include nearest neighbor classification, neural networks, and statistical techniques such as Bayesian approaches.
$
10
Question: What is the primary purpose of features in machine learning and pattern recognition?
A: To provide structural information about a phenomenon.
B: To convert categorical features to numerical features.
C: To explain the concept of explanatory variables.
D: To represent individual measurable properties of a phenomenon.
E: To calculate scalar products in linear regression.
Answer: D

Question: What are numerical features in the context of feature engineering?
A: Discrete values that can be grouped into categories.
B: Continuous values that can be measured on a scale.
C: Structural features like strings and graphs.
D: Features used exclusively in linear regression.
E: Features that require one-hot encoding.
Answer: B

Question: How are categorical features typically prepared for use in machine learning algorithms?
A: By converting them into structural features.
B: By converting them into numerical features.
C: By converting them into continuous values.
D: By converting them into discrete values.
E: By applying label encoding.
Answer: B

Question: Which machine learning algorithms can handle both numerical and categorical features?
A: Decision trees
B: Linear regression
C: Nearest neighbor classification
D: Neural networks
E: Bayesian approaches
Answer: A

Question: What is a feature vector?
A: A vector of weights used in linear regression.
B: A vector of categorical features.
C: A vector of structural features.
D: A vector of continuous values.
E: A vector of weights used in Bayesian approaches.
Answer: D

Question: How is binary classification achieved using a linear predictor function?
A: By using one-hot encoding.
B: By applying label encoding.
C: By calculating the scalar product between a feature vector and a vector of weights.
D: By using structural features.
E: By converting categorical features into numerical features.
Answer: C

Question: Which type of machine learning algorithms can only handle numerical features?
A: Decision trees
B: Nearest neighbor classification
C: Neural networks
D: Linear regression
E: Bayesian approaches
Answer: D

Question: What do algorithms for classification from a feature vector include?
A: Feature engineering techniques
B: Label encoding methods
C: Syntactic pattern recognition
D: Nearest neighbor classification
E: Bayesian approaches
Answer: D

Question: What is the primary goal of feature engineering?
A: To convert all features into structural features.
B: To convert categorical features into discrete values.
C: To explain the concept of nearest neighbor classification.
D: To choose informative, discriminating, and independent features.
E: To calculate scalar products in Bayesian approaches.
Answer: D

Question: Which machine learning technique involves calculating the scalar product between a feature vector and a vector of weights?
A: Nearest neighbor classification
B: Bayesian approaches
C: Decision trees
D: Perceptron
E: Syntactic pattern recognition
Answer: D
@
In natural language processing (NLP), a word embedding is a representation of a word. The embedding is used in text analysis. Typically, the representation is a real-valued vector that encodes the meaning of the word in such a way that words that are closer in the vector space are expected to be similar in meaning.[1] Word embeddings can be obtained using language modeling and feature learning techniques, where words or phrases from the vocabulary are mapped to vectors of real numbers.

Methods to generate this mapping include neural networks,[2] dimensionality reduction on the word co-occurrence matrix,[3][4][5] probabilistic models,[6] explainable knowledge base method,[7] and explicit representation in terms of the context in which words appear.[8]

Word and phrase embeddings, when used as the underlying input representation, have been shown to boost the performance in NLP tasks such as syntactic parsing[9] and sentiment analysis.[10]

Historically, one of the main limitations of static word embeddings or word vector space models is that words with multiple meanings are conflated into a single representation (a single vector in the semantic space). In other words, polysemy and homonymy are not handled properly. For example, in the sentence "The club I tried yesterday was great!", it is not clear if the term club is related to the word sense of a club sandwich, clubhouse, golf club, or any other sense that club might have. The necessity to accommodate multiple meanings per word in different vectors (multi-sense embeddings) is the motivation for several contributions in NLP to split single-sense embeddings into multi-sense ones.[30][31]

Most approaches that produce multi-sense embeddings can be divided into two main categories for their word sense representation, i.e., unsupervised and knowledge-based.[32] Based on word2vec skip-gram, Multi-Sense Skip-Gram (MSSG)[33] performs word-sense discrimination and embedding simultaneously, improving its training time, while assuming a specific number of senses for each word. In the Non-Parametric Multi-Sense Skip-Gram (NP-MSSG) this number can vary depending on each word. Combining the prior knowledge of lexical databases (e.g., WordNet, ConceptNet, BabelNet), word embeddings and word sense disambiguation, Most Suitable Sense Annotation (MSSA)[34] labels word-senses through an unsupervised and knowledge-based approach, considering a word's context in a pre-defined sliding window. Once the words are disambiguated, they can be used in a standard word embeddings technique, so multi-sense embeddings are produced. MSSA architecture allows the disambiguation and annotation process to be performed recurrently in a self-improving manner.[35]

The use of multi-sense embeddings is known to improve performance in several NLP tasks, such as part-of-speech tagging, semantic relation identification, semantic relatedness, named entity recognition and sentiment analysis.[36][37]

As of the late 2010s, contextually-meaningful embeddings such as ELMo and BERT have been developed.[38] Unlike static word embeddings, these embeddings are at the token-level, in that each occurrence of a word has its own embedding. These embeddings better reflect the multi-sense nature of words, because occurrences of a word in similar contexts are situated in similar regions of BERT’s embedding space.[39][40]
$
10
Question: What is the primary purpose of word embeddings in natural language processing?
A: To represent words using real-valued vectors.
B: To count the frequency of words in a text.
C: To identify the grammatical structure of sentences.
D: To convert text into binary representations.
E: To generate random words from a vocabulary.
Answer: A

Question: What is the expected relationship between words in a word embedding vector space?
A: Words with similar meanings are closer in the vector space.
B: Words with similar meanings are farther apart in the vector space.
C: Words with similar meanings have the same vector.
D: Word embeddings cannot represent word meanings.
E: Word embeddings are unrelated to word meanings.
Answer: A

Question: Which techniques can be used to generate word embeddings?
A: Neural networks and dimensionality reduction on the word co-occurrence matrix.
B: Binary encoding and probabilistic models.
C: Regular expressions and explicit representation.
D: Knowledge base methods and syntactic parsing.
E: Sentiment analysis and explainable knowledge base methods.
Answer: A

Question: How have word and phrase embeddings been shown to impact natural language processing tasks?
A: They have no impact on NLP tasks.
B: They are only relevant for syntactic parsing tasks.
C: They improve performance in various NLP tasks.
D: They make NLP tasks more challenging.
E: They are only useful for sentiment analysis.
Answer: C

Question: What is one of the main limitations of static word embeddings?
A: They are too large in dimensionality.
B: They cannot represent word meanings.
C: They handle polysemy and homonymy effectively.
D: They conflate words with multiple meanings.
E: They are only useful for sentiment analysis.
Answer: D

Question: What is the motivation for developing multi-sense embeddings in natural language processing?
A: To reduce the dimensionality of word embeddings.
B: To handle polysemy and homonymy effectively.
C: To create embeddings for phrases rather than words.
D: To eliminate the need for word embeddings.
E: To make NLP tasks more challenging.
Answer: B

Question: How are most approaches that produce multi-sense embeddings categorized based on word sense representation?
A: As neural networks or probabilistic models.
B: As unsupervised or knowledge-based methods.
C: As binary encoding or regular expressions.
D: As syntactic parsing or semantic relatedness.
E: As structural features or continuous values.
Answer: B

Question: What is the purpose of the Most Suitable Sense Annotation (MSSA) architecture in NLP?
A: To create binary word embeddings.
B: To count the frequency of words in a text.
C: To perform sentiment analysis.
D: To label word senses through an unsupervised and knowledge-based approach.
E: To improve the dimensionality of word embeddings.
Answer: D

Question: How do contextually-meaningful embeddings like ELMo and BERT differ from static word embeddings?
A: They use binary encoding.
B: They are unrelated to word meanings.
C: They are token-level embeddings.
D: They only work for syntactic parsing.
E: They are based on structural features.
Answer: C

Question: How do contextually-meaningful embeddings like ELMo and BERT reflect the multi-sense nature of words?
A: By using explicit representation of word meanings.
B: By converting categorical features into numerical features.
C: By assuming a specific number of senses for each word.
D: By providing a unique embedding for each occurrence of a word.
E: By using regular expressions to represent word meanings.
Answer: D
@
Bidirectional Encoder Representations from Transformers (BERT) is a family of language models introduced in 2018 by researchers at Google.[1][2] A 2020 literature survey concluded that "in a little over a year, BERT has become a ubiquitous baseline in Natural Language Processing (NLP) experiments counting over 150 research publications analyzing and improving the model."[3]

BERT was originally implemented in the English language at two model sizes:[1] (1) BERTBASE: 12 encoders with 12 bidirectional self-attention heads totaling 110 million parameters, and (2) BERTLARGE: 24 encoders with 16 bidirectional self-attention heads totaling 340 million parameters. Both models were pre-trained on the Toronto BookCorpus[4] (800M words) and English Wikipedia (2,500M words).

BERT is based on the transformer architecture. Specifically, BERT is composed of Transformer encoder layers.

BERT uses WordPiece to convert each English word into an integer code. Its vocabulary has size 30,000. Any token not appearing in its vocabulary is replaced by [UNK] for "unknown".

BERT was pre-trained simultaneously on two tasks:[5]

language modeling: 15% of tokens were selected for prediction, and the training objective was to predict the selected token given its context. The selected token is

replaced with a [MASK] token with probability 80%,
replaced with a random word token with probability 10%,
not replaced with probability 10%.
For example, the sentence "my dog is cute" may have the 4-th token selected for prediction. The model would have input text

"my dog is [MASK]" with probability 80%,
"my dog is happy" with probability 10%,
"my dog is cute" with probability 10%.
After processing the input text, the model's 4-th output vector is passed to a separate neural network, which outputs a probability distribution over its 30,000-large vocabulary.

next sentence prediction: Given two spans of text, the model predicts if these two spans appeared sequentially in the training corpus, outputting either [IsNext] or [NotNext]. The first span starts with a special token [CLS] (for "classify"). The two spans are separated by a special token [SEP] (for "separate"). After processing the two spans, the 1-st output vector (the vector coding for [CLS]) is passed to a separate neural network for the binary classification into [IsNext] and [NotNext].

For example, given "[CLS] my dog is cute [SEP] he likes playing" the model should output token [IsNext].
Given "[CLS] my dog is cute [SEP] how do magnets work" the model should output token [NotNext].
As a result of this training process, BERT learns latent representations of words and sentences in context. After pre-training, BERT can be fine-tuned with fewer resources on smaller datasets to optimize its performance on specific tasks such as NLP tasks (language inference, text classification) and sequence-to-sequence based language generation tasks (question-answering, conversational response generation).[1][6] The pre-training stage is significantly more computationally expensive than fine-tuning.
$
10
Question: What is the primary architecture underlying BERT language models?
A: Transformer architecture
B: LSTM architecture
C: Recurrent neural network architecture
D: Convolutional neural network architecture
E: Gated recurrent unit architecture
Answer: A

Question: What is the total number of bidirectional self-attention heads in the BERTLARGE model?
A: 12
B: 16
C: 24
D: 110
E: 340
Answer: B

Question: What is the main purpose of BERT's language modeling pre-training task?
A: To predict if two spans of text appeared sequentially.
B: To classify text as [IsNext] or [NotNext].
C: To optimize performance on specific NLP tasks.
D: To convert English words into integer codes.
E: To predict a selected token given its context.
Answer: E

Question: What special token is used to separate two spans of text in the next sentence prediction task of BERT?
A: [MASK]
B: [CLS]
C: [SEP]
D: [UNK]
E: [NotNext]
Answer: C

Question: What is the size of BERT's vocabulary?
A: 110,000 words
B: 30,000 words
C: 800,000 words
D: 2,500,000 words
E: 16 words
Answer: B

Question: What task involves predicting if two spans of text appeared sequentially in the training corpus in BERT?
A: Language modeling
B: Token classification
C: Sentiment analysis
D: Part-of-speech tagging
E: Next sentence prediction
Answer: E

Question: In BERT, what is the replacement token used for tokens not appearing in its vocabulary?
A: [MASK]
B: [CLS]
C: [SEP]
D: [UNK]
E: [IsNext]
Answer: D

Question: What corpus was used for pre-training BERT models?
A: Toronto BookCorpus and English Wikipedia
B: Toronto BookCorpus and French Wikipedia
C: Spanish BookCorpus and English Wikipedia
D: German BookCorpus and French Wikipedia
E: Chinese BookCorpus and English Wikipedia
Answer: A

Question: What is the function of the separate neural network used in BERT's language modeling task?
A: To convert English words into integer codes.
B: To predict a selected token given its context.
C: To optimize performance on specific NLP tasks.
D: To classify text as [IsNext] or [NotNext].
E: To convert text into binary representations.
Answer: B

Question: What is the main benefit of fine-tuning BERT with fewer resources on smaller datasets?
A: It reduces the computational cost of pre-training.
B: It improves the performance on the next sentence prediction task.
C: It makes BERT models smaller in size.
D: It optimizes performance on specific tasks.
E: It eliminates the need for pre-training.
Answer: D
@
The English Wikipedia is the primary[a] English-language edition of Wikipedia, an online encyclopedia. It was created by Jimmy Wales and Larry Sanger on January 15, 2001, as Wikipedia's first edition.

English Wikipedia is hosted alongside other language editions by the Wikimedia Foundation, an American nonprofit organization. Its content is written independently of other editions[1] in various varieties of English, aiming to stay consistent within articles. Its internal newspaper is The Signpost.

English Wikipedia is the most-read version of Wikipedia[2] and has the most articles of any edition, at 6,712,916 as of September 2023.[3] It contains 10.9% of articles in all Wikipedias,[3] although it lacks millions of articles found in other editions.[1] The edition's one-billionth edit was made on January 13, 2021.[4]

English Wikipedia, often as a stand-in for Wikipedia overall, has been praised for its enablement of the democratization of knowledge, extent of coverage, unique structure, culture, and reduced degree of commercial bias. It has been criticized for exhibiting systemic bias, particularly gender bias against women and ideological bias.[5][6] While its reliability was frequently criticized in the 2000s, it has improved over time, receiving greater praise in the late 2010s and early 2020s,[7][5][8][b] having become an important fact-checking site.[9][10] English Wikipedia has been characterized as having less cultural bias than other language editions due to its broader editor base.[2]

Editors of the English Wikipedia have pioneered some ideas as conventions, policies or features which were later adopted by Wikipedia editions in some of the other languages. These ideas include "featured articles",[11] the neutral-point-of-view policy,[12] navigation templates,[13] the sorting of short "stub" articles into sub-categories,[14] dispute resolution mechanisms such as mediation and arbitration,[15] and weekly collaborations.[16]

It surpassed six million articles on 23 January 2020.[17] In November 2022, the total volume of the compressed texts of its articles amounted to 20 gigabytes.[18]

The edition's one-billionth edit was made on 13 January 2021 by Ser Amantio di Nicolao (Steven Pruitt) who as of that date is the user with the highest number of edits on the English Wikipedia, at over four million.[4] Currently, there are 6,712,916 articles created with 905,556 files. The encyclopedia is home to 10.9% of articles in all Wikipedias (down from more than 50% in 2003).[19][20] The English Wikipedia currently has 46,136,173 registered accounts of which 887 are administrators.
$
10
Question: When was the English Wikipedia first created?
A: January 15, 2001
B: January 13, 2021
C: November 23, 2022
D: January 23, 2020
E: November 13, 2019
Answer: A

Question: Who are the co-founders of the English Wikipedia?
A: Sergey Brin and Larry Page
B: Mark Zuckerberg and Sheryl Sandberg
C: Jeff Bezos and Tim Cook
D: Jimmy Wales and Larry Sanger
E: Elon Musk and Peter Thiel
Answer: D

Question: What is the internal newspaper of the English Wikipedia?
A: The Encyclopedia Herald
B: The Wikipedia Journal
C: The Wiki News
D: The Signpost
E: The Knowledge Gazette
Answer: D

Question: What is the total number of articles in the English Wikipedia as of September 2023?
A: 20,000,000
B: 6,712,916
C: 46,136,173
D: 1,000,000,000
E: 10.9%
Answer: B

Question: Which edition of Wikipedia is often praised for enabling the democratization of knowledge and having a broad editor base?
A: French Wikipedia
B: Spanish Wikipedia
C: German Wikipedia
D: English Wikipedia
E: Chinese Wikipedia
Answer: D

Question: What policy on the English Wikipedia emphasizes a neutral point of view?
A: The Feature Article Policy
B: The Navigation Templates Policy
C: The Stub Article Policy
D: The Neutral-Point-of-View Policy
E: The Dispute Resolution Policy
Answer: D

Question: Who holds the record for the highest number of edits on the English Wikipedia as of January 2021?
A: Jimmy Wales
B: Larry Sanger
C: Sergey Brin
D: Larry Page
E: Ser Amantio di Nicolao (Steven Pruitt)
Answer: E

Question: What major event happened on January 23, 2020, in relation to the English Wikipedia?
A: It celebrated its 25th anniversary.
B: It surpassed six million articles.
C: It hosted its first edit-a-thon.
D: It introduced a new language edition.
E: It received a major software update.
Answer: B

Question: What is the percentage of articles in all Wikipedias that the English Wikipedia contains?
A: 100%
B: 50%
C: 46,136,173%
D: 10.9%
E: 6,712,916%
Answer: D

Question: How many registered accounts does the English Wikipedia currently have?
A: 10,000,000
B: 20,000,000
C: 905,556
D: 1,000,000,000
E: 46,136,173
Answer: C
@
Self-supervised learning (SSL) is a paradigm in machine learning for processing data of lower quality, rather than improving ultimate outcomes. Self-supervised learning more closely imitates the way humans learn to classify objects.[1]

The typical SSL method is based on an artificial neural network or other model such as a decision list.[2] The model learns in two steps. First, the task is solved based on an auxiliary or pretext classification task using pseudo-labels which help to initialize the model parameters.[3][4] Second, the actual task is performed with supervised or unsupervised learning.[5][6][7] Other auxiliary tasks involve pattern completion from masked input patterns (silent pauses in speech or image portions masked in black).

Self-supervised learning has produced promising results in recent years and has found practical application in audio processing and is being used by Facebook and others for speech recognition.[8]

For a binary classification task, training data can be divided into positive examples and negative examples. Positive examples are those that match the target. For example, if you're learning to identify birds, the positive training data are those pictures that contain birds. Negative examples are those that do not.[9]

Contrastive self-supervised learning
Contrastive self-supervised learning uses both positive and negative examples. Contrastive learning's loss function minimizes the distance between positive samples while maximizing the distance between negative samples.[9]

Non-contrastive self-supervised learning
Non-contrastive self-supervised learning (NCSSL) uses only positive examples. Counterintuitively, NCSSL converges on a useful local minimum rather than reaching a trivial solution, with zero loss. For the example of binary classification, it would trivially learn to classify each example as positive. Effective NCSSL requires an extra predictor on the online side that does not back-propagate on the target side.[9]

SSL belongs to supervised learning methods insofar as the goal is to generate a classified output from the input. At the same time, however, it does not require the explicit use of labeled input-output pairs. Instead, correlations, metadata embedded in the data, or domain knowledge present in the input are implicitly and autonomously extracted from the data. These supervisory signals, generated from the data, can then be used for training.[1]

SSL is similar to unsupervised learning in that it does not require labels in the sample data. Unlike unsupervised learning, however, learning is not done using inherent data structures.

Semi-supervised learning combines supervised and unsupervised learning, requiring only a small portion of the learning data be labeled.[4]

In transfer learning a model designed for one task is reused on a different task.[10]

Training an autoencoder intrinsically constitutes a self-supervised process, because the output pattern needs to become an optimal reconstruction of the input pattern itself. However, in current jargon, the term 'self-supervised' has become associated with classification tasks that are based on a pretext-task training setup. This involves the (human) design of such pretext task(s), unlike the case of fully self-contained autoencoder training.[11]

In reinforcement learning, self-supervising learning from a combination of losses can create abstract representations where only the most important information about the state are kept in a compressed way.[12]
Question: What is the primary goal of self-supervised learning?
A: To improve ultimate outcomes.
B: To imitate the way humans learn to classify objects.
C: To require labeled input-output pairs.
D: To minimize loss in the training process.
E: To reach a trivial solution with zero loss.
Answer: B

Question: What type of classification task does non-contrastive self-supervised learning (NCSSL) use?
A: Binary classification
B: Multi-class classification
C: Regression
D: Clustering
E: Semi-supervised classification
Answer: A

Question: What is the main objective of contrastive self-supervised learning's loss function?
A: To maximize the distance between positive samples.
B: To minimize the distance between negative samples.
C: To maximize the distance between positive and negative samples.
D: To minimize the distance between all samples.
E: To classify each example as positive.
Answer: C

Question: Which task does self-supervised learning perform first to initialize model parameters?
A: Supervised learning
B: Unsupervised learning
C: Reinforcement learning
D: Pretext classification task
E: Semi-supervised classification
Answer: D

Question: In self-supervised learning, what does SSL stand for?
A: Supervised Structure Learning
B: Self-Supported Learning
C: Semi-Supervised Learning
D: Self-Supervised Learning
E: Self-Structured Learning
Answer: D

Question: What type of data does self-supervised learning primarily focus on processing?
A: High-quality data
B: Labeled data
C: Data with metadata
D: Inherent data structures
E: Data of lower quality
Answer: E

Question: What is the primary practical application of self-supervised learning mentioned in the text?
A: Image processing
B: Speech recognition
C: Reinforcement learning
D: Clustering
E: Natural language processing
Answer: B

Question: How does semi-supervised learning combine supervised and unsupervised learning?
A: It requires all data to be labeled.
B: It doesn't use labeled data.
C: It uses labeled data for training and unlabeled data for testing.
D: It uses labeled data for testing and unlabeled data for training.
E: It requires most of the learning data to be labeled.
Answer: C

Question: What is the main difference between self-supervised learning and unsupervised learning?
A: Self-supervised learning uses inherent data structures.
B: Unsupervised learning requires correlations in the data.
C: Self-supervised learning requires labels in the sample data.
D: Unsupervised learning relies on metadata embedded in the data.
E: Self-supervised learning does not require labels.
Answer: E

Question: What kind of representations can be created in reinforcement learning through self-supervising learning from a combination of losses?
A: Abstract representations with all information about the state.
B: Noisy representations with limited information.
C: Compressed
@
A language model is a probabilistic model of a natural language[1] that can generate probabilities of a series of words, based on text corpora in one or multiple languages it was trained on. Large language models, as their most advanced form, are a combination of feedforward neural networks and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.

Language models are useful for a variety of tasks, including speech recognition[2] (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation,[3] natural language generation (generating more human-like text), optical character recognition, handwriting recognition,[4] grammar induction,[5] information retrieval,[6][7] and other.

Recurrent neural network
Continuous representations or embeddings of words are produced in recurrent neural network-based language models (known also as continuous space language models).[13] Such continuous space embeddings help to alleviate the curse of dimensionality, which is the consequence of the number of possible sequences of words increasing exponentially with the size of the vocabulary, furtherly causing a data sparsity problem. Neural networks avoid this problem by representing words as non-linear combinations of weights in a neural net.[14]

Large language models
A large language model (LLM) is a language model characterized by its large size. Their size is enabled by AI accelerators, which are able to process vast amounts of text data, mostly scraped from the Internet.[15] The artificial neural networks which are built can contain from tens of millions and up to billions of weights and are (pre-)trained using self-supervised learning and semi-supervised learning. Transformer architecture contributed to faster training.[16] Alternative architectures include the mixture of experts (MoE), which has been proposed by Google, starting with sparsely-gated ones in 2017,[17] Gshard in 2021[18] to GLaM in 2022.[19]

As language models, they work by taking an input text and repeatedly predicting the next token or word.[20] Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.[21] They are thought to acquire embodied knowledge about syntax, semantics and "ontology" inherent in human language corpora, but also inaccuracies and biases present in the corpora.[22]

Notable examples include OpenAI's GPT models (e.g., GPT-3.5 and GPT-4, used in ChatGPT), Google's PaLM (used in Bard), and Meta's LLaMa, as well as BLOOM, Ernie 3.0 Titan, and Claude.
Although sometimes matching human performance, it is not clear they are plausible cognitive models. At least for recurrent neural networks it has been shown that they sometimes learn patterns which humans do not learn, but fail to learn patterns that humans typically do learn.[23]
$
10
Question: What are some tasks that language models are useful for?
A: Speech recognition and optical character recognition
B: Image recognition and natural language generation
C: Weather forecasting and stock market analysis
D: Virtual reality gaming and augmented reality
E: Geographical mapping and 3D printing
Answer: A

Question: How do recurrent neural network-based language models produce continuous representations of words?
A: By combining weights in a neural network
B: By using pure statistical models
C: By performing optical character recognition
D: By utilizing sparsely-gated neural nets
E: By generating random sequences of words
Answer: A

Question: What is the primary advantage of large language models enabled by AI accelerators?
A: They can process small amounts of text data efficiently.
B: They rely solely on supervised learning for training.
C: They have small vocabularies to avoid data sparsity.
D: They are limited to millions of weights.
E: They can process vast amounts of text data.
Answer: E

Question: How are large language models trained?
A: They are trained using purely supervised learning.
B: They are trained using unsupervised learning.
C: They are trained using reinforcement learning.
D: They are trained using self-supervised learning and semi-supervised learning.
E: They are not trained and generate text randomly.
Answer: D

Question: What is the consequence of the curse of dimensionality in language models?
A: It leads to better model generalization.
B: It causes a data sparsity problem.
C: It results in models learning human-like patterns.
D: It increases the efficiency of training.
E: It decreases the model's weight count.
Answer: B

Question: Which architecture contributed to faster training of large language models?
A: GPT-3
B: Sparsely-gated neural nets
C: Transformer
D: Recurrent neural networks
E: Mixture of experts
Answer: C

Question: How do large language models like GPT-3 and GPT-4 adapt to specific tasks?
A: By fine-tuning
B: By using reinforcement learning
C: By relying on purely supervised learning
D: By prompt engineering
E: By implementing a mixture of experts
Answer: D

Question: What is the primary role of AI accelerators in enabling large language models?
A: They generate text data for training.
B: They increase the model's vocabulary size.
C: They facilitate fine-tuning of models.
D: They process vast amounts of text data.
E: They perform reinforcement learning.
Answer: D

Question: What is the main difference between language models and human cognitive models?
A: Language models rely on pure statistical models, while human cognitive models do not.
B: Language models are trained exclusively using supervised learning, while human cognitive models are not.
C: Language models always match human performance, while human cognitive models sometimes do not.
D: Language models learn patterns that humans do not learn, while failing to learn patterns that humans typically learn.
E: Language models do not process language corpora, while human cognitive models do.
Answer: D

Question: What are some notable examples of large language models mentioned in the text?
A: Apple's Siri and Amazon's Alexa
B: Microsoft's Cortana and IBM's Watson
C: Google's Search and Facebook's News Feed
D: OpenAI's GPT models and Meta's LLaMa
E: Twitter's Birdie and LinkedIn's Connect
Answer: D
@
A large language model (LLM) is a language model characterized by its large size. Their size is enabled by AI accelerators, which are able to process vast amounts of text data, mostly scraped from the Internet.[1] The artificial neural networks which are built can contain from tens of millions and up to billions of weights and are (pre-)trained using self-supervised learning and semi-supervised learning. Transformer architecture contributed to faster training.[2] Alternative architectures include the mixture of experts (MoE), which has been proposed by Google, starting with sparsely-gated ones in 2017,[3] Gshard in 2021[4] to GLaM in 2022.[5]

As language models, they work by taking an input text and repeatedly predicting the next token or word.[6] Up to 2020, fine tuning was the only way a model could be adapted to be able to accomplish specific tasks. Larger sized models, such as GPT-3, however, can be prompt-engineered to achieve similar results.[7] They are thought to acquire embodied knowledge about syntax, semantics and "ontology" inherent in human language corpora, but also inaccuracies and biases present in the corpora.[8]

Notable examples include OpenAI's GPT models (e.g., GPT-3.5 and GPT-4, used in ChatGPT), Google's PaLM (used in Bard), and Meta's LLaMa, as well as BLOOM, Ernie 3.0 Titan, and Claude.

Large language models by themselves are "black boxes", and it is not clear how they can perform linguistic tasks. There are several methods for understanding how LLM work.

Mechanistic interpretability aims to reverse-engineer LLM by discovering symbolic algorithms that approximate the inference performed by LLM. One example is Othello-GPT, where a small Transformer is trained to predict legal Othello moves. It is found that there is a linear representation of Othello board, and modifying the representation changes the predicted legal Othello moves in the correct way.[69][70] In another example, a small Transformer is trained on Karel programs. Similar to the Othello-GPT example, there is a linear representation of Karel program semantics, and modifying the representation changes output in the correct way. The model also generates correct programs that are on average shorter than those in the training set.[71]

In another example, the authors trained small transformers on modular arithmetic addition. The resulting models were reverse-engineered, and it turned out they used discrete Fourier transform.[72]

Understanding and intelligence
NLP researchers were evenly split when asked, in a 2022 survey, whether (untuned) LLMs "could (ever) understand natural language in some nontrivial sense".[73] Proponents of "LLM understanding" believe that some LLM abilities, such as mathematical reasoning, imply an ability to "understand" certain concepts. A Microsoft team argued in 2023 that GPT-4 "can solve novel and difficult tasks that span mathematics, coding, vision, medicine, law, psychology and more" and that GPT-4 "could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence system": "Can one reasonably say that a system that passes exams for software engineering candidates is not really intelligent?"[74][75] Some researchers characterize LLMs as "alien intelligence".[76][77] For example, Conjecture CEO Connor Leahy considers untuned LLMs to be like inscrutable alien "Shoggoths", and believes that RLHF tuning creates a "smiling facade" obscuring the inner workings of the LLM: "If you don't push it too far, the smiley face stays on. But then you give it [an unexpected] prompt, and suddenly you see this massive underbelly of insanity, of weird thought processes and clearly non-human understanding."[78][79]

In contrast, some proponents of the "LLMs lack understanding" school believe that existing LLMs are "simply remixing and recombining existing writing",[77] or point to the deficits existing LLMs continue to have in prediction skills, reasoning skills, agency, and explainability.[73] For example, GPT-4 has natural deficits in planning and in real-time learning.[75] Generative LLMs have been observed to confidently assert claims of fact which do not seem to be justified by their training data, a phenomenon which has been termed "hallucination".[80] [81] Neuroscientist Terrence Sejnowski has argued that "The diverging opinions of experts on the intelligence of LLMs suggests that our old ideas based on natural intelligence are inadequate".[73]

The matter of LLM's exhibiting intelligence or understanding [73] has foundations in the study of language as a model of Cognition in the field of Cognitive linguistics. The American Linguist George Lakoff presented Neural Theory of Language (NTL) as a computational basis for using language as a model of learning tasks and understanding.[82] In his 2014 book titled The Language Myth: Why Language Is Not An Instinct, British cognitive linguist and digital communication technologist Vyvyan Evans maps out the role of probabilistic context-free grammar (PCFG) in enabling NLP to model cognitive patterns.
$
10
Question: How are large language models, such as GPT-3, trained to perform specific tasks?
A: By prompt engineering
B: By using reinforcement learning
C: By fine-tuning with labeled data
D: By relying solely on unsupervised learning
E: By implementing a mixture of experts
Answer: A

Question: What is the primary role of AI accelerators in enabling large language models?
A: They fine-tune the models.
B: They process text data from books.
C: They increase the size of the vocabulary.
D: They enable the training of models with vast amounts of text data.
E: They create small-sized language models.
Answer: D

Question: What is one of the methods for understanding how large language models work, as mentioned in the text?
A: Fine-tuning with reinforcement learning
B: Prompt engineering with large datasets
C: Mechanistic interpretability, discovering symbolic algorithms
D: Using only unsupervised learning
E: Increasing the number of weights in the model
Answer: C

Question: What is the key characteristic of large language models as mentioned in the text?
A: They are primarily based on statistical models.
B: They lack the ability to understand natural language.
C: They are characterized by their small size.
D: They rely on purely supervised learning.
E: They contain billions of weights and are (pre-)trained using self-supervised learning.
Answer: E

Question: How do large language models like GPT-4 perform linguistic tasks?
A: By understanding natural language completely
B: By remixing and recombining existing writing
C: By generating text randomly
D: By utilizing pure statistical models
E: By fine-tuning with labeled data
Answer: B

Question: What is "hallucination" in the context of large language models?
A: A phenomenon where they predict nonsense sequences
B: A process of understanding natural language
C: A type of AI accelerator
D: A method for improving model interpretability
E: A synonym for fine-tuning
Answer: A

Question: According to a 2022 survey, what do NLP researchers believe about (untuned) large language models?
A: They unanimously agree that they can understand natural language.
B: They are evenly split on whether they could ever understand natural language in a nontrivial sense.
C: They believe that all large language models are "alien intelligence."
D: They think that LLMs completely lack understanding.
E: They agree that LLMs have human-like cognitive abilities.
Answer: B

Question: What is one argument made by proponents of "LLMs lack understanding" regarding large language models?
A: They argue that LLMs are highly intelligent and have human-like understanding.
B: They believe that LLMs are inscrutable alien beings.
C: They assert that LLMs are excellent at planning and real-time learning.
D: They point to deficits in prediction skills and reasoning skills in LLMs.
E: They claim that LLMs have complete agency and explainability.
Answer: D

Question: How does mechanistic interpretability aim to understand large language models?
A: By discovering symbolic algorithms that approximate the inference performed by LLMs
B: By fine-tuning the models with labeled data
C: By randomly generating text sequences
D: By remixing and recombining existing writing
E: By increasing the number of weights in the models
Answer: A

Question: What is Neural Theory of Language (NTL) according to the text?
A: A theory that explains how large language models understand natural language
B: A computational basis for using language as a model of learning tasks and understanding
C: A type of AI accelerator used to process text data
D: A method for fine-tuning large language models
E: A synonym for probabilistic context-free grammar (PCFG)
Answer: B
@
A chemical compound is a chemical substance composed of many identical molecules (or molecular entities) containing atoms from more than one chemical element held together by chemical bonds. A molecule consisting of atoms of only one element is therefore not a compound. A compound can be transformed into a different substance by a chemical reaction, which may involve interactions with other substances. In this process, bonds between atoms may be broken and/or new bonds formed.

There are four major types of compounds, distinguished by how the constituent atoms are bonded together. Molecular compounds are held together by covalent bonds; ionic compounds are held together by ionic bonds; intermetallic compounds are held together by metallic bonds; coordination complexes are held together by coordinate covalent bonds. Non-stoichiometric compounds form a disputed marginal case.

A chemical formula specifies the number of atoms of each element in a compound molecule, using the standard chemical symbols with numerical subscripts. Many chemical compounds have a unique CAS number identifier assigned by the Chemical Abstracts Service. Globally, more than 350,000 chemical compounds (including mixtures of chemicals) have been registered for production and use.[1]
$
10
Question: What is a chemical compound composed of?
A: Identical molecules containing atoms from more than one chemical element
B: Identical molecules containing atoms from a single chemical element
C: Molecules with no chemical bonds
D: Atoms from a single chemical element
E: Molecules with covalent bonds only
Answer: A

Question: How can a compound be transformed into a different substance?
A: Through physical changes
B: Through interactions with other substances
C: By cooling it to a very low temperature
D: By heating it to a high temperature
E: By exposing it to sunlight
Answer: B

Question: What holds molecular compounds together?
A: Covalent bonds
B: Ionic bonds
C: Metallic bonds
D: Coordinate covalent bonds
E: Physical forces
Answer: A

Question: How are ionic compounds held together?
A: By covalent bonds
B: By metallic bonds
C: By ionic bonds
D: By coordinate covalent bonds
E: By physical forces
Answer: C

Question: What type of compound is held together by metallic bonds?
A: Molecular compounds
B: Ionic compounds
C: Intermetallic compounds
D: Coordination complexes
E: Non-stoichiometric compounds
Answer: C

Question: How are coordination complexes held together?
A: By covalent bonds
B: By metallic bonds
C: By ionic bonds
D: By coordinate covalent bonds
E: By physical forces
Answer: D

Question: What do chemical formulas specify about a compound molecule?
A: The number of atoms of each element
B: The color of the compound
C: The temperature at which it melts
D: The state of matter of the compound
E: The smell of the compound
Answer: A

Question: What is the unique identifier assigned to many chemical compounds by the Chemical Abstracts Service?
A: CAS number
B: Chemical symbol
C: Molecular weight
D: Atomic number
E: Isotope
Answer: A

Question: How many major types of compounds are distinguished based on how constituent atoms are bonded together?
A: Two
B: Three
C: Four
D: Five
E: Six
Answer: C

Question: What do non-stoichiometric compounds represent?
A: A well-established category of compounds
B: A type of molecular compound
C: A type of ionic compound
D: A disputed marginal case
E: A category of coordination complexes
Answer: D
@
Types
Molecules
Main article: Molecule
A molecule is an electrically neutral group of two or more atoms held together by chemical bonds.[8][9][10] A molecule may be homonuclear, that is, it consists of atoms of one chemical element, as with two atoms in the oxygen molecule (O2); or it may be heteronuclear, a chemical compound composed of more than one element, as with water (two hydrogen atoms and one oxygen atom; H2O). A molecule is the smallest unit of a substance that still carries all the physical and chemical properties of that substance.[11]

Ionic compounds
Main article: Ionic compound
An ionic compound is a chemical compound composed of ions held together by electrostatic forces termed ionic bonding. The compound is neutral overall, but consists of positively charged ions called cations and negatively charged ions called anions. These can be simple ions such as the sodium (Na+) and chloride (Cl−) in sodium chloride, or polyatomic species such as the ammonium (NH+
4) and carbonate (CO2−
3) ions in ammonium carbonate. Individual ions within an ionic compound usually have multiple nearest neighbours, so are not considered to be part of molecules, but instead part of a continuous three-dimensional network, usually in a crystalline structure.

Ionic compounds containing basic ions hydroxide (OH−) or oxide (O2−) are classified as bases. Ionic compounds without these ions are also known as salts and can be formed by acid–base reactions. Ionic compounds can also be produced from their constituent ions by evaporation of their solvent, precipitation, freezing, a solid-state reaction, or the electron transfer reaction of reactive metals with reactive non-metals, such as halogen gases.

Ionic compounds typically have high melting and boiling points, and are hard and brittle. As solids they are almost always electrically insulating, but when melted or dissolved they become highly conductive, because the ions are mobilized.

Intermetallic compounds
Main article: Intermetallic compound
An intermetallic compound is a type of metallic alloy that forms an ordered solid-state compound between two or more metallic elements. Intermetallics are generally hard and brittle, with good high-temperature mechanical properties.[12][13][14] They can be classified as stoichiometric or nonstoichiometric intermetallic compounds.[12]

Complexes
Main article: Coordination complex
A coordination complex consists of a central atom or ion, which is usually metallic and is called the coordination centre, and a surrounding array of bound molecules or ions, that are in turn known as ligands or complexing agents.[15][16][17] Many metal-containing compounds, especially those of transition metals, are coordination complexes.[18] A coordination complex whose centre is a metal atom is called a metal complex of d block element.
$
10
Question: What is the smallest unit of a substance that still carries all the physical and chemical properties of that substance?
A: Ion
B: Atom
C: Compound
D: Molecule
E: Element
Answer: D

Question: What type of chemical compound is composed of ions held together by electrostatic forces?
A: Ionic compound
B: Molecular compound
C: Covalent compound
D: Organic compound
E: Metallic compound
Answer: A

Question: Which ions are present in the ionic compound sodium chloride (NaCl)?
A: Sodium (Na+) and chloride (Cl−)
B: Ammonium (NH4+) and carbonate (CO2−3)
C: Hydroxide (OH−) and oxide (O2−)
D: Oxygen (O2) and hydrogen (H2)
E: Sodium (Na+) and ammonium (NH4+)
Answer: A

Question: How are individual ions within an ionic compound typically arranged?
A: As molecules
B: In a crystalline structure
C: In a gaseous state
D: As free atoms
E: In a covalent bond
Answer: B

Question: What can ionic compounds be formed from?
A: Acid–base reactions
B: Precipitation
C: Freezing
D: All of the above
E: None of the above
Answer: D

Question: What are the typical electrical properties of ionic compounds in their solid state?
A: Highly conductive
B: Electrically insulating
C: Metallic
D: Semiconducting
E: Superconducting
Answer: B

Question: What is an intermetallic compound?
A: A type of organic compound
B: A type of covalent compound
C: A type of metallic compound
D: A type of compound that forms between metals
E: A type of compound that forms between nonmetals
Answer: D

Question: How are intermetallic compounds generally described in terms of mechanical properties?
A: Hard and brittle
B: Soft and ductile
C: Elastic and flexible
D: Transparent and lightweight
E: Conductive and malleable
Answer: A

Question: What is a coordination complex composed of?
A: A central atom or ion and ligands
B: Molecules of the same element
C: Ions with opposite charges
D: A single metallic element
E: A central molecule and surrounding atoms
Answer: A

Question: What are many metal-containing compounds, especially those of transition metals, classified as?
A: Ionic compounds
B: Molecular compounds
C: Covalent compounds
D: Coordination complexes
E: Organic compounds
Answer: D
@
In chemistry, an ionic compound is a chemical compound composed of ions held together by electrostatic forces termed ionic bonding. The compound is neutral overall, but consists of positively charged ions called cations and negatively charged ions called anions. These can be simple ions such as the sodium (Na+) and chloride (Cl−) in sodium chloride, or polyatomic species such as the ammonium (NH+
4) and carbonate (CO2−
3) ions in ammonium carbonate. Individual ions within an ionic compound usually have multiple nearest neighbours, so are not considered to be part of molecules, but instead part of a continuous three-dimensional network. Ionic compounds usually form crystalline structures when solid.

Ionic compounds containing basic ions hydroxide (OH−) or oxide (O2−) are classified as bases. Ionic compounds without these ions are also known as salts and can be formed by acid–base reactions. Ionic compounds can also be produced from their constituent ions by evaporation of their solvent, precipitation, freezing, a solid-state reaction, or the electron transfer reaction of reactive metals with reactive non-metals, such as halogen gases.

Ionic compounds typically have high melting and boiling points, and are hard and brittle. As solids they are almost always electrically insulating, but when melted or dissolved they become highly conductive, because the ions are mobilized.

The word ion is the Greek ἰόν, ion, "going", the present participle of ἰέναι, ienai, "to go". This term was introduced by physicist and chemist Michael Faraday in 1834 for the then-unknown species that goes from one electrode to the other through an aqueous medium.[1][2]


X-ray spectrometer developed by Bragg
In 1913 the crystal structure of sodium chloride was determined by William Henry Bragg and William Lawrence Bragg.[3][4][5] This revealed that there were six equidistant nearest-neighbours for each atom, demonstrating that the constituents were not arranged in molecules or finite aggregates, but instead as a network with long-range crystalline order.[5] Many other inorganic compounds were also found to have similar structural features.[5] These compounds were soon described as being constituted of ions rather than neutral atoms, but proof of this hypothesis was not found until the mid-1920s, when X-ray reflection experiments (which detect the density of electrons), were performed.[5][6]

Principal contributors to the development of a theoretical treatment of ionic crystal structures were Max Born, Fritz Haber, Alfred Landé, Erwin Madelung, Paul Peter Ewald, and Kazimierz Fajans.[7] Born predicted crystal energies based on the assumption of ionic constituents, which showed good correspondence to thermochemical measurements, further supporting the assumption.[5]
$
10
Question: What is the term for a chemical compound composed of ions held together by electrostatic forces?
A: Covalent compound
B: Ionic compound
C: Molecular compound
D: Metallic compound
E: Organic compound
Answer: B

Question: Which ions are considered cations in ionic compounds?
A: Sodium (Na+) and chloride (Cl−)
B: Ammonium (NH4+) and carbonate (CO2−3)
C: Hydroxide (OH−) and oxide (O2−)
D: Oxygen (O2) and hydrogen (H2)
E: None of the above
Answer: A

Question: What is the electrical conductivity of ionic compounds in their solid state?
A: Highly conductive
B: Electrically insulating
C: Metallic
D: Semiconducting
E: Superconducting
Answer: B

Question: What are ionic compounds without hydroxide (OH−) or oxide (O2−) ions classified as?
A: Salts
B: Bases
C: Acids
D: Alloys
E: Covalent compounds
Answer: A

Question: What do individual ions within an ionic compound usually have in terms of nearest neighbors?
A: They have no nearest neighbors.
B: They have one nearest neighbor.
C: They have multiple nearest neighbors.
D: They form molecules with other ions.
E: They are arranged in a linear structure.
Answer: C

Question: How do ionic compounds typically behave when they are in a solid state?
A: They are always electrically insulating.
B: They are highly conductive.
C: They become semiconducting.
D: They become transparent.
E: They are superconducting.
Answer: A

Question: Who introduced the term "ion" in 1834 for the species that moves through an aqueous medium from one electrode to the other?
A: Max Born
B: Fritz Haber
C: William Henry Bragg
D: Michael Faraday
E: Erwin Madelung
Answer: D

Question: In 1913, the crystal structure of which compound was determined, revealing its ionic nature?
A: Sodium chloride
B: Ammonium carbonate
C: Hydroxide
D: Oxygen
E: Chlorine gas
Answer: A

Question: What experimental technique in the mid-1920s provided proof of the ionic nature of inorganic compounds?
A: Spectroscopy
B: Mass spectrometry
C: NMR spectroscopy
D: X-ray reflection experiments
E: Chromatography
Answer: D

Question: Who were the principal contributors to the development of a theoretical treatment of ionic crystal structures?
A: Max Born and Fritz Haber
B: William Henry Bragg and William Lawrence Bragg
C: Michael Faraday and Erwin Madelung
D: Paul Peter Ewald and Kazimierz Fajans
E: Alfred Landé
Answer: A
@
Acidity/basicity
Ionic compounds containing hydrogen ions (H+) are classified as acids, and those containing electropositive cations[56] and basic anions ions hydroxide (OH−) or oxide (O2−) are classified as bases. Other ionic compounds are known as salts and can be formed by acid–base reactions.[57] If the compound is the result of a reaction between a strong acid and a weak base, the result is an acidic salt. If it is the result of a reaction between a strong base and a weak acid, the result is a basic salt. If it is the result of a reaction between a strong acid and a strong base, the result is a neutral salt. Weak acids reacted with weak bases can produce ionic compounds with both the conjugate base ion and conjugate acid ion, such as ammonium acetate.

Some ions are classed as amphoteric, being able to react with either an acid or a base.[58] This is also true of some compounds with ionic character, typically oxides or hydroxides of less-electropositive metals (so the compound also has significant covalent character), such as zinc oxide, aluminium hydroxide, aluminium oxide and lead(II) oxide.[59]

Melting and boiling points
Electrostatic forces between particles are strongest when the charges are high, and the distance between the nuclei of the ions is small. In such cases, the compounds generally have very high melting and boiling points and a low vapour pressure.[60] Trends in melting points can be even better explained when the structure and ionic size ratio is taken into account.[61] Above their melting point ionic solids melt and become molten salts (although some ionic compounds such as aluminium chloride and iron(III) chloride show molecule-like structures in the liquid phase).[62] Inorganic compounds with simple ions typically have small ions, and thus have high melting points, so are solids at room temperature. Some substances with larger ions, however, have a melting point below or near room temperature (often defined as up to 100 °C), and are termed ionic liquids.[63] Ions in ionic liquids often have uneven charge distributions, or bulky substituents like hydrocarbon chains, which also play a role in determining the strength of the interactions and propensity to melt.[64]

Even when the local structure and bonding of an ionic solid is disrupted sufficiently to melt it, there are still strong long-range electrostatic forces of attraction holding the liquid together and preventing ions boiling to form a gas phase.[65] This means that even room temperature ionic liquids have low vapour pressures, and require substantially higher temperatures to boil.[65] Boiling points exhibit similar trends to melting points in terms of the size of ions and strength of other interactions.[65] When vapourized, the ions are still not freed of one another. For example, in the vapour phase sodium chloride exists as diatomic "molecules".[66]

Brittleness
Most ionic compounds are very brittle. Once they reach the limit of their strength, they cannot deform malleably, because the strict alignment of positive and negative ions must be maintained. Instead the material undergoes fracture via cleavage.[67] As the temperature is elevated (usually close to the melting point) a ductile–brittle transition occurs, and plastic flow becomes possible by the motion of dislocations.[67][68]

Compressibility
The compressibility of an ionic compound is strongly determined by its structure, and in particular the coordination number. For example, halides with the caesium chloride structure (coordination number 8) are less compressible than those with the sodium chloride structure (coordination number 6), and less again than those with a coordination number of 4.[69]
$
10
Question: How are ionic compounds containing hydrogen ions (H+) classified?
A: As acids
B: As bases
C: As salts
D: As amphoteric compounds
E: As neutral compounds
Answer: A

Question: Which type of compound results from a reaction between a strong acid and a weak base?
A: Acidic salt
B: Basic salt
C: Neutral salt
D: Amphoteric compound
E: Covalent compound
Answer: A

Question: What is the term for ions that can react with either an acid or a base?
A: Amphoteric ions
B: Covalent ions
C: Neutral ions
D: Basic ions
E: Acidic ions
Answer: A

Question: What is the term for the melting and boiling points of ionic compounds when the charges are high and the distance between ions is small?
A: High melting and boiling points
B: Low melting and boiling points
C: Moderate melting and boiling points
D: No melting and boiling points
E: Variable melting and boiling points
Answer: A

Question: What happens to ionic compounds with simple ions when they reach their melting point?
A: They boil and become gases.
B: They become liquids.
C: They maintain their solid state.
D: They undergo fracture via cleavage.
E: They become amphoteric compounds.
Answer: B

Question: What are substances with larger ions and a melting point below or near room temperature termed?
A: Ionic compounds
B: Basic salts
C: Acidic salts
D: Ionic liquids
E: Covalent compounds
Answer: D

Question: What plays a role in determining the strength of interactions and propensity to melt in ionic liquids?
A: High ionic charge
B: Low coordination number
C: Bulky substituents like hydrocarbon chains
D: Covalent character
E: Lack of charge distribution
Answer: C

Question: How do ionic compounds behave even when they are in the vapor phase?
A: They form diatomic "molecules."
B: They become covalent compounds.
C: They become liquids.
D: They are freed of one another.
E: They are unstable and decompose.
Answer: A

Question: What is the term for the process of ionic compounds undergoing fracture via cleavage once they reach the limit of their strength?
A: Melting
B: Boiling
C: Compressibility
D: Ductility
E: Brittleness
Answer: E

Question: What strongly determines the compressibility of an ionic compound?
A: The charge of the ions
B: The coordination number
C: The ionic size ratio
D: The covalent character
E: The boiling point
Answer: B
@
Ionic compounds have long had a wide variety of uses and applications. Many minerals are ionic.[81] Humans have processed common salt (sodium chloride) for over 8000 years, using it first as a food seasoning and preservative, and now also in manufacturing, agriculture, water conditioning, for de-icing roads, and many other uses.[82] Many ionic compounds are so widely used in society that they go by common names unrelated to their chemical identity. Examples of this include borax, calomel, milk of magnesia, muriatic acid, oil of vitriol, saltpeter, and slaked lime.[83]

Soluble ionic compounds like salt can easily be dissolved to provide electrolyte solutions. This is a simple way to control the concentration and ionic strength. The concentration of solutes affects many colligative properties, including increasing the osmotic pressure, and causing freezing-point depression and boiling-point elevation.[84] Because the solutes are charged ions they also increase the electrical conductivity of the solution.[85] The increased ionic strength reduces the thickness of the electrical double layer around colloidal particles, and therefore the stability of emulsions and suspensions.[86]

The chemical identity of the ions added is also important in many uses. For example, fluoride containing compounds are dissolved to supply fluoride ions for water fluoridation.[87]

Solid ionic compounds have long been used as paint pigments, and are resistant to organic solvents, but are sensitive to acidity or basicity.[88] Since 1801 pyrotechnicians have described and widely used metal-containing ionic compounds as sources of colour in fireworks.[89] Under intense heat, the electrons in the metal ions or small molecules can be excited.[90] These electrons later return to lower energy states, and release light with a colour spectrum characteristic of the species present.[91][92]

In chemistry, ionic compounds are often used as precursors for high-temperature solid-state synthesis.[93]

Many metals are geologically most abundant as ionic compounds within ores.[94] To obtain the elemental materials, these ores are processed by smelting or electrolysis, in which redox reactions occur (often with a reducing agent such as carbon) such that the metal ions gain electrons to become neutral atoms.[95][96]
$
10
Question: What common ionic compound has been processed by humans for over 8000 years and is used in various applications including de-icing roads?
A: Sodium chloride
B: Borax
C: Calomel
D: Milk of magnesia
E: Muriatic acid
Answer: A

Question: What is a simple way to control the concentration and ionic strength of soluble ionic compounds?
A: Evaporation
B: Filtration
C: Dissolution
D: Sublimation
E: Precipitation
Answer: C

Question: How do soluble ionic compounds affect the electrical conductivity of a solution?
A: They decrease it.
B: They have no effect on it.
C: They increase it.
D: They stabilize it.
E: They induce osmotic pressure.
Answer: C

Question: Why is the chemical identity of the ions added important in some uses of ionic compounds?
A: It determines the color of the compound.
B: It influences the electrical conductivity.
C: It affects freezing-point depression.
D: It is essential for water fluoridation.
E: It increases osmotic pressure.
Answer: D

Question: What property of solid ionic compounds makes them suitable as paint pigments?
A: Resistance to acidity
B: Sensitivity to basicity
C: Solubility in organic solvents
D: Lack of color
E: Insensitivity to heat
Answer: A

Question: How do metal-containing ionic compounds contribute to the colors in fireworks?
A: They release colored light when they melt.
B: They release colored light when they react with oxygen.
C: They absorb colored light from their surroundings.
D: They generate colored smoke when ignited.
E: They emit colored sparks when burned.
Answer: B

Question: In chemistry, what are ionic compounds often used as precursors for?
A: Water purification
B: Low-temperature reactions
C: High-temperature solid-state synthesis
D: Organic synthesis
E: Biological reactions
Answer: C

Question: How are the most abundant metals in ores typically obtained from ionic compounds?
A: By heating the ores directly
B: By dissolving the ores in water
C: By conducting electrolysis
D: By crushing the ores into powder
E: By using strong acids
Answer: C

Question: What happens to metal ions during the process of obtaining elemental metals from ores?
A: They gain electrons and become ions.
B: They are oxidized and become cations.
C: They combine with oxygen and form oxides.
D: They remain in their ionic form.
E: They are reduced and become neutral atoms.
Answer: E

Question: What are many metals most abundant as within ores?
A: Ionic compounds
B: Covalent compounds
C: Isotopes
D: Amphoteric compounds
E: Noble gases
Answer: A
@
The melting point (or, rarely, liquefaction point) of a substance is the temperature at which it changes state from solid to liquid. At the melting point the solid and liquid phase exist in equilibrium. The melting point of a substance depends on pressure and is usually specified at a standard pressure such as 1 atmosphere or 100 kPa.

When considered as the temperature of the reverse change from liquid to solid, it is referred to as the freezing point or crystallization point. Because of the ability of substances to supercool, the freezing point can easily appear to be below its actual value. When the "characteristic freezing point" of a substance is determined, in fact, the actual methodology is almost always "the principle of observing the disappearance rather than the formation of ice, that is, the melting point."[1]

For most substances, melting and freezing points are approximately equal. For example, the melting and freezing points of mercury is 234.32 kelvins (−38.83 °C; −37.89 °F).[2] However, certain substances possess differing solid-liquid transition temperatures. For example, agar melts at 85 °C (185 °F; 358 K) and solidifies from 31 °C (88 °F; 304 K); such direction dependence is known as hysteresis. The melting point of ice at 1 atmosphere of pressure is very close[3] to 0 °C (32 °F; 273 K); this is also known as the ice point. In the presence of nucleating substances, the freezing point of water is not always the same as the melting point. In the absence of nucleators water can exist as a supercooled liquid down to −48.3 °C (−54.9 °F; 224.8 K) before freezing.[citation needed]

The metal with the highest melting point is tungsten, at 3,414 °C (6,177 °F; 3,687 K);[4] this property makes tungsten excellent for use as electrical filaments in incandescent lamps. The often-cited carbon does not melt at ambient pressure but sublimes at about 3,700 °C (6,700 °F; 4,000 K); a liquid phase only exists above pressures of 10 MPa (99 atm) and estimated 4,030–4,430 °C (7,290–8,010 °F; 4,300–4,700 K) (see carbon phase diagram). Hafnium carbonitride (HfCN) is a refractory compound with the highest known melting point of any substance to date and the only one confirmed to have a melting point above 4,273 K (4,000 °C; 7,232 °F) at ambient pressure. Quantum mechanical computer simulations predicted that this alloy (HfN0.38C0.51) would have a melting point of about 4,400 K.[5] This prediction was later confirmed by experiment, though a precise measurement of its exact melting point has yet to be confirmed.[6] At the other end of the scale, helium does not freeze at all at normal pressure even at temperatures arbitrarily close to absolute zero; a pressure of more than twenty times normal atmospheric pressure is necessary.
$
10
Question: What is the temperature at which a substance changes from solid to liquid called?
A: Boiling point
B: Freezing point
C: Melting point
D: Sublimation point
E: Crystallization point
Answer: C

Question: What is the temperature of the reverse change from liquid to solid referred to as?
A: Boiling point
B: Freezing point
C: Melting point
D: Sublimation point
E: Crystallization point
Answer: B

Question: At what pressure is the melting point of a substance usually specified?
A: 0 atmosphere
B: 10 kPa
C: 100 kPa
D: 1 MPa
E: 10 MPa
Answer: C

Question: What is the term for the phenomenon where the freezing point of water is not always the same as the melting point in the presence of nucleating substances?
A: Hysteresis
B: Sublimation
C: Supercooling
D: Crystallization
E: Boiling
Answer: A

Question: Which metal has the highest melting point?
A: Carbon
B: Tungsten
C: Hafnium
D: Helium
E: Mercury
Answer: B

Question: At what temperature does mercury melt and freeze approximately?
A: 0 °C
B: -38.83 °C
C: 85 °C
D: 234.32 kelvins
E: 3,414 °C
Answer: B

Question: What substance does not melt at ambient pressure but sublimes at high temperatures?
A: Helium
B: Carbon
C: Tungsten
D: Hafnium carbonitride
E: Mercury
Answer: B

Question: Which substance is confirmed to have a melting point above 4,273 K at ambient pressure?
A: Tungsten
B: Carbon
C: Hafnium carbonitride
D: Helium
E: Mercury
Answer: C

Question: What is the only known substance that does not freeze at normal pressure even at temperatures close to absolute zero?
A: Carbon
B: Tungsten
C: Hafnium carbonitride
D: Helium
E: Mercury
Answer: D

Question: What is the melting point of ice at 1 atmosphere of pressure?
A: 0 °C
B: -38.83 °C
C: 85 °C
D: 234.32 kelvins
E: 3,414 °C
Answer: A
@
Tungsten (also called wolfram)[9][10] is a chemical element with the symbol W and atomic number 74. Tungsten is a rare metal found naturally on Earth almost exclusively as compounds with other elements. It was identified as a new element in 1781 and first isolated as a metal in 1783. Its important ores include scheelite and wolframite, the latter lending the element its alternate name.

The free element is remarkable for its robustness, especially the fact that it has the highest melting point of all known elements, melting at 3,422 °C (6,192 °F; 3,695 K). It also has the highest boiling point, at 5,930 °C (10,706 °F; 6,203 K).[11] Its density is 19.30 grams per cubic centimetre (0.697 lb/cu in),[12] comparable with that of uranium and gold, and much higher (about 1.7 times) than that of lead.[13] Polycrystalline tungsten is an intrinsically brittle[14][15][16] and hard material (under standard conditions, when uncombined), making it difficult to work into metal. However, pure single-crystalline tungsten is more ductile and can be cut with a hard-steel hacksaw.[17]

Tungsten occurs in many alloys, which have numerous applications, including incandescent light bulb filaments, X-ray tubes, electrodes in gas tungsten arc welding, superalloys, and radiation shielding. Tungsten's hardness and high density make it suitable for military applications in penetrating projectiles. Tungsten compounds are often used as industrial catalysts.

Tungsten is the only metal in the third transition series that is known to occur in biomolecules, being found in a few species of bacteria and archaea. However, tungsten interferes with molybdenum and copper metabolism and is somewhat toxic to most forms of animal life.[18][19]
$
10
Question: What is the chemical symbol for tungsten?
A: W
B: T
C: Ta
D: Au
E: Ag
Answer: A

Question: What is the atomic number of tungsten?
A: 74
B: 10
C: 92
D: 26
E: 33
Answer: A

Question: Which element has the highest melting point among all known elements?
A: Gold
B: Tungsten
C: Uranium
D: Lead
E: Silver
Answer: B

Question: What is the melting point of tungsten?
A: 1,932 °C
B: 2,674 °C
C: 3,695 K
D: 5,930 °C
E: 6,203 K
Answer: C

Question: What is the highest boiling point of tungsten?
A: 1,932 °C
B: 2,674 °C
C: 3,695 K
D: 5,930 °C
E: 6,203 K
Answer: D

Question: What is the density of tungsten?
A: 0.697 lb/cu in
B: 1.30 g/cm³
C: 19.30 g/cm³
D: 10.0 g/cm³
E: 7.85 g/cm³
Answer: C

Question: Which property makes tungsten difficult to work into metal?
A: High ductility
B: Low melting point
C: Low density
D: Brittleness
E: Low hardness
Answer: D

Question: What is the intrinsically brittle property of tungsten associated with?
A: Polycrystalline tungsten
B: Low boiling point
C: High ductility
D: Low density
E: Low hardness
Answer: A

Question: In what applications are tungsten compounds often used?
A: Superconductors
B: Agricultural fertilizers
C: Industrial catalysts
D: Cosmetics
E: Food additives
Answer: C

Question: What is the only metal in the third transition series known to occur in biomolecules?
A: Gold
B: Tungsten
C: Uranium
D: Silver
E: Platinum
Answer: B
@
Tungsten is a mostly non-reactive element: it does not react with water, is immune to attack by most acids and bases, and does not react with oxygen or air at room temperature. At elevated temperatures (i.e., when red-hot) it reacts with oxygen to form the trioxide compound tungsten(VI), WO3. It will, however, react directly with fluorine (F2) at room temperature to form tungsten(VI) fluoride (WF6), a colorless gas. At around 250 °C it will react with chlorine or bromine, and under certain hot conditions will react with iodine. Finely divided tungsten is pyrophoric.[33][34]

The most common formal oxidation state of tungsten is +6, but it exhibits all oxidation states from −2 to +6.[34][35] Tungsten typically combines with oxygen to form the yellow tungstic oxide, WO3, which dissolves in aqueous alkaline solutions to form tungstate ions, WO2−
4.

Tungsten carbides (W2C and WC) are produced by heating powdered tungsten with carbon. W2C is resistant to chemical attack, although it reacts strongly with chlorine to form tungsten hexachloride (WCl6).[13]

In aqueous solution, tungstate gives the heteropoly acids and polyoxometalate anions under neutral and acidic conditions. As tungstate is progressively treated with acid, it first yields the soluble, metastable "paratungstate A" anion, W
7O6−
24, which over time converts to the less soluble "paratungstate B" anion, H
2W
12O10−
42.[36] Further acidification produces the very soluble metatungstate anion, H
2W
12O6−
40, after which equilibrium is reached. The metatungstate ion exists as a symmetric cluster of twelve tungsten-oxygen octahedra known as the Keggin anion. Many other polyoxometalate anions exist as metastable species. The inclusion of a different atom such as phosphorus in place of the two central hydrogens in metatungstate produces a wide variety of heteropoly acids, such as phosphotungstic acid H3PW12O40.

Tungsten trioxide can form intercalation compounds with alkali metals. These are known as bronzes; an example is sodium tungsten bronze.

In gaseous form, tungsten forms the diatomic species W2. These molecules feature a sextuple bond between tungsten atoms — the highest known bond order among stable atoms.[37][38]
$
10
Question: At elevated temperatures, what compound does tungsten react with oxygen to form?
A: Tungsten trioxide (WO3)
B: Tungsten hexachloride (WCl6)
C: Tungsten carbide (WC)
D: Tungsten fluoride (WF6)
E: Tungstate ions (WO2−4)
Answer: A

Question: Which of the following elements can react directly with tungsten at room temperature to form tungsten(VI) fluoride?
A: Chlorine (Cl)
B: Oxygen (O2)
C: Bromine (Br)
D: Fluorine (F2)
E: Iodine (I2)
Answer: D

Question: What is the most common formal oxidation state of tungsten?
A: -2
B: +2
C: +4
D: +6
E: -6
Answer: D

Question: In aqueous alkaline solutions, what do yellow tungstic oxide, WO3, and powdered tungsten typically form?
A: Tungsten carbides (W2C and WC)
B: Tungsten hexachloride (WCl6)
C: Tungstate ions (WO2−4)
D: Tungsten fluoride (WF6)
E: Tungsten trioxide (WO3)
Answer: C

Question: What is the result of heating powdered tungsten with carbon?
A: Tungsten reacts with iodine.
B: Tungsten forms a diatomic species.
C: Tungsten carbides (W2C and WC) are produced.
D: Tungsten reacts with oxygen to form WO3.
E: Tungsten combines with fluorine to form WF6.
Answer: C

Question: What does tungstate yield in aqueous solution under neutral and acidic conditions?
A: Metastable "paratungstate A" anion, W7O6−24
B: Tungsten trioxide (WO3)
C: Tungsten fluoride (WF6)
D: Sodium tungsten bronze
E: Diatomic species W2
Answer: A

Question: What is the term for the symmetric cluster of twelve tungsten-oxygen octahedra known as the Keggin anion?
A: Metatungstate ion
B: Tungsten trioxide (WO3)
C: Tungsten carbide (WC)
D: Tungsten hexachloride (WCl6)
E: Tungstate ions (WO2−4)
Answer: A

Question: In gaseous form, what diatomic species does tungsten form, featuring the highest known bond order among stable atoms?
A: Tungsten hexachloride (WCl6)
B: Tungsten fluoride (WF6)
C: Sodium tungsten bronze
D: Tungsten carbide (WC)
E: Diatomic species W2
Answer: E

Question: What happens when tungsten is exposed to chlorine or bromine at around 250 °C?
A: Tungsten reacts with oxygen to form WO3.
B: Tungsten reacts with fluorine at room temperature.
C: Tungsten forms tungsten hexachloride (WCl6).
D: Tungsten reacts with iodine under certain hot conditions.
E: Tungsten forms tungstate ions (WO2−4).
Answer: C

Question: What are the heteropoly acids and polyoxometalate anions produced when tungstate is in aqueous solution under neutral and acidic conditions?
A: Tungsten fluoride (WF6)
B: Metastable "paratungstate A" anion, W7O6−24
C: Tungsten trioxide (WO3)
D: Sodium tungsten bronze
E: Metatungstate ion, H2W12O6−40
Answer: A
@
Reserves
The world's reserves of tungsten are 3,200,000 tonnes; they are mostly located in China (1,800,000 t), Canada (290,000 t),[56] Russia (160,000 t), Vietnam (95,000 t) and Bolivia. As of 2017, China, Vietnam and Russia are the leading suppliers with 79,000, 7,200 and 3,100 tonnes, respectively. Canada had ceased production in late 2015 due to the closure of its sole tungsten mine. Meanwhile, Vietnam had significantly increased its output in the 2010s, owing to the major optimization of its domestic refining operations, and overtook Russia and Bolivia.[57]

China remains the world's leader not only in production, but also in export and consumption of tungsten products. Tungsten production is gradually increasing outside China because of the rising demand. Meanwhile, its supply by China is strictly regulated by the Chinese Government, which fights illegal mining and excessive pollution originating from mining and refining processes.[58]

There is a large deposit of tungsten ore on the edge of Dartmoor in the United Kingdom, which was exploited during World War I and World War II as the Hemerdon Mine. Following increases in tungsten prices, this mine was reactivated in 2014,[59] but ceased activities in 2018.[60]

Within the EU, the Austrian Felbertal scheelite deposit is one of the few producing tungsten mines.[61] Portugal is one of Europe's main tungsten producers, with 121 kt of contained tungsten in mineral concentrates from 1910 to 2020, accounting for roughly 3.3% of the global production.[62]

Tungsten is considered to be a conflict mineral due to the unethical mining practices observed in the Democratic Republic of the Congo.[63][64]

Extraction
Tungsten is extracted from its ores in several stages. The ore is eventually converted to tungsten(VI) oxide (WO3), which is heated with hydrogen or carbon to produce powdered tungsten.[41] Because of tungsten's high melting point, it is not commercially feasible to cast tungsten ingots. Instead, powdered tungsten is mixed with small amounts of powdered nickel or other metals, and sintered. During the sintering process, the nickel diffuses into the tungsten, producing an alloy.

Tungsten can also be extracted by hydrogen reduction of WF6:

WF6 + 3 H2 → W + 6 HF
or pyrolytic decomposition:[65]

WF6 → W + 3 F2 (ΔHr = +)
Tungsten is not traded as a futures contract and cannot be tracked on exchanges like the London Metal Exchange. The tungsten industry often uses independent pricing references such as Argus Media or Metal Bulletin as a basis for contracts.[66] The prices are usually quoted for tungsten concentrate or WO3.[57]
$
10
Question: Which country has the highest reserves of tungsten?
A: Canada
B: Vietnam
C: Russia
D: China
E: Bolivia
Answer: D

Question: Which country had ceased tungsten production in late 2015 due to the closure of its sole tungsten mine?
A: Russia
B: China
C: Canada
D: Vietnam
E: Bolivia
Answer: C

Question: What is the leading supplier of tungsten products as of 2017?
A: Vietnam
B: China
C: Russia
D: Canada
E: Bolivia
Answer: B

Question: Which tungsten mine was reactivated in 2014 but ceased activities in 2018 due to changes in tungsten prices?
A: Felbertal scheelite deposit in Austria
B: Dartmoor mine in the United Kingdom
C: Hemerdon Mine in the United Kingdom
D: Russian tungsten mine
E: Canadian tungsten mine
Answer: C

Question: What is the unethical mining practice in the Democratic Republic of the Congo that makes tungsten a conflict mineral?
A: Pollution from tungsten mining
B: Excessive tungsten production
C: Illegal mining of tungsten
D: Unregulated tungsten exports
E: Unethical tungsten pricing
Answer: C

Question: How is tungsten extracted from its ores?
A: By casting tungsten ingots directly from the ore
B: By sintering powdered tungsten with other metals
C: By dissolving the ore in acid
D: By subjecting the ore to high-pressure conditions
E: By smelting the ore with carbon
Answer: B

Question: What is tungsten(VI) oxide (WO3) converted into to produce powdered tungsten?
A: Tungsten ingots
B: Tungsten hexafluoride (WF6)
C: Tungsten carbide (WC)
D: Tungsten dioxide (WO2)
E: Tungsten alloy
Answer: E

Question: Which process involves the reduction of WF6 to produce tungsten?
A: Sintering
B: Pyrolytic decomposition
C: Smelting
D: Electrolysis
E: Casting
Answer: B

Question: How is tungsten typically priced in the industry?
A: As tungsten concentrate
B: As tungsten futures contracts
C: As tungsten ingots
D: As tungsten oxides
E: As tungsten alloy
Answer: A

Question: What are independent pricing references used by the tungsten industry as a basis for contracts?
A: Tungsten exchanges
B: Tungsten ingot prices
C: Tungsten futures contracts
D: Tungsten concentrate prices
E: Tungsten alloy prices
Answer: D
@
Applications

Close-up of a tungsten filament inside a halogen lamp

Tungsten carbide jewelry
Approximately half of the tungsten is consumed for the production of hard materials – namely tungsten carbide – with the remaining major use being in alloys and steels. Less than 10% is used in other chemical compounds.[67] Because of the high ductile-brittle transition temperature of tungsten, its products are conventionally manufactured through powder metallurgy, spark plasma sintering, chemical vapor deposition, hot isostatic pressing, and thermoplastic routes. A more flexible manufacturing alternative is selective laser melting, which is a form of 3D printing and allows creating complex three-dimensional shapes.[68]

Industrial
Tungsten is mainly used in the production of hard materials based on tungsten carbide (WC), one of the hardest carbides. WC is an efficient electrical conductor, but W2C is less so. WC is used to make wear-resistant abrasives, and "carbide" cutting tools such as knives, drills, circular saws, dies, milling and turning tools used by the metalworking, woodworking, mining, petroleum and construction industries.[13] Carbide tooling is actually a ceramic/metal composite, where metallic cobalt acts as a binding (matrix) material to hold the WC particles in place. This type of industrial use accounts for about 60% of current tungsten consumption.[69]

The jewelry industry makes rings of sintered tungsten carbide, tungsten carbide/metal composites, and also metallic tungsten.[70] WC/metal composite rings use nickel as the metal matrix in place of cobalt because it takes a higher luster when polished. Sometimes manufacturers or retailers refer to tungsten carbide as a metal, but it is a ceramic.[71] Because of tungsten carbide's hardness, rings made of this material are extremely abrasion resistant, and will hold a burnished finish longer than rings made of metallic tungsten. Tungsten carbide rings are brittle, however, and may crack under a sharp blow.[72]

Military
Tungsten, usually alloyed with nickel, iron, or cobalt to form heavy alloys, is used in kinetic energy penetrators as an alternative to depleted uranium, in applications where uranium's radioactivity is problematic even in depleted form, or where uranium's additional pyrophoric properties are not desired (for example, in ordinary small arms bullets designed to penetrate body armor). Similarly, tungsten alloys have also been used in shells, grenades, and missiles, to create supersonic shrapnel. Germany used tungsten during World War II to produce shells for anti-tank gun designs using the Gerlich squeeze bore principle to achieve very high muzzle velocity and enhanced armor penetration from comparatively small caliber and light weight field artillery. The weapons were highly effective but a shortage of tungsten used in the shell core, caused in part by the Wolfram Crisis, limited their use.[citation needed]

Tungsten has also been used in Dense inert metal explosives, which use it as dense powder to reduce collateral damage while increasing the lethality of explosives within a small radius.[77]
$
10
Question: What is the primary use of tungsten carbide in industrial applications?
A: To create jewelry
B: As an efficient electrical conductor
C: To make wear-resistant abrasives and cutting tools
D: In chemical compounds
E: As a binding material in ceramics
Answer: C

Question: What is the binding material that holds tungsten carbide particles in place in carbide tooling?
A: Cobalt
B: Iron
C: Nickel
D: Tungsten
E: Chromium
Answer: A

Question: What type of manufacturing allows for the creation of complex three-dimensional shapes using tungsten?
A: Powder metallurgy
B: Chemical vapor deposition
C: 3D printing (selective laser melting)
D: Thermoplastic routes
E: Hot isostatic pressing
Answer: C

Question: In the jewelry industry, which metal is often used as the matrix in tungsten carbide/metal composite rings?
A: Cobalt
B: Iron
C: Nickel
D: Tungsten
E: Chromium
Answer: C

Question: What are kinetic energy penetrators made of tungsten used for?
A: Creating supersonic shrapnel
B: Reducing collateral damage in explosives
C: Penetrating body armor
D: Enhancing the lethality of explosives
E: Producing high muzzle velocity in artillery shells
Answer: C

Question: Why is tungsten sometimes used as an alternative to depleted uranium in kinetic energy penetrators?
A: Tungsten is less expensive than depleted uranium.
B: Tungsten is more readily available than depleted uranium.
C: Tungsten is less dense than depleted uranium.
D: Depleted uranium is highly radioactive.
E: Depleted uranium is pyrophoric.
Answer: D

Question: What role did tungsten play in Germany's anti-tank gun designs during World War II?
A: Tungsten was used to create armor-piercing bullets.
B: Tungsten was used to produce supersonic shrapnel.
C: Tungsten was used to increase the lethality of explosives.
D: Tungsten was used as the shell core material.
E: Tungsten was used to reduce collateral damage in explosives.
Answer: D

Question: How are tungsten alloys used in shells, grenades, and missiles to increase their effectiveness?
A: By making them highly radioactive
B: By creating supersonic shrapnel
C: By reducing collateral damage
D: By increasing their lethality within a small radius
E: By enhancing their armor-penetrating capabilities
Answer: D

Question: What is the primary use of tungsten in military applications when alloyed with nickel, iron, or cobalt?
A: To create dense inert metal explosives
B: To make jewelry
C: To increase the radioactivity of ammunition
D: To reduce the effectiveness of explosives
E: To form heavy alloys for penetrators and shells
Answer: E

Question: How is tungsten used in Dense inert metal explosives (DIME)?
A: It is used to reduce the density of explosives.
B: It is used as a binding material for explosives.
C: It is used as a dense powder to increase lethality within a small radius.
D: It is used to enhance the blast radius of explosives.
E: It is used to decrease the pyrophoric properties of explosives.
Answer: C
@
Biological role
Tungsten, at atomic number Z = 74, is the heaviest element known to be biologically functional. It is used by some bacteria and archaea,[110] but not in eukaryotes. For example, enzymes called oxidoreductases use tungsten similarly to molybdenum by using it in a tungsten-pterin complex with molybdopterin (molybdopterin, despite its name, does not contain molybdenum, but may complex with either molybdenum or tungsten in use by living organisms). Tungsten-using enzymes typically reduce carboxylic acids to aldehydes.[111] The tungsten oxidoreductases may also catalyse oxidations. The first tungsten-requiring enzyme to be discovered also requires selenium, and in this case the tungsten-selenium pair may function analogously to the molybdenum-sulfur pairing of some molybdopterin-requiring enzymes.[112] One of the enzymes in the oxidoreductase family which sometimes employ tungsten (bacterial formate dehydrogenase H) is known to use a selenium-molybdenum version of molybdopterin.[113] Acetylene hydratase is an unusual metalloenzyme in that it catalyzes a hydration reaction. Two reaction mechanisms have been proposed, in one of which there is a direct interaction between the tungsten atom and the C≡C triple bond.[114] Although a tungsten-containing xanthine dehydrogenase from bacteria has been found to contain tungsten-molydopterin and also non-protein bound selenium, a tungsten-selenium molybdopterin complex has not been definitively described.[115]

In soil, tungsten metal oxidizes to the tungstate anion. It can be selectively or non-selectively imported by some prokaryotic organisms and may substitute for molybdate in certain enzymes. Its effect on the action of these enzymes is in some cases inhibitory and in others positive.[116] The soil's chemistry determines how the tungsten polymerizes; alkaline soils cause monomeric tungstates; acidic soils cause polymeric tungstates.[117]

Sodium tungstate and lead have been studied for their effect on earthworms. Lead was found to be lethal at low levels and sodium tungstate was much less toxic, but the tungstate completely inhibited their reproductive ability.[118]

Tungsten has been studied as a biological copper metabolic antagonist, in a role similar to the action of molybdenum. It has been found that tetrathiotungstate [zh] salts may be used as biological copper chelation chemicals, similar to the tetrathiomolybdates.[119]

In archaea
Tungsten is essential for some archaea. The following tungsten-utilizing enzymes are known:

Aldehyde ferredoxin oxidoreductase (AOR) in Thermococcus strain ES-1
Formaldehyde ferredoxin oxidoreductase (FOR) in Thermococcus litoralis
Glyceraldehyde-3-phosphate ferredoxin oxidoreductase (GAPOR) in Pyrococcus furiosus
A wtp system is known to selectively transport tungsten in archaea:

WtpA is tungsten-binding protein of ABC family of transporters
WptB is a permease
WtpC is ATPase[120]
$
10
Question: Which group of organisms does not use tungsten in biological processes?
A: Eukaryotes
B: Archaea
C: Bacteria
D: Prokaryotes
E: Soil microorganisms
Answer: A

Question: What is the primary function of tungsten-pterin complexes in enzymes?
A: Catalyzing hydration reactions
B: Reducing carboxylic acids to aldehydes
C: Binding with molybdopterin
D: Transporting tungsten in cells
E: Complexing with selenium
Answer: B

Question: Which element may function analogously to tungsten in certain enzymes that require both tungsten and selenium?
A: Molybdenum
B: Lead
C: Copper
D: Sodium
E: Iron
Answer: A

Question: How does the soil's chemistry affect the polymerization of tungsten?
A: Acidic soils cause monomeric tungstates.
B: Alkaline soils cause polymeric tungstates.
C: Alkaline soils cause monomeric tungstates.
D: Acidic soils cause lead to polymerize.
E: Tungsten does not polymerize in soil.
Answer: B

Question: What was the effect of sodium tungstate on earthworms in a study?
A: It was lethal at low levels.
B: It had no impact on earthworms.
C: It completely inhibited their reproductive ability.
D: It improved their reproductive ability.
E: It caused lead to be less toxic to earthworms.
Answer: C

Question: What role does tungsten play as a biological copper metabolic antagonist?
A: It enhances copper metabolism.
B: It has no effect on copper metabolism.
C: It chelates copper ions.
D: It promotes copper toxicity.
E: It inhibits copper chelation.
Answer: C

Question: Which group of microorganisms requires tungsten for biological processes?
A: Eukaryotes
B: Archaea
C: Bacteria
D: Prokaryotes
E: Fungi
Answer: B

Question: What is the function of the WtpA, WptB, and WtpC system in archaea?
A: Catalyzing hydration reactions
B: Transporting tungsten in cells
C: Binding with molybdopterin
D: Inhibiting tungsten transport
E: Promoting copper metabolism
Answer: B
@
Uranium is a chemical element with symbol U and atomic number 92. It is a silvery-grey metal in the actinide series of the periodic table. A uranium atom has 92 protons and 92 electrons, of which 6 are valence electrons. Uranium radioactively decays by emitting an alpha particle. The half-life of this decay varies between 159,200 and 4.5 billion years for different isotopes, making them useful for dating the age of the Earth. The most common isotopes in natural uranium are uranium-238 (which has 146 neutrons and accounts for over 99% of uranium on Earth) and uranium-235 (which has 143 neutrons). Uranium has the highest atomic weight of the primordially occurring elements. Its density is about 70% higher than that of lead, and slightly lower than that of gold or tungsten. It occurs naturally in low concentrations of a few parts per million in soil, rock and water, and is commercially extracted from uranium-bearing minerals such as uraninite.[6]

Many contemporary uses of uranium exploit its unique nuclear properties. Uranium-235 is the only naturally occurring fissile isotope, which makes it widely used in nuclear power plants and nuclear weapons. However, because of the extreme dearth of concentrations of uranium-235 in naturally occurring uranium (which is, overwhelmingly, mostly uranium-238), uranium needs to undergo enrichment so that enough uranium-235 is present. Uranium-238 is fissionable by fast neutrons, and is fertile, meaning it can be transmuted to fissile plutonium-239 in a nuclear reactor. Another fissile isotope, uranium-233, can be produced from natural thorium and is studied for future industrial use in nuclear technology. Uranium-238 has a small probability for spontaneous fission or even induced fission with fast neutrons; uranium-235, and to a lesser degree uranium-233, have a much higher fission cross-section for slow neutrons. In sufficient concentration, these isotopes maintain a sustained nuclear chain reaction. This generates the heat in nuclear power reactors, and produces the fissile material for nuclear weapons. Depleted uranium (238U) is used in kinetic energy penetrators and armor plating.[7][8]

The 1789 discovery of uranium in the mineral pitchblende is credited to Martin Heinrich Klaproth, who named the new element after the recently discovered planet Uranus. Eugène-Melchior Péligot was the first person to isolate the metal and its radioactive properties were discovered in 1896 by Henri Becquerel. Research by Otto Hahn, Lise Meitner, Enrico Fermi and others, such as J. Robert Oppenheimer starting in 1934 led to its use as a fuel in the nuclear power industry and in Little Boy, the first nuclear weapon used in war. An ensuing arms race during the Cold War between the United States and the Soviet Union produced tens of thousands of nuclear weapons that used uranium metal and uranium-derived plutonium-239. Dismantling of these weapons and related nuclear facilities is carried out within various nuclear disarmament programs and costs billions of dollars. Weapon-grade uranium obtained from nuclear weapons is diluted with uranium-238 and reused as fuel for nuclear reactors. The development and deployment of these nuclear reactors continue on a global base as they are powerful sources of CO2-free energy. Spent nuclear fuel forms radioactive waste, which mostly consists of uranium-238 and poses significant health threat and environmental impact.
$
10
Question: What is the atomic number of uranium?
A: 92
B: 235
C: 238
D: 146
E: 143
Answer: A

Question: Which isotope of uranium is widely used in nuclear power plants and nuclear weapons?
A: Uranium-238
B: Uranium-235
C: Uranium-233
D: Plutonium-239
E: Depleted uranium
Answer: B

Question: Who discovered uranium in the mineral pitchblende in 1789?
A: Henri Becquerel
B: Enrico Fermi
C: Eugène-Melchior Péligot
D: Martin Heinrich Klaproth
E: J. Robert Oppenheimer
Answer: D

Question: What is the primary method used to extract uranium commercially?
A: Mining
B: Chemical synthesis
C: Biological extraction
D: Condensation
E: Sublimation
Answer: A

Question: What is the main use of depleted uranium (238U)?
A: Nuclear reactor fuel
B: Nuclear weapons
C: Armor plating
D: Nuclear chain reactions
E: Radioactive waste
Answer: C

Question: Which isotope of uranium can be produced from natural thorium?
A: Uranium-238
B: Uranium-235
C: Uranium-233
D: Plutonium-239
E: Depleted uranium
Answer: C

Question: Who discovered the radioactive properties of uranium in 1896?
A: Henri Becquerel
B: Martin Heinrich Klaproth
C: Enrico Fermi
D: Eugène-Melchior Péligot
E: J. Robert Oppenheimer
Answer: A

Question: What element was uranium named after?
A: Pluto
B: Neptune
C: Jupiter
D: Saturn
E: Uranus
Answer: E

Question: Which uranium isotope has the highest fission cross-section for slow neutrons?
A: Uranium-238
B: Uranium-235
C: Uranium-233
D: Plutonium-239
E: Depleted uranium
Answer: B

Question: What did the arms race during the Cold War between the United States and the Soviet Union lead to?
A: Discovery of uranium isotopes
B: Nuclear disarmament programs
C: Development of peaceful nuclear reactors
D: Production of tens of thousands of nuclear weapons
E: Elimination of radioactive waste
Answer: D
@
Uranium is a silvery white, weakly radioactive metal. It has a Mohs hardness of 6, sufficient to scratch glass and approximately equal to that of titanium, rhodium, manganese and niobium. It is malleable, ductile, slightly paramagnetic, strongly electropositive and a poor electrical conductor.[9][10] Uranium metal has a very high density of 19.1 g/cm3,[11] denser than lead (11.3 g/cm3),[12] but slightly less dense than tungsten and gold (19.3 g/cm3).[13][14]

Uranium metal reacts with almost all non-metal elements (with the exception of the noble gases) and their compounds, with reactivity increasing with temperature.[15] Hydrochloric and nitric acids dissolve uranium, but non-oxidizing acids other than hydrochloric acid attack the element very slowly.[9] When finely divided, it can react with cold water; in air, uranium metal becomes coated with a dark layer of uranium oxide.[10] Uranium in ores is extracted chemically and converted into uranium dioxide or other chemical forms usable in industry.

Uranium-235 was the first isotope that was found to be fissile. Other naturally occurring isotopes are fissionable, but not fissile. On bombardment with slow neutrons, its uranium-235 isotope will most of the time divide into two smaller nuclei, releasing nuclear binding energy and more neutrons. If too many of these neutrons are absorbed by other uranium-235 nuclei, a nuclear chain reaction occurs that results in a burst of heat or (in special circumstances) an explosion. In a nuclear reactor, such a chain reaction is slowed and controlled by a neutron poison, absorbing some of the free neutrons. Such neutron absorbent materials are often part of reactor control rods (see nuclear reactor physics for a description of this process of reactor control).

As little as 15 lb (6.8 kg) of uranium-235 can be used to make an atomic bomb.[16] The nuclear weapon detonated over Hiroshima, called Little Boy, relied on uranium fission. However, the first nuclear bomb (the Gadget used at Trinity) and the bomb that was detonated over Nagasaki (Fat Man) were both plutonium bombs.

Uranium metal has three allotropic forms:[17]

α (orthorhombic) stable up to 668 °C (1,234 °F). Orthorhombic, space group No. 63, Cmcm, lattice parameters a = 285.4 pm, b = 587 pm, c = 495.5 pm.[18]
β (tetragonal) stable from 668 to 775 °C (1,234 to 1,427 °F). Tetragonal, space group P42/mnm, P42nm, or P4n2, lattice parameters a = 565.6 pm, b = c = 1075.9 pm.[18]
γ (body-centered cubic) from 775 °C (1,427 °F) to melting point—this is the most malleable and ductile state. Body-centered cubic, lattice parameter a = 352.4 pm.[18]
$
10
Question: What is the Mohs hardness of uranium?
A: 6
B: 11.3
C: 19.1
D: 19.3
E: 352.4
Answer: A

Question: Which of the following materials has a density slightly less than uranium?
A: Lead
B: Titanium
C: Rhodium
D: Manganese
E: Tungsten
Answer: B

Question: What happens when uranium metal reacts with cold water?
A: It becomes paramagnetic.
B: It becomes strongly electropositive.
C: It dissolves rapidly.
D: It reacts slowly.
E: It forms a dark layer of uranium oxide.
Answer: D

Question: What is the primary use of uranium-235 in nuclear weapons?
A: To absorb neutrons
B: To serve as a neutron poison
C: To control nuclear chain reactions
D: To release nuclear binding energy
E: To act as a reactor control rod
Answer: D

Question: Which isotope of uranium is fissile?
A: Uranium-235
B: Uranium-238
C: Plutonium-239
D: Uranium-233
E: Uranium-234
Answer: A

Question: What type of bomb did the nuclear weapon detonated over Hiroshima rely on?
A: Plutonium bomb
B: Uranium-235 bomb
C: Neutron bomb
D: Hydrogen bomb
E: Nitrogen bomb
Answer: B

Question: At what temperature is the γ (body-centered cubic) form of uranium stable?
A: 668 °C
B: 775 °C
C: 1,427 °F
D: 1,234 °F
E: Melting point
Answer: B

Question: What is the lattice parameter for the β (tetragonal) form of uranium?
A: 285.4 pm
B: 587 pm
C: 565.6 pm
D: 1075.9 pm
E: 352.4 pm
Answer: D

Question: What element is used as a neutron poison in nuclear reactors to slow and control chain reactions?
A: Plutonium
B: Uranium-235
C: Neptunium
D: Thorium
E: Control rods
Answer: E

Question: Which uranium allotropic form is the most malleable and ductile?
A: α (orthorhombic)
B: β (tetragonal)
C: γ (body-centered cubic)
D: δ (hexagonal)
E: ζ (monoclinic)
Answer: C
@
Oxides
Calcined uranium yellowcake, as produced in many large mills, contains a distribution of uranium oxidation species in various forms ranging from most oxidized to least oxidized. Particles with short residence times in a calciner will generally be less oxidized than those with long retention times or particles recovered in the stack scrubber. Uranium content is usually referenced to U
3O
8, which dates to the days of the Manhattan Project when U
3O
8 was used as an analytical chemistry reporting standard.[105]

Phase relationships in the uranium-oxygen system are complex. The most important oxidation states of uranium are uranium(IV) and uranium(VI), and their two corresponding oxides are, respectively, uranium dioxide (UO
2) and uranium trioxide (UO
3).[106] Other uranium oxides such as uranium monoxide (UO), diuranium pentoxide (U
2O
5), and uranium peroxide (UO
4·2H
2O) also exist.

The most common forms of uranium oxide are triuranium octoxide (U
3O
8) and UO
2.[107] Both oxide forms are solids that have low solubility in water and are relatively stable over a wide range of environmental conditions. Triuranium octoxide is (depending on conditions) the most stable compound of uranium and is the form most commonly found in nature. Uranium dioxide is the form in which uranium is most commonly used as a nuclear reactor fuel.[107] At ambient temperatures, UO
2 will gradually convert to U
3O
8. Because of their stability, uranium oxides are generally considered the preferred chemical form for storage or disposal.[107]
$
10
Question: Which oxide form of uranium is most commonly used as a nuclear reactor fuel?
A: Uranium trioxide (UO3)
B: Uranium monoxide (UO)
C: Uranium dioxide (UO2)
D: Diuranium pentoxide (U2O5)
E: Uranium peroxide (UO4·2H2O)
Answer: C

Question: What is the most stable compound of uranium under certain conditions?
A: Uranium dioxide (UO2)
B: Uranium trioxide (UO3)
C: Triuranium octoxide (U3O8)
D: Uranium peroxide (UO4·2H2O)
E: Uranium monoxide (UO)
Answer: C

Question: Which uranium oxide is generally considered the preferred chemical form for storage or disposal due to its stability?
A: Uranium trioxide (UO3)
B: Uranium monoxide (UO)
C: Uranium dioxide (UO2)
D: Diuranium pentoxide (U2O5)
E: Uranium peroxide (UO4·2H2O)
Answer: C

Question: What is the uranium content usually referenced to in yellowcake?
A: UO2
B: U2O5
C: U3O8
D: UO
E: UO4·2H2O
Answer: C

Question: What are the two most important oxidation states of uranium?
A: Uranium monoxide (UO) and uranium peroxide (UO4·2H2O)
B: Uranium dioxide (UO2) and uranium trioxide (UO3)
C: Uranium dioxide (UO2) and diuranium pentoxide (U2O5)
D: Triuranium octoxide (U3O8) and uranium trioxide (UO3)
E: Uranium dioxide (UO2) and uranium peroxide (UO4·2H2O)
Answer: B

Question: At ambient temperatures, what will UO2 gradually convert to?
A: Uranium trioxide (UO3)
B: Uranium monoxide (UO)
C: Triuranium octoxide (U3O8)
D: Uranium dioxide (UO2)
E: Uranium peroxide (UO4·2H2O)
Answer: C

Question: Which uranium oxide is the form most commonly found in nature?
A: Uranium monoxide (UO)
B: Uranium trioxide (UO3)
C: Triuranium octoxide (U3O8)
D: Uranium dioxide (UO2)
E: Uranium peroxide (UO4·2H2O)
Answer: C

Question: What does U3O8 stand for?
A: Uranium dioxide
B: Uranium trioxide
C: Uranium monoxide
D: Triuranium octoxide
E: Uranium peroxide
Answer: D

Question: Which uranium oxide is the most commonly used analytical chemistry reporting standard?
A: Uranium dioxide (UO2)
B: Uranium trioxide (UO3)
C: Uranium monoxide (UO)
D: Diuranium pentoxide (U2O5)
E: Uranium peroxide (UO4·2H2O)
Answer: B

Question: What is the primary form of uranium used as a nuclear reactor fuel?
A: Uranium monoxide (UO)
B: Uranium trioxide (UO3)
C: Diuranium pentoxide (U2O5)
D: Uranium dioxide (UO2)
E: Uranium peroxide (UO4·2H2O)
Answer: D
@
Uranium as it is taken directly from the Earth is not suitable as fuel for most nuclear reactors and requires additional processes to make it usable (CANDU design is a notable exception). Uranium is mined either underground or in an open pit depending on the depth at which it is found. After the uranium ore is mined, it must go through a milling process to extract the uranium from the ore.

This is accomplished by a combination of chemical processes with the end product being concentrated uranium oxide, which is known as "yellowcake", contains roughly 80% uranium whereas the original ore typically contains as little as 0.1% uranium.[3]

After the milling process is complete, the uranium must next undergo a process of conversion, "to either uranium dioxide, which can be used as the fuel for those types of reactors that do not require enriched uranium, or into uranium hexafluoride, which can be enriched to produce fuel for the majority of types of reactors".[4] Naturally-occurring uranium is made of a mixture of 235U and 238U. The 235U is fissile, meaning it is easily split with neutrons while the remainder is 238U, but in nature, more than 99% of the extracted ore is 238U. Most nuclear reactors require enriched uranium, which is uranium with higher concentrations of 235U ranging between 3.5% and 4.5% (although a few reactor designs using a graphite or heavy water moderator, such as the RBMK and CANDU, are capable of operating with natural uranium as fuel). There are two commercial enrichment processes: gaseous diffusion and gas centrifugation. Both enrichment processes involve the use of uranium hexafluoride and produce enriched uranium oxide.

Reprocessed uranium (RepU) is a product of nuclear fuel cycles involving nuclear reprocessing of spent fuel. RepU recovered from light water reactor (LWR) spent fuel typically contains slightly more 235U than natural uranium, and therefore could be used to fuel reactors that customarily use natural uranium as fuel, such as CANDU reactors. It also contains the undesirable isotope uranium-236, which undergoes neutron capture, wasting neutrons (and requiring higher 235U enrichment) and creating neptunium-237, which would be one of the more mobile and troublesome radionuclides in deep geological repository disposal of nuclear waste.

Low-enriched uranium (LEU) has a lower than 20% concentration of 235U; for instance, in commercial LWR, the most prevalent power reactors in the world, uranium is enriched to 3 to 5% 235U. Slightly enriched uranium (SEU) has a concentration of under 2% 235U.[5]

High-assay LEU (HALEU) is enriched between 5% and 20%.[6] Fresh LEU used in research reactors is usually enriched between 12% and 19.75% 235U; the latter concentration is used to replace HEU fuels when converting to LEU.[7]

Highly enriched uranium (HEU) has a 20% or higher concentration of 235U. The fissile uranium in nuclear weapon primaries usually contains 85% or more of 235U known as weapons grade, though theoretically for an implosion design, a minimum of 20% could be sufficient (called weapon-usable) although it would require hundreds of kilograms of material and "would not be practical to design";[8][9] even lower enrichment is hypothetically possible, but as the enrichment percentage decreases the critical mass for unmoderated fast neutrons rapidly increases, with for example, an infinite mass of 5.4% 235U being required.[8] For criticality experiments, enrichment of uranium to over 97% has been accomplished.[10]
$
10
Question: What is the end product of the milling process used to extract uranium from ore?
A: Uranium hexafluoride
B: Highly enriched uranium
C: Low-enriched uranium
D: Reprocessed uranium
E: Yellowcake
Answer: E

Question: What is the main difference between 235U and 238U in terms of their nuclear properties?
A: 235U is more stable.
B: 238U is fissile.
C: 235U is easily split with neutrons.
D: 238U is enriched uranium.
E: 235U is more common in nature.
Answer: C

Question: Which type of uranium is typically used as fuel in most nuclear reactors?
A: Reprocessed uranium
B: Highly enriched uranium
C: Low-enriched uranium
D: Slightly enriched uranium
E: Fresh LEU
Answer: C

Question: What is the primary purpose of the conversion process for uranium after milling?
A: To create highly enriched uranium
B: To produce uranium dioxide
C: To extract uranium hexafluoride
D: To reduce the concentration of 235U
E: To convert uranium to yellowcake
Answer: B

Question: Which enrichment process involves the use of uranium hexafluoride?
A: Gaseous diffusion
B: Natural enrichment
C: Reprocessing
D: Conversion
E: Milling
Answer: A

Question: What is the concentration range of 235U in low-enriched uranium (LEU)?
A: Above 20%
B: Between 12% and 19.75%
C: Less than 2%
D: 3.5% to 4.5%
E: 85% or more
Answer: B

Question: What is the enrichment level of highly enriched uranium (HEU)?
A: Below 2%
B: Between 5% and 20%
C: 20% or higher
D: 3.5% to 4.5%
E: 12% to 19.75%
Answer: C

Question: What is the primary use of highly enriched uranium (HEU) in nuclear weapon primaries?
A: To create yellowcake
B: To fuel research reactors
C: To produce natural uranium
D: To facilitate nuclear reprocessing
E: To achieve criticality in nuclear weapons
Answer: E

Question: What is the purpose of reprocessing uranium (RepU) recovered from spent fuel?
A: To create highly enriched uranium
B: To extract uranium hexafluoride
C: To dispose of nuclear waste
D: To convert it into yellowcake
E: To fuel CANDU reactors
Answer: E

Question: What concentration of 235U is typically found in fresh LEU used in research reactors?
A: Less than 2%
B: Between 5% and 20%
C: Above 20%
D: 3.5% to 4.5%
E: 12% to 19.75%
Answer: E
@
Gaseous diffusion is a technology that was used to produce enriched uranium by forcing gaseous uranium hexafluoride (UF6) through microporous membranes. This produces a slight separation (enrichment factor 1.0043) between the molecules containing uranium-235 (235U) and uranium-238 (238U). By use of a large cascade of many stages, high separations can be achieved. It was the first process to be developed that was capable of producing enriched uranium in industrially useful quantities, but is nowadays considered obsolete, having been superseded by the more-efficient gas centrifuge process.[1]

Gaseous diffusion was devised by Francis Simon and Nicholas Kurti at the Clarendon Laboratory in 1940, tasked by the MAUD Committee with finding a method for separating uranium-235 from uranium-238 in order to produce a bomb for the British Tube Alloys project. The prototype gaseous diffusion equipment itself was manufactured by Metropolitan-Vickers (MetroVick) at Trafford Park, Manchester, at a cost of £150,000 for four units, for the M. S. Factory, Valley. This work was later transferred to the United States when the Tube Alloys project became subsumed by the later Manhattan Project.[2]

Of the 33 known radioactive primordial nuclides, two (235U and 238U) are isotopes of uranium. These two isotopes are similar in many ways, except that only 235U is fissile (capable of sustaining a nuclear chain reaction of nuclear fission with thermal neutrons). In fact, 235U is the only naturally occurring fissile nucleus.[3] Because natural uranium is only about 0.72% 235U by mass, it must be enriched to a concentration of 2–5% to be able to support a continuous nuclear chain reaction[4] when normal water is used as the moderator. The product of this enrichment process is called enriched uranium.

Scientific basis
Gaseous diffusion is based on Graham's law, which states that the rate of effusion of a gas is inversely proportional to the square root of its molecular mass. For example, in a box with a microporous membrane containing a mixture of two gases, the lighter molecules will pass out of the container more rapidly than the heavier molecules, if the pore diameter is smaller than the mean free path length (molecular flow). The gas leaving the container is somewhat enriched in the lighter molecules, while the residual gas is somewhat depleted. A single container wherein the enrichment process takes place through gaseous diffusion is called a diffuser.
$
10
Question: What is the primary purpose of gaseous diffusion technology?
A: To enrich uranium hexafluoride
B: To produce enriched uranium
C: To produce uranium hexafluoride
D: To separate uranium-235 from uranium-238
E: To create a nuclear chain reaction
Answer: B

Question: Who devised the gaseous diffusion technology for separating uranium isotopes?
A: Francis Simon
B: Nicholas Kurti
C: Graham
D: Metropolitan-Vickers
E: Manhattan Project
Answer: A

Question: What is the enrichment factor achieved by gaseous diffusion?
A: 1.0043
B: 1.01
C: 2–5%
D: 0.72%
E: 33%
Answer: A

Question: What was the main goal of the British Tube Alloys project that led to the development of gaseous diffusion technology?
A: To manufacture nuclear reactors
B: To produce enriched uranium
C: To create a nuclear chain reaction
D: To develop the atomic bomb
E: To extract uranium hexafluoride
Answer: D

Question: Which isotope of uranium is fissile and capable of sustaining a nuclear chain reaction?
A: 235U
B: 238U
C: 233U
D: 234U
E: 239U
Answer: A

Question: What is the primary difference between 235U and 238U?
A: 238U is fissile, while 235U is not.
B: 235U is the only naturally occurring fissile nucleus.
C: 235U is less abundant in nature than 238U.
D: 238U has a shorter half-life than 235U.
E: 238U is used as a moderator in nuclear reactors.
Answer: B

Question: In gaseous diffusion, what property of gas molecules is utilized to achieve enrichment?
A: Molecular mass
B: Molecular shape
C: Molecular charge
D: Molecular density
E: Molecular volume
Answer: A

Question: What does Graham's law state regarding the rate of effusion of gases?
A: The rate of effusion is directly proportional to molecular mass.
B: The rate of effusion is inversely proportional to molecular mass.
C: The rate of effusion is constant for all gases.
D: The rate of effusion is highest for heavier molecules.
E: The rate of effusion depends on the gas's color.
Answer: B

Question: What is the term for a single container where the enrichment process takes place through gaseous diffusion?
A: Enricher
B: Separator
C: Diffuser
D: Reactor
E: Converter
Answer: C

Question: In terms of molecular flow, what happens to the lighter molecules in gaseous diffusion?
A: They are depleted.
B: They are enriched.
C: They react with heavier molecules.
D: They combine with uranium hexafluoride.
E: They are neutralized.
Answer: B
@
The kinetic theory of gases is a simple, historically significant classical model of the thermodynamic behavior of gases, with which many principal concepts of thermodynamics were established. The model describes a gas as a large number of identical submicroscopic particles (atoms or molecules), all of which are in constant, rapid, random motion. Their size is assumed to be much smaller than the average distance between the particles. The particles undergo random elastic collisions between themselves and with the enclosing walls of the container. The basic version of the model describes the ideal gas, and considers no other interactions between the particles.

The kinetic theory of gases explains the macroscopic properties of gases, such as volume, pressure, and temperature, as well as transport properties such as viscosity, thermal conductivity and mass diffusivity. Due to the time reversibility of microscopic dynamics (microscopic reversibility), the kinetic theory is also connected to the principle of detailed balance, in terms of the fluctuation-dissipation theorem (for Brownian motion) and the Onsager reciprocal relations.

Historically, the kinetic theory of gases was the first explicit exercise of the ideas of statistical mechanics.

In about 50 BCE, the Roman philosopher Lucretius proposed that apparently static macroscopic bodies were composed on a small scale of rapidly moving atoms all bouncing off each other.[1] This Epicurean atomistic point of view was rarely considered in the subsequent centuries, when Aristotlean ideas were dominant.


Hydrodynamica front cover
In 1738 Daniel Bernoulli published Hydrodynamica, which laid the basis for the kinetic theory of gases. In this work, Bernoulli posited the argument, that gases consist of great numbers of molecules moving in all directions, that their impact on a surface causes the pressure of the gas, and that their average kinetic energy determines the temperature of the gas. The theory was not immediately accepted, in part because conservation of energy had not yet been established, and it was not obvious to physicists how the collisions between molecules could be perfectly elastic.[2]: 36–37 

Other pioneers of the kinetic theory, whose work was also largely neglected by their contemporaries, were Mikhail Lomonosov (1747),[3] Georges-Louis Le Sage (ca. 1780, published 1818),[4] John Herapath (1816)[5] and John James Waterston (1843),[6] which connected their research with the development of mechanical explanations of gravitation. In 1856 August Krönig created a simple gas-kinetic model, which only considered the translational motion of the particles.[7]

In 1857 Rudolf Clausius developed a similar, but more sophisticated version of the theory, which included translational and, contrary to Krönig, also rotational and vibrational molecular motions. In this same work he introduced the concept of mean free path of a particle.[8] In 1859, after reading a paper about the diffusion of molecules by Clausius, Scottish physicist James Clerk Maxwell formulated the Maxwell distribution of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range.[9] This was the first-ever statistical law in physics.[10] Maxwell also gave the first mechanical argument that molecular collisions entail an equalization of temperatures and hence a tendency towards equilibrium.[11] In his 1873 thirteen page article 'Molecules', Maxwell states: "we are told that an 'atom' is a material point, invested and surrounded by 'potential forces' and that when 'flying molecules' strike against a solid body in constant succession it causes what is called pressure of air and other gases."[12] In 1871, Ludwig Boltzmann generalized Maxwell's achievement and formulated the Maxwell–Boltzmann distribution. The logarithmic connection between entropy and probability was also first stated by Boltzmann.

At the beginning of the 20th century, however, atoms were considered by many physicists to be purely hypothetical constructs, rather than real objects. An important turning point was Albert Einstein's (1905)[13] and Marian Smoluchowski's (1906)[14] papers on Brownian motion, which succeeded in making certain accurate quantitative predictions based on the kinetic theory.
$
10
Question: According to the kinetic theory of gases, how are gas particles described in terms of motion?
A: Stationary and non-moving
B: Constant, rapid, and random motion
C: Orbiting the nucleus
D: Moving in a straight line
E: Oscillating between two points
Answer: B

Question: What does the kinetic theory of gases consider the size of gas particles to be compared to the average distance between them?
A: Much larger
B: Much smaller
C: Approximately the same
D: Irrelevant
E: Variable
Answer: B

Question: Which properties of gases does the kinetic theory explain?
A: Density, color, and volume
B: Viscosity, temperature, and electrical conductivity
C: Mass, color, and pressure
D: Density, thermal conductivity, and electrical resistance
E: Volume, pressure, and temperature
Answer: E

Question: What principle is connected to the kinetic theory of gases due to the time reversibility of microscopic dynamics?
A: The law of conservation of energy
B: The principle of detailed balance
C: The law of inertia
D: The principle of least action
E: The first law of thermodynamics
Answer: B

Question: Who was the Roman philosopher who proposed the idea of rapidly moving atoms as the fundamental components of matter?
A: Daniel Bernoulli
B: Mikhail Lomonosov
C: Georges-Louis Le Sage
D: John Herapath
E: Lucretius
Answer: E

Question: What work by Daniel Bernoulli laid the basis for the kinetic theory of gases?
A: Hydrodynamica
B: Thermodynamics
C: Quantum Mechanics
D: Newton's Principia
E: Kinetic Theory of Gases and Fluids
Answer: A

Question: Which physicist developed a gas-kinetic model in 1856 that considered only the translational motion of gas particles?
A: Rudolf Clausius
B: James Clerk Maxwell
C: August Krönig
D: Ludwig Boltzmann
E: Albert Einstein
Answer: C

Question: In 1859, which physicist formulated the Maxwell distribution of molecular velocities?
A: Rudolf Clausius
B: James Clerk Maxwell
C: August Krönig
D: Ludwig Boltzmann
E: Albert Einstein
Answer: B

Question: What is the concept introduced by Rudolf Clausius in 1857 that represents the average distance traveled by a gas particle between collisions?
A: Mean free path
B: Mean collision distance
C: Mean kinetic distance
D: Mean thermal distance
E: Mean molecular path
Answer: A

Question: Who was the physicist that first established the logarithmic connection between entropy and probability, building on Maxwell's work?
A: Rudolf Clausius
B: James Clerk Maxwell
C: August Krönig
D: Ludwig Boltzmann
E: Albert Einstein
Answer: D
@
Throughout his life, Einstein published hundreds of books and articles.[39][245] He published more than 300 scientific papers and 150 non-scientific ones.[48][245] On 5 December 2014, universities and archives announced the release of Einstein's papers, comprising more than 30,000 unique documents.[246][247] Einstein's intellectual achievements and originality have made the word "Einstein" synonymous with "genius".[46] In addition to the work he did by himself he also collaborated with other scientists on additional projects including the Bose–Einstein statistics, the Einstein refrigerator and others.[248][249]

There is some evidence from Einstein's writings that he collaborated with his first wife, Mileva Marić. In 13 December 1900, a first article on capillarity signed only under his name was submitted. The decision to publish only under his name seems to have been mutual, but the exact reason is unknown.[72]

1905 – Annus Mirabilis papers
The Annus Mirabilis papers are four articles pertaining to the photoelectric effect (which gave rise to quantum theory), Brownian motion, the special theory of relativity, and E = mc2 that Einstein published in the Annalen der Physik scientific journal in 1905. These four works contributed substantially to the foundation of modern physics and changed views on space, time, and matter. The four papers are:

Title (translated)	Area of focus	Received	Published	Significance
"On a Heuristic Viewpoint Concerning the Production and Transformation of Light"[250]	Photoelectric effect	18 March	9 June	Resolved an unsolved puzzle by suggesting that energy is exchanged only in discrete amounts (quanta).[251] This idea was pivotal to the early development of quantum theory.[252]
"On the Motion of Small Particles Suspended in a Stationary Liquid, as Required by the Molecular Kinetic Theory of Heat"[253]	Brownian motion	11 May	18 July	Explained empirical evidence for the atomic theory, supporting the application of statistical physics.
"On the Electrodynamics of Moving Bodies"[254]	Special relativity	30 June	26 September	Reconciled Maxwell's equations for electricity and magnetism with the laws of mechanics by introducing changes to mechanics, resulting from analysis based on empirical evidence that the speed of light is independent of the motion of the observer.[255] Discredited the concept of a "luminiferous ether".[256]
"Does the Inertia of a Body Depend Upon Its Energy Content?"[257]	Matter–energy equivalence	27 September	21 November	Equivalence of matter and energy, E = mc2, the existence of "rest energy", and the basis of nuclear energy.
$
10
Question: Which concept did Einstein's paper "On the Electrodynamics of Moving Bodies" introduce?
A: Quantum theory
B: Theory of relativity
C: Luminiferous ether
D: Special theory of relativity
E: Photoelectric effect
Answer: D

Question: What is the significance of Einstein's paper "On the Motion of Small Particles Suspended in a Stationary Liquid"?
A: It explained the concept of matter-energy equivalence.
B: It reconciled Maxwell's equations for electricity and magnetism.
C: It resolved the puzzle of the photoelectric effect.
D: It introduced the concept of the luminiferous ether.
E: It supported the atomic theory through the explanation of Brownian motion.
Answer: E

Question: Which of Einstein's papers resolved the puzzle of the photoelectric effect and contributed to the early development of quantum theory?
A: "On a Heuristic Viewpoint Concerning the Production and Transformation of Light"
B: "On the Motion of Small Particles Suspended in a Stationary Liquid, as Required by the Molecular Kinetic Theory of Heat"
C: "On the Electrodynamics of Moving Bodies"
D: "Does the Inertia of a Body Depend Upon Its Energy Content?"
E: "Annus Mirabilis papers"
Answer: A

Question: What is the area of focus of Einstein's paper "Does the Inertia of a Body Depend Upon Its Energy Content?"?
A: Matter-energy equivalence
B: Brownian motion
C: Special relativity
D: Photoelectric effect
E: Quantum theory
Answer: A

Question: In what year did universities and archives release Einstein's papers, comprising more than 30,000 unique documents?
A: 1905
B: 1915
C: 1955
D: 2014
E: 2024
Answer: D

Question: What term is often used to describe Einstein due to his intellectual achievements and originality?
A: Genius
B: Scientist
C: Collaborator
D: Mathematician
E: Theorist
Answer: A

Question: Which of Einstein's papers reconciled Maxwell's equations for electricity and magnetism with the laws of mechanics?
A: "On a Heuristic Viewpoint Concerning the Production and Transformation of Light"
B: "On the Motion of Small Particles Suspended in a Stationary Liquid, as Required by the Molecular Kinetic Theory of Heat"
C: "On the Electrodynamics of Moving Bodies"
D: "Does the Inertia of a Body Depend Upon Its Energy Content?"
E: "Annus Mirabilis papers"
Answer: C

Question: What was the main focus of the paper "On a Heuristic Viewpoint Concerning the Production and Transformation of Light"?
A: Matter-energy equivalence
B: Special relativity
C: Photoelectric effect
D: Quantum theory
E: Brownian motion
Answer: C

Question: In collaboration with whom did Einstein work on projects like the Bose–Einstein statistics and the Einstein refrigerator?
A: His first wife, Mileva Marić
B: Albert Einstein Jr.
C: Max Planck
D: Niels Bohr
E: James Clerk Maxwell
Answer: A

Question: What is the term used for the four papers that Einstein published in 1905, which significantly contributed to the foundation of modern physics?
A: Groundbreaking quartet
B: Revolutionary articles
C: Einstein's masterpieces
D: Annus Mirabilis papers
E: Scientific breakthroughs
Answer: D
@
Critical opalescence is a phenomenon which arises in the region of a continuous, or second-order, phase transition. Originally reported by Charles Cagniard de la Tour in 1823 in mixtures of alcohol and water, its importance was recognised by Thomas Andrews in 1869 following his experiments on the liquid-gas transition in carbon dioxide; many other examples have been discovered since. In 1908 the Polish physicist Marian Smoluchowski became the first to ascribe the phenomenon of critical opalescence to large density fluctuations. In 1910 Albert Einstein showed that the link between critical opalescence and Rayleigh scattering is quantitative.[1]

Binary fluid mixtures
The phenomenon is most commonly demonstrated in binary fluid mixtures, such as methanol and cyclohexane. As the critical point is approached, the sizes of the gas and liquid region begin to fluctuate over increasingly large length scales (the correlation length of the liquid diverges). As the density fluctuations become of a size comparable to the wavelength of light, the light is scattered and causes the normally transparent liquid to appear cloudy. Tellingly, the opalescence does not diminish as one gets closer to the critical point, where the largest fluctuations can reach even centimetre proportions, confirming the physical relevance of smaller fluctuations.

Approaching the critical point from the opposite direction, in case of liquid-gas transition, the gas phase may contain drops of liquid as mist and spray, and the boiling liquid phase bubbles of gas phase as foam. Far from the critical point the gravity causes liquid drops and gas bubbles to rapidly settle towards the interface and surface tension causes drops and bubbles to rapidly merge to larger ones, which settle even faster. But as critical point is approached, the density difference between liquid and vapour diminishes and so does the surface tension. These effects will slow down settling of drops and bubbles and their merger, such that boiling liquid forms increasingly refractory to settling and fine mist and foam around the interface.

In case of liquid-liquid critical point, again the liquids of limited solubility precipitate out as emulsions which far from critical point on the immiscible side readily settle to interface. As critical point is approached, density difference decreases along with the interfacial surface tension, so that precipitation takes place as increasingly fine and refractory to settling emulsion.

Since liquid-gas critical point occurs at pressures over 30 bar for all substances except some cryogenic gases, demonstrating it requires a transparent vessel safe under over 30 bar, while liquid-liquid critical point for many systems can be demonstrated at ambient pressure and modest temperatures.
$
10
Question: What phenomenon is associated with critical opalescence?
A: Rayleigh scattering
B: Large density fluctuations
C: Transparency
D: Gravity effects
E: Surface tension
Answer: B

Question: Who was the first physicist to link critical opalescence to large density fluctuations?
A: Thomas Andrews
B: Charles Cagniard de la Tour
C: Marian Smoluchowski
D: Albert Einstein
E: Rayleigh
Answer: C

Question: In binary fluid mixtures, what happens to the correlation length of the liquid as the critical point is approached?
A: It remains constant.
B: It decreases.
C: It fluctuates randomly.
D: It increases.
E: It becomes negative.
Answer: D

Question: As the critical point is approached during a liquid-gas transition, what happens to the sizes of gas and liquid regions?
A: They remain constant.
B: They decrease.
C: They fluctuate randomly.
D: They merge.
E: They increase.
Answer: E

Question: How does the surface tension of a liquid change as the critical point is approached during a liquid-gas transition?
A: It increases.
B: It remains constant.
C: It decreases.
D: It becomes negative.
E: It becomes zero.
Answer: C

Question: What effect does gravity have on liquid drops and gas bubbles as the critical point is approached during a liquid-gas transition?
A: It causes them to settle rapidly.
B: It causes them to merge quickly.
C: It reverses their direction.
D: It makes them transparent.
E: It has no effect.
Answer: A

Question: At what pressure does the liquid-gas critical point typically occur for most substances?
A: Below 30 bar
B: Exactly 30 bar
C: Above 30 bar
D: At atmospheric pressure
E: Below 1 bar
Answer: C

Question: In the case of a liquid-liquid critical point, what happens as the critical point is approached?
A: Density difference increases.
B: Surface tension increases.
C: Precipitation becomes slower.
D: Emulsion becomes less refractory to settling.
E: The immiscibility of liquids disappears.
Answer: D

Question: What is used to demonstrate the liquid-gas critical point?
A: A transparent vessel under over 30 bar
B: A glass container
C: A metal cylinder
D: A ceramic flask
E: A wooden box
Answer: A

Question: Which physicist conducted experiments on the liquid-gas transition in carbon dioxide, contributing to the recognition of critical opalescence?
A: Albert Einstein
B: Charles Cagniard de la Tour
C: Thomas Andrews
D: Marian Smoluchowski
E: Rayleigh
Answer: C
@
General relativity, also known as the general theory of relativity and Einstein's theory of gravity, is the geometric theory of gravitation published by Albert Einstein in 1915 and is the current description of gravitation in modern physics. General relativity generalises special relativity and refines Newton's law of universal gravitation, providing a unified description of gravity as a geometric property of space and time or four-dimensional spacetime. In particular, the curvature of spacetime is directly related to the energy and momentum of whatever matter and radiation are present. The relation is specified by the Einstein field equations, a system of second order partial differential equations.

Newton's law of universal gravitation, which describes classical gravity, can be seen as a prediction of general relativity for the almost flat spacetime geometry around stationary mass distributions. Some predictions of general relativity, however, are beyond Newton's law of universal gravitation in classical physics. These predictions concern the passage of time, the geometry of space, the motion of bodies in free fall, and the propagation of light, and include gravitational time dilation, gravitational lensing, the gravitational redshift of light, the Shapiro time delay and singularities/black holes. So far, all tests of general relativity have been shown to be in agreement with the theory. The time-dependent solutions of general relativity enable us to talk about the history of the universe and have provided the modern framework for cosmology, thus leading to the discovery of the Big Bang and cosmic microwave background radiation. Despite the introduction of a number of alternative theories, general relativity continues to be the simplest theory consistent with experimental data.

Reconciliation of general relativity with the laws of quantum physics remains a problem, however, as there is a lack of a self-consistent theory of quantum gravity. It is not yet known how gravity can be unified with the three non-gravitational forces: strong, weak and electromagnetic.

Einstein's theory has astrophysical implications, including the prediction of black holes—regions of space in which space and time are distorted in such a way that nothing, not even light, can escape from them. Black holes are the end-state for massive stars. Microquasars and active galactic nuclei are believed to be stellar black holes and supermassive black holes. It also predicts gravitational lensing, where the bending of light results in multiple images of the same distant astronomical phenomenon. Other predictions include the existence of gravitational waves, which have been observed directly by the physics collaboration LIGO and other observatories. In addition, general relativity has provided the base of cosmological models of an expanding universe.
$
10
Question: What did Albert Einstein publish in 1915 that is the current description of gravitation in modern physics?
A: Special relativity
B: Newton's law of universal gravitation
C: General relativity
D: Quantum physics
E: Einstein field equations
Answer: C

Question: How does general relativity relate the curvature of spacetime to matter and radiation?
A: Through mathematical equations
B: Through electromagnetic forces
C: Through strong nuclear forces
D: Through weak nuclear forces
E: Through gravitational waves
Answer: A

Question: What does general relativity predict about the motion of bodies in free fall?
A: They move in straight lines.
B: They move in perfect circles.
C: They move in unpredictable patterns.
D: They experience time dilation.
E: They remain stationary.
Answer: A

Question: Which of the following is a prediction of general relativity concerning the propagation of light?
A: Light travels at infinite speed.
B: Light does not propagate in space.
C: Light travels in a straight line.
D: Light experiences gravitational lensing.
E: Light always moves at the speed of sound.
Answer: D

Question: What is the name of the phenomenon where light passing near a massive object is bent, resulting in multiple images of the same distant object?
A: Gravitational redshift
B: Time dilation
C: Gravitational lensing
D: The Shapiro time delay
E: Quantum gravity
Answer: C

Question: What has been the outcome of all tests of general relativity in relation to experimental data?
A: General relativity has been disproven.
B: General relativity is consistent with experimental data.
C: General relativity has not been tested yet.
D: General relativity predicts the existence of black holes.
E: General relativity is incompatible with the laws of quantum physics.
Answer: B

Question: What does general relativity predict about the existence of black holes?
A: Black holes are purely theoretical and do not exist.
B: Black holes are regions where only electromagnetic radiation can escape.
C: Black holes are regions where time stands still.
D: Black holes are end-states for massive stars.
E: Black holes are made of dark matter.
Answer: D

Question: Which phenomenon in general relativity describes the bending of light by gravity, leading to the observation of multiple images of the same distant object?
A: Gravitational redshift
B: Gravitational waves
C: Shapiro time delay
D: Gravitational lensing
E: Quantum gravity
Answer: D

Question: What has general relativity contributed to the field of cosmology?
A: The discovery of electromagnetic forces
B: The understanding of weak nuclear forces
C: The framework for understanding dark matter
D: The framework for understanding the Big Bang and cosmic microwave background radiation
E: The explanation of black holes
Answer: D

Question: What is the primary challenge in reconciling general relativity with quantum physics?
A: The unification of gravity with electromagnetic forces
B: The unification of gravity with the strong nuclear force
C: The unification of gravity with the weak nuclear force
D: The unification of gravity with the three non-gravitational forces
E: The existence of singularities in black holes
Answer: D
@
In general relativity, Schwarzschild geodesics describe the motion of test particles in the gravitational field of a central fixed mass 
�
,
{\textstyle M,} that is, motion in the Schwarzschild metric. Schwarzschild geodesics have been pivotal in the validation of Einstein's theory of general relativity. For example, they provide accurate predictions of the anomalous precession of the planets in the Solar System and of the deflection of light by gravity.

Schwarzschild geodesics pertain only to the motion of particles of masses so small they contribute little to the gravitational field. However, they are highly accurate in many astrophysical scenarios provided that 
�
{\textstyle m} is many-fold smaller than the central mass 
�
{\textstyle M}, e.g., for planets orbiting their sun. Schwarzschild geodesics are also a good approximation to the relative motion of two bodies of arbitrary mass, provided that the Schwarzschild mass 
�
{\textstyle M} is set equal to the sum of the two individual masses 
�
1
{\textstyle m_{1}} and 
�
2
{\textstyle m_{2}}. This is important in predicting the motion of binary stars in general relativity.

An exact solution to the Einstein field equations is the Schwarzschild metric, which corresponds to the external gravitational field of an uncharged, non-rotating, spherically symmetric body of mass 
�
{\textstyle M}. The Schwarzschild solution can be written as[3]

�
2
�
�
2
=
(
1
−
�
s
�
)
�
2
�
�
2
−
�
�
2
1
−
�
s
�
−
�
2
�
�
2
−
�
2
sin
2
⁡
�
�
�
2
{\displaystyle c^{2}{d\tau }^{2}=\left(1-{\frac {r_{\text{s}}}{r}}\right)c^{2}dt^{2}-{\frac {dr^{2}}{1-{\frac {r_{\text{s}}}{r}}}}-r^{2}d\theta ^{2}-r^{2}\sin ^{2}\theta \,d\varphi ^{2}}
where

�\tau , in the case of a test particle of small positive mass, is the proper time (time measured by a clock moving with the particle) in seconds,
�
c is the speed of light in meters per second,
�
t is, for 
�
>
�
s
{\displaystyle r>r_{\text{s}}}, the time coordinate (time measured by a stationary clock at infinity) in seconds,
�
r is, for 
�
>
�
s
{\displaystyle r>r_{\text{s}}}, the radial coordinate (circumference of a circle centered at the star divided by 
2
�2\pi ) in meters,
�\theta  is the colatitude (angle from North) in radians,
�\varphi  is the longitude in radians, and
�
s
{\displaystyle r_{\text{s}}} is the Schwarzschild radius of the massive body (in meters), which is related to its mass 
�
{\textstyle M} by
�
s
=
2
�
�
�
2
,
{\displaystyle r_{\text{s}}={\frac {2GM}{c^{2}}},}
where 
�
{\textstyle G} is the gravitational constant. The classical Newtonian theory of gravity is recovered in the limit as the ratio 
�
s
�
{\textstyle {\frac {r_{\text{s}}}{r}}} goes to zero. In that limit, the metric returns to that defined by special relativity.
In practice, this ratio is almost always extremely small. For example, the Schwarzschild radius 
�
s
{\textstyle r_{\text{s}}} of the Earth is roughly 9 mm (3⁄8 inch); at the surface of the Earth, the corrections to Newtonian gravity are only one part in a billion. The Schwarzschild radius of the Sun is much larger, roughly 2953 meters, but at its surface, the ratio 
�
s
�
{\textstyle {\frac {r_{\text{s}}}{r}}} is roughly 4 parts in a million. A white dwarf star is much denser, but even here the ratio at its surface is roughly 250 parts in a million. The ratio only becomes large close to ultra-dense objects such as neutron stars (where the ratio is roughly 50%) and black holes.
$
10
Question: What do Schwarzschild geodesics describe in general relativity?
A: The motion of test particles in the gravitational field of a central fixed mass
B: The motion of planets in the Solar System
C: The motion of binary stars
D: The motion of massive bodies in the universe
E: The motion of particles with mass equal to the central mass
Answer: A

Question: What does the Schwarzschild metric correspond to in general relativity?
A: The internal gravitational field of a charged, rotating body
B: The external gravitational field of an uncharged, non-rotating, spherically symmetric body
C: The curvature of spacetime
D: The gravitational field of a binary star system
E: The gravitational field of a neutron star
Answer: B

Question: Which coordinate represents the proper time for a test particle of small positive mass in the Schwarzschild metric?
A: t (time measured by a stationary clock at infinity)
B: r (radial coordinate)
C: θ (colatitude)
D: φ (longitude)
E: τ (proper time measured by a clock moving with the particle)
Answer: E

Question: What is the Schwarzschild radius related to in the Schwarzschild metric?
A: The Schwarzschild mass
B: The speed of light
C: The gravitational constant
D: The mass of the central body
E: The circumference of a circle centered at the star
Answer: A

Question: In which limit does the Schwarzschild metric return to the metric defined by special relativity?
A: When the speed of light approaches infinity
B: When the Schwarzschild radius approaches zero
C: When the ratio of Schwarzschild radius to radial coordinate goes to zero
D: When the mass of the central body approaches infinity
E: When the ratio of radial coordinate to Schwarzschild radius goes to zero
Answer: C

Question: How large is the Schwarzschild radius of the Earth?
A: Roughly 4 parts in a million of Earth's radius
B: Roughly 9 mm (3⁄8 inch)
C: Roughly 2953 meters
D: Roughly 50% of Earth's radius
E: Roughly 250 parts in a million of Earth's radius
Answer: B

Question: What are the corrections to Newtonian gravity at the surface of the Earth in relation to the Schwarzschild radius?
A: One part in a billion
B: Roughly 2953 meters
C: Roughly 4 parts in a million
D: Roughly 50%
E: Roughly 250 parts in a million
Answer: A

Question: When does the ratio of Schwarzschild radius to radial coordinate become large in the Schwarzschild metric?
A: Close to ultra-dense objects like neutron stars and black holes
B: When the central mass is extremely small
C: When the speed of light is very slow
D: When the Schwarzschild radius approaches infinity
E: When the ratio of radial coordinate to Schwarzschild radius approaches zero
Answer: A

Question: What physical phenomenon does the Schwarzschild metric help explain?
A: The bending of light by gravity
B: The motion of particles with mass equal to the central mass
C: The expansion of the universe
D: The formation of galaxies
E: The behavior of electromagnetic waves in a vacuum
Answer: A

Question: What does the Schwarzschild solution represent in the context of general relativity?
A: The gravitational field of a rotating neutron star
B: The gravitational field of a charged black hole
C: The gravitational field of a massive galaxy
D: The gravitational field of a binary star system
E: The gravitational field of an uncharged, non-rotating, spherically symmetric body
Answer: E
@
A gravitational lens is a distribution of matter (such as a cluster of galaxies) or a point particle between a distant light source and an observer that is capable of bending the light from the source as the light travels toward the observer. This effect is known as gravitational lensing, and the amount of bending is one of the predictions of Albert Einstein's general theory of relativity.[1][2] Treating light as corpuscles travelling at the speed of light, Newtonian physics also predicts the bending of light, but only half of that predicted by general relativity.[3][4][5][6]

Unlike an optical lens, a point-like gravitational lens produces a maximum deflection of light that passes closest to its center, and a minimum deflection of light that travels furthest from its center. Consequently, a gravitational lens has no single focal point, but a focal line. The term "lens" in the context of gravitational light deflection was first used by O.J. Lodge, who remarked that it is "not permissible to say that the solar gravitational field acts like a lens, for it has no focal length".[11] If the (light) source, the massive lensing object, and the observer lie in a straight line, the original light source will appear as a ring around the massive lensing object (provided the lens has circular symmetry). If there is any misalignment, the observer will see an arc segment instead.
$
10
Question: What is the phenomenon where light from a distant source is bent by a distribution of matter between the source and an observer?
A: Gravitational lensing
B: Optical refraction
C: Photon scattering
D: Spectral dispersion
E: Quantum tunneling
Answer: A

Question: Whose general theory of relativity predicts the bending of light by gravity?
A: Isaac Newton
B: Albert Einstein
C: Johannes Kepler
D: Galileo Galilei
E: Stephen Hawking
Answer: B

Question: How much of the light bending predicted by general relativity does Newtonian physics predict?
A: None
B: One-quarter
C: Half
D: Three-quarters
E: All of it
Answer: C

Question: What type of gravitational lens produces a maximum deflection of light closest to its center?
A: Point-like gravitational lens
B: Massive gravitational lens
C: Distant gravitational lens
D: Optical gravitational lens
E: Focal gravitational lens
Answer: A

Question: How does the focal point of a gravitational lens differ from that of an optical lens?
A: It has no focal length
B: It has a single focal point
C: It has multiple focal points
D: It has a focal line
E: It has a focal plane
Answer: A

Question: What is the term used to describe the appearance of a ring around a massive lensing object when the source, lensing object, and observer are in a straight line?
A: Focal point
B: Lens segment
C: Arc alignment
D: Gravitational deflection
E: Einstein ring
Answer: E

Question: Who first used the term "lens" in the context of gravitational light deflection?
A: Albert Einstein
B: O.J. Lodge
C: Isaac Newton
D: Johannes Kepler
E: Stephen Hawking
Answer: B

Question: What does a gravitational lens produce if there is any misalignment between the source, lensing object, and observer?
A: Focal point
B: Lens segment
C: Arc segment
D: Gravitational deflection
E: Optical aberration
Answer: C

Question: In the context of gravitational lensing, what determines whether the original light source appears as a ring or an arc segment?
A: The observer's location
B: The mass of the source
C: The speed of light
D: The alignment of the source, lensing object, and observer
E: The distance to the lensing object
Answer: D

Question: What is the maximum deflection of light produced by a point-like gravitational lens?
A: It varies depending on the lens
B: 90 degrees
C: 180 degrees
D: It depends on the observer's position
E: It has no maximum deflection
Answer: C
@
Strong lensing
Where there are easily visible distortions such as the formation of Einstein rings, arcs, and multiple images. Despite being considered "strong", the effect is in general relatively small, such that even a galaxy with a mass more than 100 billion times that of the Sun will produce multiple images separated by only a few arcseconds. Galaxy clusters can produce separations of several arcminutes. In both cases the galaxies and sources are quite distant, many hundreds of megaparsecs away from our Galaxy.
Weak lensing
Where the distortions of background sources are much smaller and can only be detected by analyzing large numbers of sources in a statistical way to find coherent distortions of only a few percent. The lensing shows up statistically as a preferred stretching of the background objects perpendicular to the direction to the centre of the lens. By measuring the shapes and orientations of large numbers of distant galaxies, their orientations can be averaged to measure the shear of the lensing field in any region. This, in turn, can be used to reconstruct the mass distribution in the area: in particular, the background distribution of dark matter can be reconstructed. Since galaxies are intrinsically elliptical and the weak gravitational lensing signal is small, a very large number of galaxies must be used in these surveys. These weak lensing surveys must carefully avoid a number of important sources of systematic error: the intrinsic shape of galaxies, the tendency of a camera's point spread function to distort the shape of a galaxy and the tendency of atmospheric seeing to distort images must be understood and carefully accounted for. The results of these surveys are important for cosmological parameter estimation, to better understand and improve upon the Lambda-CDM model, and to provide a consistency check on other cosmological observations. They may also provide an important future constraint on dark energy.
Microlensing
Where no distortion in shape can be seen but the amount of light received from a background object changes in time. The lensing object may be stars in the Milky Way in one typical case, with the background source being stars in a remote galaxy, or, in another case, an even more distant quasar. In extreme cases, a star in a distant galaxy can act as a microlens and magnify another star much farther away. The first example of this was the star MACS J1149 Lensed Star 1 (also known as Icarus), thanks to the boost in flux due to the microlensing effect.
Gravitational lenses act equally on all kinds of electromagnetic radiation, not just visible light, and also in non-electromagnetic radiation, like gravitational waves. Weak lensing effects are being studied for the cosmic microwave background as well as galaxy surveys. Strong lenses have been observed in radio and x-ray regimes as well. If a strong lens produces multiple images, there will be a relative time delay between two paths: that is, in one image the lensed object will be observed before the
$
10
Question: Which type of lensing produces easily visible distortions like Einstein rings and arcs?
A: Strong lensing
B: Weak lensing
C: Microlensing
D: Gravitational waves
E: Radio lensing
Answer: A

Question: In strong lensing, how far away are galaxies and sources typically from our Galaxy?
A: Closer than our Galaxy
B: Approximately the same distance as our Galaxy
C: Many hundreds of megaparsecs away from our Galaxy
D: Less than a megaparsec away from our Galaxy
E: Billions of light-years away from our Galaxy
Answer: C

Question: What is the primary method for detecting weak lensing?
A: Easily visible distortions
B: Analyzing individual sources
C: Analyzing large numbers of sources statistically
D: Measuring time delays in lensed images
E: Observing background galaxies
Answer: C

Question: How does weak lensing manifest itself statistically?
A: As a preferred stretching of background objects parallel to the lens
B: As a preferred stretching of background objects perpendicular to the lens
C: As multiple images of the same object
D: As a change in the shape of lensed objects
E: As an increase in the brightness of lensed objects
Answer: B

Question: What can be reconstructed by analyzing the shear of the lensing field in weak lensing surveys?
A: The composition of galaxies
B: The distances between galaxies
C: The mass distribution in the area
D: The source of dark energy
E: The point spread function of the camera
Answer: C

Question: What are microlenses typically composed of in one common scenario?
A: Distant galaxies
B: Quasars
C: Stars in the Milky Way
D: Stars in a remote galaxy
E: Dark matter
Answer: C

Question: What is the name of the star known for its microlensing effect, which boosted its flux?
A: MACS J1149 Lensed Star 1
B: Einstein Star
C: Quasar Star
D: Milky Way Star
E: Icarus Star
Answer: A

Question: Which types of radiation can gravitational lenses affect?
A: Only visible light
B: Only electromagnetic radiation
C: All kinds of electromagnetic radiation
D: Only radio waves
E: Only x-rays
Answer: C

Question: In what regimes have strong lenses been observed?
A: Only in visible light
B: Only in radio waves
C: Only in x-rays
D: In radio and x-ray regimes
E: In x-ray and gamma-ray regimes
Answer: D

Question: What is the consequence of strong lensing producing multiple images?
A: There is no time delay between the images.
B: There is a relative time delay between the images.
C: The images appear identical.
D: The lensing object appears as a single image.
E: The images overlap and cannot be distinguished.
Answer: B
@
n physical cosmology and astronomy, dark energy is an unknown form of energy that affects the universe on the largest scales. Its primary effect is to drive the accelerating expansion of the universe. Assuming that the lambda-CDM model of cosmology is correct,[1] dark energy is the dominant component of the universe, contributing 68% of the total energy in the present-day observable universe while dark matter and ordinary (baryonic) matter contribute 26% and 5%, respectively, and other components such as neutrinos and photons are nearly negligible.[2][3][4][5] Dark energy's density is very low: 6×10−10 J/m3 (≈7×10−30 g/cm3), much less than the density of ordinary matter or dark matter within galaxies. However, it dominates the universe's mass–energy content because it is uniform across space.[6][7][8]

The first observational evidence for dark energy's existence came from measurements of supernovae. Type 1A supernovae have constant luminosity, which means they can be used as accurate distance measures. Comparing this distance to the redshift (which measures the speed at which the supernova is receding) shows that the universe's expansion is accelerating.[9][10] Prior to this observation, scientists thought that the gravitational attraction of matter and energy in the universe would cause the universe's expansion to slow down over time. Since the discovery of accelerating expansion, several independent lines of evidence have been discovered that support the existence of dark energy.

The exact nature of dark energy remains a mystery, and explanations abound. The main candidates are a cosmological constant[11][12] (representing a constant energy density filling space homogeneously) and scalar fields (dynamic quantities having energy densities that vary in time and space) such as quintessence or moduli. A cosmological constant would remain constant across time and space, while scalar fields can vary. Yet other possibilities are interacting dark energy, an observational effect, and cosmological coupling (see the Theories of Dark Energy section).
$
10
Question: What is the primary effect of dark energy on the universe?
A: It causes the universe to contract.
B: It slows down the expansion of the universe.
C: It accelerates the expansion of the universe.
D: It has no effect on the expansion of the universe.
E: It causes the universe to collapse.
Answer: C

Question: In the lambda-CDM model of cosmology, what percentage of the total energy in the present-day observable universe is contributed by dark energy?
A: 5%
B: 26%
C: 68%
D: 7%
E: 30%
Answer: C

Question: What is the density of dark energy in the universe?
A: Equal to the density of ordinary matter
B: Much greater than the density of ordinary matter
C: Nearly negligible
D: Much less than the density of dark matter
E: Constant across space
Answer: D

Question: What type of supernovae were used to provide the first observational evidence for dark energy's existence?
A: Type 1B supernovae
B: Type 1C supernovae
C: Type 2 supernovae
D: Type 1A supernovae
E: Type 2A supernovae
Answer: D

Question: How did the discovery of accelerating expansion differ from scientists' previous expectations regarding the universe's expansion?
A: It confirmed that the universe's expansion was slowing down.
B: It had no effect on scientists' previous expectations.
C: It showed that the universe's expansion was constant.
D: It contradicted scientists' previous expectations of a slowing expansion.
E: It confirmed that dark matter was responsible for the expansion.
Answer: D

Question: What is the main candidate for explaining dark energy's nature as a constant energy density filling space homogeneously?
A: Scalar fields
B: Quintessence
C: Cosmological coupling
D: Cosmological constant
E: Moduli
Answer: D

Question: Which of the following is NOT mentioned as a candidate for explaining the nature of dark energy?
A: Quintessence
B: Scalar fields
C: Cosmological constant
D: Dark matter
E: Moduli
Answer: D

Question: What does scalar fields represent in the context of dark energy?
A: Constant energy density filling space
B: Dynamic quantities with varying energy densities
C: Interacting dark energy
D: Observational effects
E: Cosmological coupling
Answer: B

Question: What is one possibility for dark energy mentioned as an observational effect?
A: Dark matter
B: Quintessence
C: Cosmological constant
D: Scalar fields
E: Cosmological coupling
Answer: E

Question: How does dark energy's density compare to the density of ordinary matter or dark matter within galaxies?
A: It is much greater.
B: It is equal.
C: It is much less.
D: It is nearly negligible.
E: It is constant.
Answer: D
@
In cosmology, the cosmological constant (usually denoted by the Greek capital letter lambda: Λ), alternatively called Einstein's cosmological constant, is the constant coefficient of a term that Albert Einstein temporarily added to his field equations of general relativity. He later removed it. Much later it was revived and reinterpreted as the energy density of space, or vacuum energy, that arises in quantum mechanics. It is closely associated with the concept of dark energy.[1]

Einstein originally introduced the constant in 1917[2] to counterbalance the effect of gravity and achieve a static universe, a notion that was the accepted view at the time. Einstein's cosmological constant was abandoned after Edwin Hubble's confirmation that the universe was expanding.[3] From the 1930s until the late 1990s, most physicists agreed with Einstein's choice of setting the cosmological constant to zero.[4] That changed with the discovery in 1998 that the expansion of the universe is accelerating, implying that the cosmological constant may have a positive value.[5]

Since the 1990s, studies have shown that, assuming the cosmological principle, around 68% of the mass–energy density of the universe can be attributed to so-called dark energy.[6][7][8] The cosmological constant Λ is the simplest possible explanation for dark energy, and is used in the current standard model of cosmology known as the ΛCDM model.

According to quantum field theory (QFT), which underlies modern particle physics, empty space is defined by the vacuum state, which is composed of a collection of quantum fields. All these quantum fields exhibit fluctuations in their ground state (lowest energy density) arising from the zero-point energy present everywhere in space. These zero-point fluctuations should act as a contribution to the cosmological constant Λ, but when calculations are performed, these fluctuations give rise to an enormous vacuum energy.[9] The discrepancy between theorized vacuum energy from quantum field theory and observed vacuum energy from cosmology is a source of major contention, with the values predicted exceeding observation by some 120 orders of magnitude, a discrepancy that has been called "the worst theoretical prediction in the history of physics!".[10] This issue is called the cosmological constant problem and it is one of the greatest mysteries in science with many physicists believing that "the vacuum holds the key to a full understanding of nature".[11]
$
10
Question: What is the cosmological constant Λ associated with in modern cosmology?
A: Gravity
B: Dark matter
C: Dark energy
D: Quantum fields
E: Vacuum energy
Answer: C

Question: Why did Einstein introduce the cosmological constant in 1917?
A: To explain the expansion of the universe
B: To counterbalance the effect of gravity and achieve a static universe
C: To support the concept of dark energy
D: To develop the theory of general relativity
E: To explain the behavior of quantum fields
Answer: B

Question: When did physicists generally agree with Einstein's choice of setting the cosmological constant to zero?
A: In the 1910s
B: In the 1930s
C: In the 1960s
D: In the 1980s
E: In the 1990s
Answer: B

Question: What changed physicists' perspective on the cosmological constant in 1998?
A: The discovery of dark matter
B: The discovery of the Higgs boson
C: The confirmation that the universe was expanding at an accelerating rate
D: The development of quantum field theory
E: The validation of the cosmological principle
Answer: C

Question: What is the current standard model of cosmology known as?
A: The Einstein Model
B: The Dark Matter Model
C: The Quantum Field Model
D: The ΛCDM Model
E: The Hubble Model
Answer: D

Question: In quantum field theory, what is the vacuum state composed of?
A: Quantum fields
B: Dark energy
C: Gravitational waves
D: Photons
E: Dark matter
Answer: A

Question: What do quantum fields in the vacuum state exhibit?
A: Fluctuations in their ground state
B: Steady-state behavior
C: High-energy density
D: Quantum entanglement
E: Time dilation
Answer: A

Question: What discrepancy arises when comparing theorized vacuum energy from quantum field theory with observed vacuum energy from cosmology?
A: A discrepancy of 1 order of magnitude
B: A discrepancy of 10 orders of magnitude
C: A discrepancy of 100 orders of magnitude
D: A discrepancy of 120 orders of magnitude
E: No discrepancy exists
Answer: D

Question: What is the issue called where vacuum energy from quantum field theory greatly exceeds observed vacuum energy from cosmology?
A: The Dark Matter Problem
B: The Quantum Field Problem
C: The Vacuum State Problem
D: The Cosmological Constant Problem
E: The Gravity Anomaly
Answer: D

Question: According to many physicists, what holds the key to a full understanding of nature?
A: The cosmological constant
B: Dark energy
C: The vacuum
D: Quantum fields
E: The Higgs boson
Answer: C
@
Edwin Powell Hubble (November 20, 1889 – September 28, 1953)[1] was an American astronomer. He played a crucial role in establishing the fields of extragalactic astronomy and observational cosmology.[2][3]

Hubble proved that many objects previously thought to be clouds of dust and gas and classified as "nebulae" were actually galaxies beyond the Milky Way.[4] He used the strong direct relationship between a classical Cepheid variable's luminosity and pulsation period[5][6] (discovered in 1908 by Henrietta Swan Leavitt[7]) for scaling galactic and extragalactic distances.[8][9]

Hubble provided evidence that the recessional velocity of a galaxy increases with its distance from Earth, a property now known as Hubble's law, although it had been proposed two years earlier by Georges Lemaître.[10] The Hubble law implies that the universe is expanding.[11] A decade before, the American astronomer Vesto Slipher had provided the first evidence that the light from many of these nebulae was strongly red-shifted, indicative of high recession velocities.[12][13]

Hubble's name is most widely recognized for the Hubble Space Telescope, which was named in his honor, with a model prominently displayed in his hometown of Marshfield, Missouri.
$
10
Question: What field did Edwin Hubble help establish through his work in astronomy?
A: Extragalactic astronomy
B: Observational geology
C: Stellar astrophysics
D: Planetary science
E: Quantum mechanics
Answer: A

Question: What did Hubble discover about objects classified as "nebulae"?
A: They were clouds of dust and gas.
B: They were part of the Milky Way.
C: They were stars.
D: They were galaxies beyond the Milky Way.
E: They were comets.
Answer: D

Question: What relationship did Hubble use for scaling galactic and extragalactic distances?
A: The relationship between temperature and luminosity
B: The relationship between mass and brightness
C: The relationship between pulsation period and luminosity
D: The relationship between color and age
E: The relationship between size and density
Answer: C

Question: What property is now known as Hubble's law?
A: The relationship between luminosity and pulsation period
B: The relationship between redshift and recession velocity
C: The relationship between temperature and luminosity
D: The relationship between mass and brightness
E: The relationship between size and density
Answer: B

Question: Who had proposed a similar idea to Hubble's law two years earlier?
A: Henrietta Swan Leavitt
B: Vesto Slipher
C: Georges Lemaître
D: Albert Einstein
E: Isaac Newton
Answer: C

Question: What did Vesto Slipher provide evidence for regarding the light from many nebulae?
A: That it was strongly blue-shifted
B: That it was scattered by dust
C: That it was indicative of high recession velocities
D: That it was composed of dark matter
E: That it was constant across the universe
Answer: C

Question: What is the Hubble Space Telescope named after?
A: Edwin Hubble's favorite constellation
B: A famous astronaut
C: A distant galaxy
D: Edwin Hubble's hometown
E: A famous comet
Answer: D

Question: What is the property of galaxies discovered by Hubble that implies the universe is expanding?
A: Their luminosity
B: Their color
C: Their size
D: Their distance from Earth
E: Their brightness
Answer: D

Question: What kind of variable did Hubble use to determine galactic and extragalactic distances?
A: Cepheid variable
B: Planetary variable
C: Stellar variable
D: Quantum variable
E: Cosmic variable
Answer: A

Question: What was Henrietta Swan Leavitt's contribution to astronomy?
A: She discovered Hubble's law.
B: She provided evidence of galaxy recession velocities.
C: She discovered the Hubble Space Telescope.
D: She established the relationship between Cepheid variable luminosity and pulsation period.
E: She observed extragalactic distances directly.
Answer: D
@
Edwin Hubble's arrival at Mount Wilson Observatory, California, in 1919 coincided roughly with the completion of the 100-inch (2.5 m) Hooker Telescope, then the world's largest. At that time, the prevailing view of the cosmos was that the universe consisted entirely of the Milky Way Galaxy.

Using the Hooker Telescope at Mount Wilson, Hubble identified Cepheid variables, a standard candle discovered by Henrietta Leavitt.[7] Comparing their apparent luminosity to their intrinsic luminosity gives their distance from Earth.[25][26] Hubble found Cepheids in several nebulae, including the Andromeda Nebula and Triangulum Nebula. His observations, made in 1924, proved conclusively that these nebulae were much too distant to be part of the Milky Way and were, in fact, entire galaxies outside our own; thus today they are no longer considered nebulae.

This was first hypothesized as early as 1755 when Immanuel Kant's General History of Nature and Theory of the Heavens appeared. This hypothesis was opposed by many in the astronomy establishment of the time, in particular by Harvard University–based Harlow Shapley. Despite the opposition, Hubble, then a thirty-five-year-old scientist, had his findings first published in The New York Times on November 23, 1924,[27] then presented them to other astronomers at the January 1, 1925, meeting of the American Astronomical Society.[28] Hubble's results for Andromeda were not formally published in a peer-reviewed scientific journal until 1929.[29]


Hubble's classification scheme
Hubble's findings fundamentally changed the scientific view of the universe. Supporters state that Hubble's discovery of nebulae outside of our galaxy helped pave the way for future astronomers.[30] Although some of his more renowned colleagues simply scoffed at his results, Hubble ended up publishing his findings on nebulae. This published work earned him an award titled the American Association Prize and five hundred dollars from Burton E. Livingston of the Committee on Awards.[16]

Hubble also devised the most commonly used system for classifying galaxies, grouping them according to their appearance in photographic images. He arranged the different groups of galaxies in what became known as the Hubble
$
10
Question: What was the prevailing view of the cosmos before Hubble's work?
A: The universe consisted entirely of the Milky Way Galaxy.
B: The universe consisted of multiple galaxies.
C: The universe was expanding.
D: The universe was contracting.
E: The universe was static.
Answer: A

Question: What did Hubble use to determine the distances to various celestial objects?
A: Redshift measurements
B: Apparent brightness
C: Cepheid variables
D: Neutrino emissions
E: Radio signals
Answer: C

Question: Which scientist first hypothesized that some nebulae might be other galaxies outside of the Milky Way?
A: Edwin Hubble
B: Immanuel Kant
C: Henrietta Leavitt
D: Harlow Shapley
E: Burton E. Livingston
Answer: B

Question: When were Hubble's findings on Andromeda and other galaxies outside of the Milky Way first presented to other astronomers?
A: January 1, 1925
B: November 23, 1924
C: 1929
D: 1924
E: 1755
Answer: A

Question: What award did Hubble receive for his published work on nebulae?
A: The Nobel Prize in Physics
B: The Burton E. Livingston Award
C: The American Association Prize
D: The Immanuel Kant Medal
E: The Henrietta Leavitt Award
Answer: C

Question: What is the term for Hubble's system of classifying galaxies based on their appearance in photographic images?
A: Hubble's law
B: The Hooker classification scheme
C: The Cepheid variable system
D: The nebulae classification
E: The Hubble sequence
Answer: E

Question: What instrument did Hubble use at Mount Wilson Observatory for his observations?
A: The Leavitt Telescope
B: The Redshift Spectrometer
C: The Kantian Telescope
D: The Hubble Space Telescope
E: The Hooker Telescope
Answer: E

Question: How did Hubble's work change the scientific view of the universe?
A: It confirmed the prevailing view that the Milky Way was the entire universe.
B: It established the existence of dark matter.
C: It showed that nebulae were part of the Milky Way.
D: It proved that the universe was contracting.
E: It demonstrated the existence of galaxies beyond the Milky Way.
Answer: E

Question: What important finding did Hubble make about nebulae, such as Andromeda and Triangulum?
A: They were part of the Milky Way.
B: They were not visible in photographic images.
C: They were star clusters.
D: They were too distant to be part of the Milky Way.
E: They were not real objects.
Answer: D

Question: What was the response of some of Hubble's colleagues to his findings on nebulae?
A: They were supportive and immediately accepted his results.
B: They scoffed at his results.
C: They awarded him the Nobel Prize.
D: They replicated his findings.
E: They conducted further research to confirm his results.
Answer: B
@
An elliptical galaxy is a type of galaxy with an approximately ellipsoidal shape and a smooth, nearly featureless image. They are one of the four main classes of galaxy described by Edwin Hubble in his Hubble sequence and 1936 work The Realm of the Nebulae,[1] along with spiral and lenticular galaxies. Elliptical (E) galaxies are, together with lenticular galaxies (S0) with their large-scale disks, and ES galaxies[2][3][4] with their intermediate scale disks, a subset of the "early-type" galaxy population.

Most elliptical galaxies are composed of older, low-mass stars, with a sparse interstellar medium and minimal star formation activity, and they tend to be surrounded by large numbers of globular clusters. Elliptical galaxies are believed to make up approximately 10–15% of galaxies in the Virgo Supercluster, and they are not the dominant type of galaxy in the universe overall.[5] They are preferentially found close to the centers of galaxy clusters.[6]

Elliptical galaxies range in size from dwarf ellipticals with tens of millions of stars, to supergiants of over one hundred trillion stars that dominate their galaxy clusters. Originally, Edwin Hubble hypothesized that elliptical galaxies evolved into spiral galaxies, which was later discovered to be false,[7] although the accretion of gas and smaller galaxies may build a disk around a pre-existing ellipsoidal structure.[8][9] Stars found inside of elliptical galaxies are on average much older than stars found in spiral galaxies.[7]

Elliptical galaxies are characterized by several properties that make them distinct from other classes of galaxy. They are spherical or ovoid masses of stars, starved of star-making gases. Furthermore, there is very little interstellar matter (neither gas nor dust), which results in low rates of star formation, few open star clusters, and few young stars; rather elliptical galaxies are dominated by old stellar populations, giving them red colors. Large elliptical galaxies typically have an extensive system of globular clusters. They generally have two distinct populations of globular clusters: one that is redder and metal-rich, and another that is bluer and metal-poor.[11]

The dynamical properties of elliptical galaxies and the bulges of disk galaxies are similar, suggesting that they may be formed by the same physical processes, although this remains controversial. The luminosity profiles of both elliptical galaxies and bulges are well fit by Sersic's law, and a range of scaling relations between the elliptical galaxies' structural parameters unify the population.[12]

Every massive elliptical galaxy contains a supermassive black hole at its center. Observations of 46 elliptical galaxies, 20 classical bulges, and 22 pseudobulges show that each contain a black hole at the center.[13] The mass of the black hole is tightly correlated with the mass of the galaxy,[14] evidenced through correlations such as the M–sigma relation which relates the velocity dispersion of the surrounding stars to the mass of the black hole at the center.

Elliptical galaxies are preferentially found in galaxy clusters and in compact groups of galaxies.

Unlike flat spiral galaxies with organization and structure, elliptical galaxies are more three-dimensional, without much structure, and their stars are in somewhat random orbits around the center.
$
10
Question: What percentage of galaxies in the Virgo Supercluster are believed to be elliptical galaxies?
A: 10–15%
B: 25–30%
C: 50–55%
D: 70–75%
E: 90–95%
Answer: A

Question: What distinguishes elliptical galaxies from other classes of galaxies in terms of their star populations?
A: They have predominantly young stars.
B: They contain many open star clusters.
C: They have a rich interstellar medium.
D: They have predominantly old stars.
E: They contain few globular clusters.
Answer: D

Question: What is the characteristic shape of most elliptical galaxies?
A: Spiral shape
B: Ellipsoidal shape
C: Irregular shape
D: Bar-shaped
E: Disk shape
Answer: B

Question: Which galaxy class is considered a subset of the "early-type" galaxy population along with elliptical galaxies?
A: Spiral galaxies
B: Lenticular galaxies
C: Irregular galaxies
D: Dwarf galaxies
E: Starburst galaxies
Answer: B

Question: What is the primary composition of most elliptical galaxies in terms of stars?
A: Young, massive stars
B: Middle-aged stars
C: Old, low-mass stars
D: Blue stars
E: Binary star systems
Answer: C

Question: What do large elliptical galaxies typically have a system of?
A: Spiral arms
B: Asteroid belts
C: Open star clusters
D: Globular clusters
E: Dark matter halos
Answer: D

Question: What dynamical property of elliptical galaxies is similar to the bulges of disk galaxies?
A: Spiral arms
B: Stellar populations
C: Luminosity profiles
D: Dark matter content
E: Star formation rates
Answer: C

Question: What is tightly correlated with the mass of the galaxy in elliptical galaxies?
A: The number of globular clusters
B: The amount of interstellar matter
C: The number of spiral arms
D: The mass of the supermassive black hole
E: The color of the stars
Answer: D

Question: In what environments are elliptical galaxies preferentially found?
A: Solitary regions of space
B: Compact groups of galaxies
C: Spiral galaxy clusters
D: Nebulae and star clusters
E: The outskirts of galaxy clusters
Answer: B

Question: How does the three-dimensional structure of elliptical galaxies compare to flat spiral galaxies?
A: Elliptical galaxies have more structure.
B: Elliptical galaxies have a flatter appearance.
C: Elliptical galaxies have spiral arms.
D: Elliptical galaxies have more organized stars.
E: Elliptical galaxies have fewer stars.
Answer: A
@
A galaxy cluster, or a cluster of galaxies, is a structure that consists of anywhere from hundreds to thousands of galaxies that are bound together by gravity,[1] with typical masses ranging from 1014 to 1015 solar masses. They are the second-largest known gravitationally bound structures in the universe after galaxy filaments and were believed to be the largest known structures in the universe until the 1980s, when superclusters were discovered.[2] One of the key features of clusters is the intracluster medium (ICM). The ICM consists of heated gas between the galaxies and has a peak temperature between 2–15 keV that is dependent on the total mass of the cluster. Galaxy clusters should not be confused with galactic clusters (also known as open clusters), which are star clusters within galaxies, or with globular clusters, which typically orbit galaxies. Small aggregates of galaxies are referred to as galaxy groups rather than clusters of galaxies. The galaxy groups and clusters can themselves cluster together to form superclusters.

Notable galaxy clusters in the relatively nearby Universe include the Virgo Cluster, Fornax Cluster, Hercules Cluster, and the Coma Cluster. A very large aggregation of galaxies known as the Great Attractor, dominated by the Norma Cluster, is massive enough to affect the local expansion of the Universe. Notable galaxy clusters in the distant, high-redshift universe include SPT-CL J0546-5345 and SPT-CL J2106-5844, the most massive galaxy clusters found in the early Universe. In the last few decades, they are also found to be relevant sites of particle acceleration, a feature that has been discovered by observing non-thermal diffuse radio emissions, such as radio halos and radio relics. Using the Chandra X-ray Observatory, structures such as cold fronts and shock waves have also been found in many galaxy clusters.

Galaxy clusters typically have the following properties:

They contain 100 to 1,000 galaxies, hot X-ray emitting gas and large amounts of dark matter.[4] Details are described in the "Composition" section.
The distribution of the three components is approximately the same in the cluster.[citation needed]
They have total masses of 1014 to 1015 solar masses.
They typically have a diameter from 1 to 5 Mpc (see 1023 m for distance comparisons).
The spread of velocities for the individual galaxies is about 800–1000 km/s.
$
10
Question: What is the primary force that binds galaxies together within a galaxy cluster?
A: Electromagnetic force
B: Gravitational force
C: Nuclear force
D: Electrostatic force
E: Magnetic force
Answer: B

Question: What is the typical mass range of galaxy clusters?
A: 10^10 to 10^11 solar masses
B: 10^11 to 10^12 solar masses
C: 10^12 to 10^13 solar masses
D: 10^13 to 10^14 solar masses
E: 10^14 to 10^15 solar masses
Answer: D

Question: What is the intracluster medium (ICM) primarily composed of?
A: Star clusters
B: Dark matter
C: Heated gas
D: Cosmic rays
E: Nebulae
Answer: C

Question: Which structures are the second-largest known gravitationally bound structures in the universe after galaxy filaments?
A: Superclusters
B: Galaxy clusters
C: Galaxy groups
D: Galactic clusters
E: Globular clusters
Answer: B

Question: What is the peak temperature range of the intracluster medium (ICM) in galaxy clusters?
A: 2–15 K
B: 2–15 °C
C: 2–15 eV
D: 2–15 MeV
E: 2–15 keV
Answer: E

Question: What is the term for small aggregates of galaxies that are referred to as groups rather than clusters?
A: Galactic clusters
B: Star clusters
C: Nebulae
D: Galaxy groups
E: Superclusters
Answer: D

Question: Which galaxy cluster, dominated by the Norma Cluster, is massive enough to affect the local expansion of the Universe?
A: Virgo Cluster
B: Fornax Cluster
C: Hercules Cluster
D: Great Attractor
E: Coma Cluster
Answer: D

Question: What is the primary method used to observe particle acceleration in galaxy clusters?
A: Visible light observations
B: Infrared observations
C: Ultraviolet observations
D: Radio emissions
E: X-ray observations
Answer: D

Question: What kind of emissions, such as radio halos and radio relics, have been observed in galaxy clusters, indicating particle acceleration?
A: Optical emissions
B: Infrared emissions
C: X-ray emissions
D: Radio emissions
E: Gamma-ray emissions
Answer: D

Question: What is the approximate spread of velocities for the individual galaxies within galaxy clusters?
A: 100–200 km/s
B: 200–400 km/s
C: 400–600 km/s
D: 600–800 km/s
E: 800–1000 km/s
Answer: E
@
The Virgo Cluster is a large cluster of galaxies whose center is 53.8 ± 0.3 Mly (16.5 ± 0.1 Mpc)[2] away in the constellation Virgo. Comprising approximately 1,300 (and possibly up to 2,000) member galaxies,[3] the cluster forms the heart of the larger Virgo Supercluster, of which the Local Group (containing our Milky Way galaxy) is a member. The Local Group actually experiences the mass of the Virgo Supercluster as the Virgocentric flow. It is estimated that the Virgo Cluster's mass is 1.2×1015 M☉ out to 8 degrees of the cluster's center or a radius of about 2.2 Mpc.[4]

Many of the brighter galaxies in this cluster, including the giant elliptical galaxy Messier 87, were discovered in the late 1770s and early 1780s and subsequently included in Charles Messier's catalogue of non-cometary fuzzy objects. Described by Messier as nebulae without stars, their true nature was not recognized until the 1920s.[A]

The cluster subtends a maximum arc of approximately 8 degrees centered in the constellation Virgo. Although some of the cluster's most prominent members can be seen with smaller instruments, a 6-inch telescope will reveal about 160 of the cluster's galaxies on a clear night. Its brightest member is the elliptical galaxy Messier 49; however its most famous member is the elliptical galaxy Messier 87, which is located in the center of the cluster.[6]

The cluster is a fairly heterogeneous mixture of spiral and elliptical galaxies.[7] As of 2004, it is believed that the spiral galaxies of the cluster are distributed in an oblong prolate filament, approximately four times as long as it is wide, stretching along the line of sight from the Milky Way.[8] The elliptical galaxies are more centrally concentrated than the spiral galaxies.[9]

The cluster is an aggregate of at least three separate subclumps: Virgo A, centered on M87, a second centered on the galaxy M86, and Virgo B, centered on M49, with some authors including a Virgo C subcluster, centered on the galaxy M60 as well as a LVC (Low Velocity Cloud) subclump, centered on the large spiral galaxy NGC 4216.[10] Notably, the giant elliptical galaxy M87 contains a supermassive black hole, whose event horizon was observed by the Event Horizon Telescope Collaboration in 2019.[11][12]

Of all of the subclumps, Virgo A, formed by a mixture of elliptical, lenticular, and (usually) gas-poor spiral galaxies,[13] is the dominant one, with a mass of approximately 1014 M☉, which is approximately an order of magnitude larger than the other two subclumps.[14]


Turbulence may prevent galaxy clusters from cooling (Chandra X-ray).
The three subgroups are in the process of merging to form a larger single cluster[14] and are surrounded by other smaller galaxy clouds, mostly composed of spiral galaxies, known as N Cloud, S Cloud, and Virgo E that are in the process of infalling to merge with them,[15] plus other farther isolated galaxies and galaxy groups (like the galaxy cloud Coma I) that are also attracted by the gravity of Virgo to merge with it in the future.[16] This strongly suggests the Virgo cluster is a dynamically young cluster that is still forming.[15]

Other two nearby aggregations known as M Cloud, W Cloud, and W' Cloud[10] seem to be background systems independent of the main cluster.[15]

The large mass of the cluster is indicated by the high peculiar velocities of many of its galaxies, sometimes as high as 1,600 km/s with respect to the cluster's center.
$
10
Question: What is the Virgo Cluster's approximate distance from Earth?
A: 53.8 ± 0.3 Mpc
B: 16.5 ± 0.1 Mly
C: 1.2×10^15 M☉
D: 8 degrees
E: 2.2 Mpc
Answer: A

Question: How many member galaxies are estimated to be in the Virgo Cluster?
A: 300
B: 800
C: 1,300
D: 1,800
E: 2,000
Answer: C

Question: Which prominent elliptical galaxy is located in the center of the Virgo Cluster?
A: Messier 87
B: Messier 49
C: Messier 86
D: Messier 60
E: NGC 4216
Answer: A

Question: What is the Virgocentric flow?
A: The flow of galaxies away from the Virgo Cluster
B: The mass experienced by the Local Group due to the Virgo Supercluster
C: A description of the cluster's subclumps
D: The observed turbulence in the Virgo Cluster
E: The maximum arc subtended by the cluster
Answer: B

Question: What is the nature of the galaxies initially cataloged by Charles Messier in the Virgo Cluster?
A: Spiral galaxies
B: Elliptical galaxies
C: Nebulae without stars
D: Star clusters
E: Supernovae remnants
Answer: C

Question: How many of the Virgo Cluster's galaxies can be revealed with a 6-inch telescope on a clear night?
A: About 10
B: About 50
C: About 100
D: About 160
E: About 200
Answer: D

Question: What is the primary type of galaxy in the Virgo A subclump of the cluster?
A: Spiral galaxies
B: Elliptical galaxies
C: Lenticular galaxies
D: Gas-poor spiral galaxies
E: Star clusters
Answer: C

Question: Which galaxy in the Virgo Cluster contains a supermassive black hole with an observed event horizon?
A: Messier 49
B: Messier 86
C: Messier 60
D: Messier 87
E: NGC 4216
Answer: D

Question: What suggests that the Virgo Cluster is a dynamically young cluster that is still forming?
A: The high peculiar velocities of its galaxies
B: The presence of only elliptical galaxies
C: The absence of a dominant subclump
D: The lack of turbulence within the cluster
E: The small number of galaxies in the cluster
Answer: A

Question: What are the smaller galaxy clouds surrounding the Virgo Cluster that are in the process of merging with it called?
A: N Cloud and S Cloud
B: Virgo B and Virgo C
C: M Cloud and W Cloud
D: LVC and Coma I
E: Galaxy groups
Answer: A
@
Messier 98, M98 or NGC 4192, is an intermediate spiral galaxy about 44.4[3] million light-years away in slightly northerly Coma Berenices, about 6° to the east of the bright star Denebola (Beta Leonis). It was discovered by French astronomer Pierre Méchain on 1781,[a] along with nearby M99 and M100, and was catalogued by compatriot Charles Messier 29 days later in his Catalogue des Nébuleuses & des amas d'Étoiles.[5] It has a blueshift, denoting ignoring of its fast other movement (vectors of proper motion), it is approaching at about 140 km/s.[2]

The morphological classification of this galaxy is SAB(s)ab,[3] which indicates it is a spiral galaxy that displays mixed barred and non-barred features with intermediate to tightly wound arms and no ring.[6] It is highly inclined to the line of sight at an angle of 74°[7] and has a maximum rotation velocity of 236 km/s.[8] The combined mass of the stars in this galaxy is an estimated 76 billion (7.6 × 1010) times the mass of the Sun. It contains about 4.3 billion solar masses of neutral hydrogen and 85 million solar masses in dust.[9] The nucleus is active, displaying characteristics of a "transition" type object. That is, it shows properties of a LINER-type galaxy intermixed with an H II region around the nucleus.[10]

Messier 98 is a member of the Virgo Cluster, which is a large cluster of galaxies, part of the local supercluster.[11]

About 750 million years ago, it may have interacted with the large spiral galaxy Messier 99. These are now separated by 1,300,000 ly (400,000 pc).[8]
$
10
Question: What is the morphological classification of Messier 98?
A: SAB(s)ab
B: E0
C: SBc
D: S0
E: Sd
Answer: A

Question: How far away is Messier 98 from Earth in terms of light-years?
A: 44.4 million light-years
B: 1781 light-years
C: 6°
D: 140 km/s
E: 1,300,000 ly
Answer: A

Question: Who discovered Messier 98?
A: Pierre Méchain
B: Charles Messier
C: Denebola
D: LINER-type galaxy
E: Virgo Cluster
Answer: A

Question: What is the maximum rotation velocity of Messier 98?
A: 44.4 million km/s
B: 236 km/s
C: 1781 km/s
D: 140 km/s
E: 1,300,000 km/s
Answer: B

Question: What type of galaxy is Messier 98?
A: Spiral galaxy
B: Elliptical galaxy
C: Lenticular galaxy
D: Irregular galaxy
E: Barred spiral galaxy
Answer: A

Question: How many solar masses of neutral hydrogen does Messier 98 contain?
A: 44.4 billion solar masses
B: 4.3 million solar masses
C: 76 billion solar masses
D: 85 million solar masses
E: 1,300,000 solar masses
Answer: B

Question: What type of object is the nucleus of Messier 98?
A: LINER-type galaxy
B: Quasar
C: Supernova
D: Globular cluster
E: Nebula
Answer: A

Question: In which cluster is Messier 98 a member?
A: Local Supercluster
B: Coma Berenices
C: Virgo Cluster
D: Denebola Cluster
E: Messier 99 Cluster
Answer: C

Question: Approximately how long ago may Messier 98 have interacted with Messier 99?
A: 750,000 years ago
B: 44.4 million years ago
C: 1,300,000 years ago
D: 1781 years ago
E: 6° years ago
Answer: A

Question: What is the approach velocity of Messier 98?
A: 44.4 million km/s
B: 236 km/s
C: 1781 km/s
D: 140 km/s
E: It is not mentioned in the text.
Answer: D
@
The Virgo Supercluster (Virgo SC) or the Local Supercluster (LSC or LS) is a mass concentration of galaxies containing the Virgo Cluster and Local Group, which itself contains the Milky Way and Andromeda galaxies, as well as others. At least 100 galaxy groups and clusters are located within its diameter of 33 megaparsecs (110 million light-years). The Virgo SC is one of about 10 million superclusters in the observable universe and is in the Pisces–Cetus Supercluster Complex, a galaxy filament.

A 2014 study indicates that the Virgo Supercluster is only a lobe of an even greater supercluster, Laniakea, a larger, competing referent of the term Local Supercluster centered on the Great Attractor.[2]

In a comprehensive 1982 paper, R. Brent Tully presented the conclusions of his research concerning the basic structure of the LS. It consists of two components: an appreciably flattened disk containing two-thirds of the supercluster's luminous galaxies, and a roughly spherical halo containing the remaining one-third.[7] The disk itself is a thin (~1 Mpc) ellipsoid with a long axis / short axis ratio of at least 6 to 1, and possibly as high as 9 to 1.[8] Data released in June 2003 from the 5-year Two-degree-Field Galaxy Redshift Survey (2dF) has allowed astronomers to compare the LS to other superclusters. The LS represents a typical poor (that is, lacking a high density core) supercluster of rather small size. It has one rich galaxy cluster in the center, surrounded by filaments of galaxies and poor groups.[1] The Local Group is located on the outskirts of the LS in a small filament extending from the Fornax Cluster to the Virgo Cluster.[6] The Virgo Supercluster's volume is very approximately 7000 times that of the Local Group or 100 billion times that of the Milky Way.

Galaxy distribution
The number density of galaxies in the LS falls off with the square of the distance from its center near the Virgo Cluster, suggesting that this cluster is not randomly located. Overall, the vast majority of the luminous galaxies (less than absolute magnitude −13) are concentrated in a small number of clouds (groups of galaxy clusters). Ninety-eight percent can be found in the following 11 clouds (given in decreasing order of number of luminous galaxies): Canes Venatici, Virgo Cluster, Virgo II (southern extension), Leo II, Virgo III, Crater (NGC 3672), Leo I, Leo Minor (NGC 2841), Draco (NGC 5907), Antlia (NGC 2997), and NGC 5643. Of the luminous galaxies located in the disk, one third are in the Virgo Cluster, while the remainder are found in the Canes Venatici Cloud and Virgo II Cloud, plus the somewhat insignificant NGC 5643 Group.

The luminous galaxies in the halo are also concentrated in a small number of clouds (94% in 7 clouds). This distribution indicates that "most of the volume of the supergalactic plane is a great void."[8] A helpful analogy that matches the observed distribution is that of soap bubbles. Flattish clusters and superclusters are found at the intersection of bubbles, which are large, roughly spherical (on the order of 20–60 Mpc in diameter) voids in space.[9] Long filamentary structures seem to predominate. An example of this is the Hydra–Centaurus Supercluster, the nearest supercluster to the LS, which starts at a distance of roughly 30 Mpc and extends to 60 Mpc.[10]
$
10
Question: How many superclusters are estimated to be in the observable universe?
A: About 10 million superclusters
B: About 100 superclusters
C: About 1,000 superclusters
D: About 1 billion superclusters
E: About 100 billion superclusters
Answer: A

Question: What is the name of the even greater supercluster of which the Virgo Supercluster is a lobe?
A: Milky Way Supercluster
B: Andromeda Supercluster
C: Pisces–Cetus Supercluster
D: Laniakea Supercluster
E: Great Attractor Supercluster
Answer: D

Question: How is the Virgo Supercluster's disk described in terms of shape?
A: A thick sphere
B: A flattened ellipsoid with a long axis / short axis ratio of at least 6 to 1
C: A thin cylinder
D: A perfect sphere
E: A flat plane
Answer: B

Question: What is the approximate volume of the Virgo Supercluster compared to the Milky Way?
A: 100 times that of the Milky Way
B: 1,000 times that of the Milky Way
C: 10,000 times that of the Milky Way
D: 100,000 times that of the Milky Way
E: 1 million times that of the Milky Way
Answer: A

Question: In what direction is the Local Group located with respect to the Virgo Supercluster?
A: In the center of the Virgo Supercluster
B: On the outskirts of the Virgo Supercluster
C: In a small filament extending from the Fornax Cluster to the Virgo Cluster
D: At the intersection of bubbles in space
E: Within the Great Attractor Supercluster
Answer: C

Question: Where are the majority of luminous galaxies located within the Virgo Supercluster?
A: In randomly distributed locations
B: In a few concentrated clouds
C: In the Virgo Cluster only
D: In the Canes Venatici Cloud only
E: In the Milky Way Galaxy
Answer: B

Question: What is the main distribution pattern of long filamentary structures within superclusters?
A: Concentrated at the center
B: Concentrated at the edges
C: Randomly distributed
D: Found at the intersection of bubbles
E: Predominant
Answer: E

Question: Which supercluster is described as the nearest supercluster to the Virgo Supercluster in the text?
A: Pisces–Cetus Supercluster
B: Laniakea Supercluster
C: Canes Venatici Supercluster
D: Hydra–Centaurus Supercluster
E: Milky Way Supercluster
Answer: D

Question: What analogy is used to describe the distribution of clusters and superclusters within the universe?
A: A beehive
B: A chessboard
C: Soap bubbles
D: A tree
E: A spiderweb
Answer: C

Question: How does the number density of galaxies in the Virgo Supercluster vary with distance from its center?
A: It increases linearly with distance.
B: It remains constant at all distances.
C: It falls off with the square of the distance.
D: It decreases exponentially with distance.
E: It has no discernible pattern.
Answer: C
@
The Laniakea Supercluster (/ˌlæni.əˈkeɪ.ə/; Hawaiian for "open skies" or "immense heaven")[2] is the galaxy supercluster that is home to the Milky Way and approximately 100,000 other nearby galaxies. It was defined in September 2014, when a group of astronomers including R. Brent Tully of the University of Hawaiʻi, Hélène Courtois of the University of Lyon, Yehuda Hoffman of the Hebrew University of Jerusalem, and Daniel Pomarède of CEA Université Paris-Saclay published a new way of defining superclusters according to the relative velocities of galaxies.[3][4] The new definition of the local supercluster subsumes the prior defined local supercluster, the Virgo Supercluster, as an appendage.[5][6][7][8][9]

Follow-up studies suggest that the Laniakea Supercluster is not gravitationally bound; it will disperse rather than continue to maintain itself as an overdensity relative to surrounding areas.[10]

The Laniakea Supercluster encompasses approximately 100,000 galaxies stretched out over 160 Mpc (520 million ly). It has the approximate mass of 1017 solar masses, or 100,000 times that of our galaxy, which is almost the same as that of the Horologium Supercluster.[3] It consists of four subparts, which were known previously as separate superclusters:

Virgo Supercluster, the part in which the Milky Way resides.
Hydra–Centaurus Supercluster
the Great Attractor, Laniakea's central gravitational point near Norma
Antlia Wall, known as Hydra Supercluster
Centaurus Supercluster
Pavo–Indus Supercluster
Southern Supercluster, including Fornax Cluster (S373), Dorado and Eridanus clouds.[13]
The most massive galaxy clusters of the Laniakea Supercluster are Virgo, Hydra, Centaurus, Abell 3565, Abell 3574, Abell 3521, Fornax, Eridanus and Norma. The entire supercluster consists of approximately 300 to 500 known galaxy clusters and groups. The real number may be much larger because some of these are traversing the Zone of Avoidance, an area of the sky that is partially obscured by gas and dust from the Milky Way galaxy, making them essentially undetectable.

Superclusters are some of the universe's largest structures and have boundaries that are difficult to define, especially from the inside. Within a given supercluster, most galaxy motions will be directed inward, toward the center of mass. In the case of Laniakea, this gravitational focal point is called the Great Attractor, and influences the motions of the Local Group of galaxies, where the Milky Way galaxy resides, and all others throughout the supercluster. Unlike its constituent clusters, Laniakea is not gravitationally bound and is projected to be torn apart by dark energy.[7]

Although the confirmation of the existence of the Laniakea Supercluster emerged in 2014,[3] early studies in the 1980s already suggested that several of the superclusters then known might be connected. For example, South African astronomer Tony Fairall stated in 1988 that redshifts suggested that the Virgo and Hydra–Centaurus superclusters may be connected.[14]
$
10
Question: What is the meaning of "Laniakea" in Hawaiian?
A: Closed skies
B: Small galaxies
C: Immense heaven
D: Gravitational pull
E: Hidden galaxies
Answer: C

Question: What method did astronomers use to define the Laniakea Supercluster?
A: Counting the number of galaxies
B: Measuring the size of galaxies
C: Calculating the relative velocities of galaxies
D: Analyzing galaxy colors
E: Examining galaxy shapes
Answer: C

Question: How does the mass of the Laniakea Supercluster compare to the mass of our galaxy, the Milky Way?
A: It is 100 times less massive.
B: It is 100,000 times more massive.
C: It is the same mass.
D: It is impossible to determine the mass.
E: It is 10 times more massive.
Answer: B

Question: What is the central gravitational point of the Laniakea Supercluster called?
A: Virgo Supercluster
B: Hydra–Centaurus Supercluster
C: The Great Attractor
D: Antlia Wall
E: Centaurus Supercluster
Answer: C

Question: What is the approximate length of the Laniakea Supercluster in megaparsecs (Mpc)?
A: 520 Mpc
B: 160 Mpc
C: 100,000 Mpc
D: 1017 Mpc
E: 300 to 500 Mpc
Answer: A

Question: Which supercluster is subsumed by the Laniakea Supercluster, making it an appendage?
A: The Hydra Supercluster
B: The Great Attractor
C: The Virgo Supercluster
D: The Centaurus Supercluster
E: The Fornax Cluster
Answer: C

Question: Why is the true number of galaxy clusters within the Laniakea Supercluster difficult to determine?
A: They are too small to detect.
B: They are obscured by gas and dust.
C: They are moving too fast to count.
D: They are located outside the supercluster.
E: They are bound by dark energy.
Answer: B

Question: What is the expected fate of the Laniakea Supercluster due to dark energy?
A: It will collapse into a single galaxy.
B: It will remain gravitationally bound.
C: It will be torn apart.
D: It will become invisible.
E: It will accelerate its expansion.
Answer: C

Question: What influences the motions of galaxies within the Laniakea Supercluster?
A: Galaxy shapes
B: Galaxy colors
C: The Milky Way's gravitational pull
D: Dark matter
E: The Great Attractor
Answer: E

Question: When did early studies first suggest a connection between superclusters like Virgo and Hydra–Centaurus?
A: In the 2010s
B: In the 1990s
C: In the 2000s
D: In the 1980s
E: In the 1970s
Answer: D
@
The Local Void is a vast, empty region of space, lying adjacent to the Local Group.[3][4] Discovered by Brent Tully and Rick Fisher in 1987,[5] the Local Void is now known to be composed of three separate sectors, separated by bridges of "wispy filaments".[4] The precise extent of the void is unknown, but it is at least 45 Mpc (150 million light-years) across,[6] and possibly 150 to 300 Mpc.[7][8] The Local Void appears to have significantly fewer galaxies than expected from standard cosmology.[9]

Location and dimensions
Voids are affected by the way gravity causes matter in the universe to "clump together", herding galaxies into clusters and chains, which are separated by regions mostly devoid of galaxies, yet the exact mechanisms are subject to scientific debate.[3][10]

Astronomers have previously noticed that the Milky Way sits in a large, flat array of galaxies called the Local Sheet, which bounds the Local Void.[3] The Local Void extends approximately 60 megaparsecs (200 Mly), beginning at the edge of the Local Group.[11] It is believed that the distance from Earth to the centre of the Local Void must be at least 23 megaparsecs (75 Mly).[4]

The size of the Local Void was calculated due to an isolated dwarf galaxy known as ESO 461-36 located inside it. The bigger and emptier the void, the weaker its gravity, and the faster the dwarf should be fleeing the void towards concentrations of matter, yet discrepancies give room for competing theories.[4] Dark energy has been suggested as one alternative explanation for the speedy expulsion of the dwarf galaxy.[3]

An earlier "Hubble Bubble" model, based on measured velocities of Type 1a supernovae, proposed a relative void centred on the Milky Way. Recent analysis of that data, however, suggested that interstellar dust had resulted in misleading measurements.[12]

Several authors have shown that the local universe up to 300 Mpc from the Milky Way is less dense than surrounding areas – by 15–50%. This has been called the Local Void or Local Hole.[7][8] Some media reports have dubbed it the KBC Void,[13] although this name has not been taken up in other publications.[citation needed]
$
10
Question: Who discovered the Local Void in 1987?
A: Edwin Hubble
B: Brent Tully and Rick Fisher
C: Henrietta Leavitt
D: Charles Messier
E: Albert Einstein
Answer: B

Question: How is the Local Void different from regions with more galaxies?
A: It contains more galaxies.
B: It has a stronger gravitational pull.
C: It is flat.
D: It is mostly devoid of galaxies.
E: It has more dark matter.
Answer: D

Question: What is the estimated minimum size of the Local Void?
A: 23 megaparsecs
B: 60 megaparsecs
C: 200 megaparsecs
D: 45 megaparsecs
E: 300 megaparsecs
Answer: A

Question: What is ESO 461-36 in relation to the Local Void?
A: A distant star
B: A bridge of wispy filaments
C: An isolated dwarf galaxy located inside the Local Void
D: A black hole
E: A type of dark energy
Answer: C

Question: What factor has been suggested as an explanation for the rapid motion of the dwarf galaxy ESO 461-36 within the Local Void?
A: Dark energy
B: Gravitational pull from the Milky Way
C: Solar wind
D: The Milky Way's rotation
E: Interstellar dust
Answer: A

Question: What earlier model proposed a relative void centered on the Milky Way?
A: Hubble Bubble model
B: Dark Matter theory
C: Einstein's theory of relativity
D: Local Group model
E: Galaxy clumping model
Answer: A

Question: What percentage less dense is the local universe up to 300 Mpc from the Milky Way compared to surrounding areas?
A: 5%
B: 10%
C: 15%
D: 25%
E: 50%
Answer: C

Question: What name has been given to the Local Void in some media reports?
A: Milky Way Void
B: Galactic Gap
C: Local Hole
D: Universe Emptiness
E: Cosmic Abyss
Answer: C
@
The Shapley Supercluster or Shapley Concentration (SCl 124) is the largest concentration of galaxies in our nearby universe that forms a gravitationally interacting unit, thereby pulling itself together instead of expanding with the universe. It appears as a striking overdensity in the distribution of galaxies in the constellation of Centaurus. It is 650 million light-years away (z=0.046).

The Shapley Supercluster lies very close to the direction in which the Local Group of galaxies (including our galaxy) is moving with respect to the cosmic microwave background (CMB) frame of reference. This has led many to speculate that the Shapley Supercluster may indeed be one of the major causes of our galaxy's peculiar motion—the Great Attractor may be another—and has led to a surge of interest in this supercluster. It has been found that the Great Attractor and all the galaxies in our region of the universe (including our galaxy, the Milky Way) are moving toward the Shapley Supercluster.[5]

In 2017 it was proposed that the movement towards attractors like the Shapley Attractor in the supercluster creates a relative movement away from underdense areas, that may be visualized as a virtual repeller. This approach enables new ways of understanding and modelling variations in galactic movements. The nearest large underdense area has been labelled the dipole repeller.[6]
$
10
Question: What is the Shapley Supercluster's location in the universe?
A: In the constellation of Centaurus
B: Near the Milky Way
C: Near the Great Attractor
D: In the cosmic microwave background
E: In the Local Group
Answer: A

Question: How far away is the Shapley Supercluster from Earth in terms of light-years?
A: 650 million light-years
B: 46 million light-years
C: 100 million light-years
D: 1 billion light-years
E: 500 million light-years
Answer: A

Question: What is unique about the Shapley Supercluster's behavior in relation to the expansion of the universe?
A: It expands with the universe.
B: It moves at a constant speed.
C: It pulls itself together gravitationally.
D: It is not affected by gravity.
E: It is repelled by galaxies.
Answer: C

Question: Why is the Shapley Supercluster of particular interest to astronomers studying galactic motion?
A: It is composed of only nearby galaxies.
B: It is responsible for the cosmic microwave background.
C: It is stationary compared to the Milky Way.
D: It may influence the peculiar motion of our galaxy.
E: It is a virtual repeller of galaxies.
Answer: D

Question: What is the relationship between the Great Attractor and the Shapley Supercluster?
A: They are stationary in relation to each other.
B: The Great Attractor is part of the Shapley Supercluster.
C: Both are moving away from the Milky Way.
D: They are both repellers of galaxies.
E: The Shapley Supercluster is moving toward the Great Attractor.
Answer: E

Question: What term is used to describe the nearby underdense area in contrast to the Shapley Supercluster's attracting influence?
A: The Great Repeller
B: The Milky Way Cluster
C: The Cosmic Microwave Background
D: The Dipole Repeller
E: The Virtual Attractor
Answer: D

Question: What is the connection between galactic movements and attractors like the Shapley Supercluster?
A: Attractors cause galaxies to remain stationary.
B: Attractors have no effect on galactic movements.
C: Galactic movements are unaffected by attractors.
D: Attractors cause relative movements away from underdense areas.
E: Attractors repel galaxies in all directions.
Answer: D

Question: How does the Shapley Supercluster relate to the movement of the Local Group of galaxies?
A: It opposes the movement of the Local Group.
B: It is part of the Local Group.
C: It is unaffected by the Local Group's motion.
D: It is moving away from the Local Group.
E: It influences the motion of the Local Group.
Answer: E

Question: What is the significance of the Shapley Supercluster's location with respect to the cosmic microwave background frame of reference?
A: It is the origin point of the cosmic microwave background.
B: It is moving at the speed of light in that frame.
C: It is stationary in that frame.
D: It is the reference point for galactic motion.
E: It is unrelated to the cosmic microwave background.
Answer: D

Question: How far away is the nearest large underdense area in the context of galactic movements?
A: 650 million light-years
B: 46 million light-years
C: 100 million light-years
D: 1 billion light-years
E: It is not mentioned in the text.
Answer: E
@
The Great Attractor is a purported gravitational attraction in intergalactic space and the apparent central gravitational point of the Laniakea Supercluster. This supercluster contains the Milky Way, as well as about 100,000 other galaxies.

The observed attraction suggests a localized concentration of mass millions of times more massive than the Milky Way. However, it is inconveniently obscured by Milky Way's galactic plane, lying behind the Zone of Avoidance (ZOA), so that in visible light wavelengths, the Great Attractor is difficult to observe directly.[1]

The attraction is observable by its effect on the motion of galaxies and their associated clusters over a region of hundreds of millions of light-years across the universe. These galaxies are observable above and below the ZOA; all are redshifted in accordance with the Hubble flow, indicating that they are receding relative to us and to each other, but the variations in their redshifts are large enough and regular enough to reveal that they are slightly drawn towards the attraction. The variations in their redshifts are known as peculiar velocities, and cover a range from about +700 km/s to −700 km/s, depending on the angular deviation from the direction to the Great Attractor.

The Great Attractor itself is moving towards the Shapley Supercluster.[1] Recent astronomical studies by a team of South African astrophysicists revealed a supercluster of galaxies, termed the Vela Supercluster, in the Great Attractor's theorized location.[2]

Discovery
It was first discovered in the 1970s that the Milky Way moves through space. Through a series of peculiar velocity tests, astrophysicists found that the Milky Way was moving in the direction of the constellation of Centaurus at about 600 km/s. Then, the discovery of cosmic microwave background (CMB) dipoles were used to reflect the motion of the Local Group of galaxies towards the Great Attractor.[3] The 1980s brought many discoveries about the Great Attractor such as the fact that the Milky Way is not the only galaxy impacted and an approximation of 400 elliptical galaxies are moving toward the Great Attractor beyond the ZOA.

Location
The first indications of a deviation from uniform expansion of the universe were reported in 1973 and again in 1978. The location of the Great Attractor was finally determined in 1986: It is situated at a distance of somewhere between 150 and 250 Mly (million light-years) (47–79 Mpc) (the larger being the most recent estimate) away from the Milky Way, in the direction of the constellations Triangulum Australe (The Southern Triangle) and Norma (The Carpenter's Square).[4] While objects in that direction lie in the Zone of Avoidance (the part of the night sky obscured by the Milky Way galaxy) and are thus difficult to study with visible wavelengths, X-ray observations have revealed that region of space to be dominated by the Norma Cluster (ACO 3627),[5][6] a massive cluster of galaxies containing a preponderance of large, old galaxies, many of which are colliding with their neighbours and radiating large amounts of radio waves.
$
10
Question: What is the Great Attractor's significance in the universe?
A: It is a small galactic cluster.
B: It is a well-observed region of space.
C: It is the center of the Laniakea Supercluster.
D: It is an area devoid of galaxies.
E: It is a part of the Milky Way.
Answer: C

Question: Why is the Great Attractor difficult to observe in visible light wavelengths?
A: It is too far away from Earth.
B: It is located in the Zone of Avoidance.
C: It emits no visible light.
D: It is too small to be seen.
E: It is obscured by other galaxies.
Answer: B

Question: How is the Great Attractor observable despite being obscured by the Milky Way?
A: By studying its effect on galaxy motion.
B: By using advanced telescopes.
C: By analyzing its visible light emissions.
D: By sending spacecraft to observe it directly.
E: By studying its gravitational waves.
Answer: A

Question: What are the variations in the redshifts of galaxies known as?
A: Cosmic microwave background.
B: Peculiar velocities.
C: Hubble flow.
D: Doppler effects.
E: Galactic deviations.
Answer: B

Question: How does the motion of galaxies around the Great Attractor manifest in their redshifts?
A: They all have zero redshifts.
B: They have redshifts that increase uniformly.
C: They have redshifts that decrease uniformly.
D: They have redshifts that vary irregularly.
E: They have redshifts that are constant.
Answer: D

Question: In which direction is the Great Attractor moving?
A: Toward the Milky Way.
B: Away from the Milky Way.
C: Toward the Shapley Supercluster.
D: Away from the Shapley Supercluster.
E: It is stationary.
Answer: C

Question: What supercluster of galaxies was discovered in the location theorized for the Great Attractor?
A: The Shapley Supercluster
B: The Laniakea Supercluster
C: The Vela Supercluster
D: The Milky Way Supercluster
E: The Centaurus Supercluster
Answer: C

Question: How was the Milky Way's motion towards the Great Attractor initially discovered?
A: Through cosmic microwave background measurements.
B: Through observations of its redshift.
C: Through tests of peculiar velocities.
D: Through direct visual observations.
E: Through gravitational wave analysis.
Answer: C

Question: What did astrophysicists discover about the Milky Way's motion in the 1980s?
A: It is moving away from the Great Attractor.
B: It is the only galaxy impacted by the Great Attractor.
C: It is stationary.
D: Many galaxies, including the Milky Way, are moving toward the Great Attractor.
E: It is moving at the speed of light.
Answer: D

Question: Where is the Great Attractor located in relation to the Milky Way?
A: It is at the center of the Milky Way.
B: It is directly above the Milky Way.
C: It is in the Zone of Avoidance.
D: It is at the edge of the Milky Way.
E: It is in the Andromeda Galaxy.
Answer: C
@
Implications for the fate of the universe
Cosmologists estimate that the acceleration began roughly 5 billion years ago.[95][a] Before that, it is thought that the expansion was decelerating, due to the attractive influence of matter. The density of dark matter in an expanding universe decreases more quickly than dark energy, and eventually the dark energy dominates. Specifically, when the volume of the universe doubles, the density of dark matter is halved, but the density of dark energy is nearly unchanged (it is exactly constant in the case of a cosmological constant).

Projections into the future can differ radically for different models of dark energy. For a cosmological constant, or any other model that predicts that the acceleration will continue indefinitely, the ultimate result will be that galaxies outside the Local Group will have a line-of-sight velocity that continually increases with time, eventually far exceeding the speed of light.[96] This is not a violation of special relativity because the notion of "velocity" used here is different from that of velocity in a local inertial frame of reference, which is still constrained to be less than the speed of light for any massive object (see Uses of the proper distance for a discussion of the subtleties of defining any notion of relative velocity in cosmology). Because the Hubble parameter is decreasing with time, there can actually be cases where a galaxy that is receding from us faster than light does manage to emit a signal which reaches us eventually.[97][98]

However, because of the accelerating expansion, it is projected that most galaxies will eventually cross a type of cosmological event horizon where any light they emit past that point will never be able to reach us at any time in the infinite future[99] because the light never reaches a point where its "peculiar velocity" toward us exceeds the expansion velocity away from us (these two notions of velocity are also discussed in Uses of the proper distance). Assuming the dark energy is constant (a cosmological constant), the current distance to this cosmological event horizon is about 16 billion light years, meaning that a signal from an event happening at present would eventually be able to reach us in the future if the event were less than 16 billion light years away, but the signal would never reach us if the event were more than 16 billion light years away.[98]

As galaxies approach the point of crossing this cosmological event horizon, the light from them will become more and more redshifted, to the point where the wavelength becomes too large to detect in practice and the galaxies appear to vanish completely[100][101] (see Future of an expanding universe). Planet Earth, the Milky Way, and the Local Group of which the Milky Way is a part, would all remain virtually undisturbed as the rest of the universe recedes and disappears from view. In this scenario, the Local Group would ultimately suffer heat death, just as was hypothesized for the flat, matter-dominated universe before measurements of cosmic acceleration.[citation needed]

There are other, more speculative ideas about the future of the universe. The phantom energy model of dark energy results in divergent expansion, which would imply that the effective force of dark energy continues growing until it dominates all other forces in the universe. Under this scenario, dark energy would ultimately tear apart all gravitationally bound structures, including galaxies and solar systems, and eventually overcome the electrical and nuclear forces to tear apart atoms themselves, ending the universe in a "Big Rip". On the other hand, dark energy might dissipate with time or even become attractive. Such uncertainties leave open the possibility of gravity eventually prevailing and lead to a universe that contracts in on itself in a "Big Crunch",[102] or that there may even be a dark energy cycle, which implies a cyclic model of the universe in which every iteration (Big Bang then eventually a Big Crunch) takes about a trillion (1012) years.[103][104] While none of these are supported by observations, they are not ruled out.[citation needed]
$
10
Question: When did cosmologists estimate that the acceleration of the universe began?
A: 5 billion years ago
B: 16 billion years ago
C: 10 billion years ago
D: 20 billion years ago
E: 1 billion years ago
Answer: A

Question: What is the ultimate result projected for galaxies outside the Local Group in models with a cosmological constant?
A: They will stop moving.
B: They will reach the speed of light.
C: Their line-of-sight velocity will continually increase with time.
D: They will move randomly.
E: They will become invisible.
Answer: C

Question: What is the current distance to the cosmological event horizon in models with a constant dark energy (cosmological constant)?
A: 10 billion light years
B: 5 billion light years
C: 16 billion light years
D: 20 billion light years
E: 1 billion light years
Answer: C

Question: How does the light from galaxies approaching the cosmological event horizon change as they get closer to it?
A: It becomes more and more blue-shifted.
B: It becomes dimmer but maintains its color.
C: It becomes increasingly redshifted.
D: It becomes brighter and more colorful.
E: It becomes invisible.
Answer: C

Question: In the scenario of the "Big Rip," what is the ultimate fate of the universe according to the phantom energy model of dark energy?
A: The universe will contract in a "Big Crunch."
B: Dark energy will dissipate.
C: All gravitationally bound structures will tear apart.
D: The universe will enter a cyclic pattern of expansion and contraction.
E: Dark energy will become attractive.
Answer: C

Question: What forces would dark energy eventually overcome in the "Big Rip" scenario?
A: Gravity only
B: Gravitationally bound structures only
C: Electrical and nuclear forces only
D: Gravitationally bound structures, galaxies, and solar systems
E: None, as it would dissipate over time
Answer: D

Question: What is the potential result of dark energy dissipating or becoming attractive in the future of the universe?
A: The universe will enter a cyclic pattern.
B: The universe will contract in a "Big Crunch."
C: The universe will continue to expand indefinitely.
D: The universe will remain unchanged.
E: The universe will tear apart.
Answer: B

Question: What is the dark energy cycle model of the universe?
A: A model in which dark energy dissipates with time.
B: A model in which dark energy becomes attractive.
C: A cyclic model in which the universe undergoes iterations of expansion and contraction.
D: A model in which dark energy dominates all other forces.
E: A model in which dark energy causes galaxies to collide.
Answer: C

Question: What would happen to the Local Group in the scenario where the universe recedes and disappears from view?
A: It would remain undisturbed.
B: It would be torn apart by dark energy.
C: It would contract in a "Big Crunch."
D: It would expand indefinitely.
E: It would vanish completely.
Answer: A

Question: How do models with a cosmological constant predict the fate of galaxies outside the Local Group?
A: They predict that these galaxies will eventually collide.
B: They predict that these galaxies will stop moving.
C: They predict that these galaxies will never reach the speed of light.
D: They predict that these galaxies will expand indefinitely.
E: They predict that these galaxies will be absorbed by the Local Group.
Answer: C
@
In 1998, the High-Z Supernova Search Team[18] published observations of Type Ia ("one-A") supernovae. In 1999, the Supernova Cosmology Project[19] followed by suggesting that the expansion of the universe is accelerating.[26] The 2011 Nobel Prize in Physics was awarded to Saul Perlmutter, Brian P. Schmidt, and Adam G. Riess for their leadership in the discovery.[27][28]

Since then, these observations have been corroborated by several independent sources. Measurements of the cosmic microwave background, gravitational lensing, and the large-scale structure of the cosmos, as well as improved measurements of supernovae, have been consistent with the Lambda-CDM model.[29] Some people argue that the only indications for the existence of dark energy are observations of distance measurements and their associated redshifts. Cosmic microwave background anisotropies and baryon acoustic oscillations serve only to demonstrate that distances to a given redshift are larger than would be expected from a "dusty" Friedmann–Lemaître universe and the local measured Hubble constant.[30]

Supernovae are useful for cosmology because they are excellent standard candles across cosmological distances. They allow researchers to measure the expansion history of the universe by looking at the relationship between the distance to an object and its redshift, which gives how fast it is receding from us. The relationship is roughly linear, according to Hubble's law. It is relatively easy to measure redshift, but finding the distance to an object is more difficult. Usually, astronomers use standard candles: objects for which the intrinsic brightness, or absolute magnitude, is known. This allows the object's distance to be measured from its actual observed brightness, or apparent magnitude. Type Ia supernovae are the best-known standard candles across cosmological distances because of their extreme and consistent luminosity.

Recent observations of supernovae are consistent with a universe made up 71.3% of dark energy and 27.4% of a combination of dark matter and baryonic matter.[31]
$
10
Question: Who received the 2011 Nobel Prize in Physics for their leadership in discovering the acceleration of the universe?
A: Saul Perlmutter, Brian P. Schmidt, and Adam G. Riess
B: Edwin Hubble and Georges Lemaître
C: The High-Z Supernova Search Team
D: The Supernova Cosmology Project
E: The Lambda-CDM model
Answer: A

Question: What type of supernovae are considered excellent standard candles for measuring cosmological distances?
A: Type Ia supernovae
B: Type II supernovae
C: Type III supernovae
D: Type IV supernovae
E: Type V supernovae
Answer: A

Question: How do astronomers use standard candles like Type Ia supernovae to measure the distance to objects in the universe?
A: By measuring their redshift
B: By calculating their absolute magnitude
C: By determining their apparent magnitude
D: By observing their luminosity
E: By analyzing their spectral lines
Answer: C

Question: What is the primary role of Type Ia supernovae in cosmology?
A: They serve as indicators of dark energy.
B: They provide insights into dark matter.
C: They help explain the cosmic microwave background.
D: They reveal the large-scale structure of the cosmos.
E: They demonstrate the existence of baryonic matter.
Answer: A

Question: What is the composition of the universe according to recent observations?
A: 71.3% dark matter and 27.4% dark energy
B: 71.3% dark energy and 27.4% baryonic matter
C: 71.3% baryonic matter and 27.4% dark energy
D: 71.3% dark matter and 27.4% baryonic matter
E: 71.3% dark energy and 27.4% dark matter
Answer: E

Question: What allows researchers to measure the expansion history of the universe using supernovae?
A: Hubble's law
B: The cosmic microwave background
C: Gravitational lensing
D: Baryon acoustic oscillations
E: Large-scale structure of the cosmos
Answer: A

Question: Why are Type Ia supernovae considered excellent standard candles for measuring cosmological distances?
A: They are extremely bright.
B: They have variable luminosities.
C: They have unpredictable spectral lines.
D: They have inconsistent redshifts.
E: They have consistent luminosity.
Answer: E

Question: How did the High-Z Supernova Search Team contribute to the discovery of the universe's acceleration?
A: They made measurements of the cosmic microwave background.
B: They observed gravitational lensing.
C: They improved measurements of supernovae.
D: They discovered dark energy.
E: They measured baryon acoustic oscillations.
Answer: C

Question: What does the Lambda-CDM model describe?
A: The expansion history of the universe
B: The composition of dark energy
C: The large-scale structure of the cosmos
D: The cosmic microwave background
E: The Hubble constant
Answer: A

Question: According to the subject text, what evidence supports the existence of dark energy?
A: Observations of distance measurements and associated redshifts
B: Measurements of the cosmic microwave background
C: Observations of gravitational lensing
D: Analysis of the large-scale structure of the cosmos
E: Study of the local measured Hubble constant
Answer: A
@
A quasar (/ˈkweɪzɑːr/ KWAY-zar) is an extremely luminous active galactic nucleus (AGN). It is sometimes known as a quasi-stellar object, abbreviated QSO. The emission from an AGN is powered by a supermassive black hole with a mass ranging from millions to tens of billions of solar masses, surrounded by a gaseous accretion disc. Gas in the disc falling towards the black hole heats up and releases energy in the form of electromagnetic radiation. The radiant energy of quasars is enormous; the most powerful quasars have luminosities thousands of times greater than that of a galaxy such as the Milky Way.[2][3] Quasars are usually categorized as a subclass of the more general category of AGN. The redshifts of quasars are of cosmological origin.[4]

The term quasar originated as a contraction of "quasi-stellar [star-like] radio source"—because they were first identified during the 1950s as sources of radio-wave emission of unknown physical origin—and when identified in photographic images at visible wavelengths, they resembled faint, star-like points of light. High-resolution images of quasars, particularly from the Hubble Space Telescope, have shown that quasars occur in the centers of galaxies, and that some host galaxies are strongly interacting or merging galaxies.[5] As with other categories of AGN, the observed properties of a quasar depend on many factors, including the mass of the black hole, the rate of gas accretion, the orientation of the accretion disc relative to the observer, the presence or absence of a jet, and the degree of obscuration by gas and dust within the host galaxy.

More than a million quasars have been found,[6] with the nearest known being about 600 million light-years from Earth. The record for the most distant known quasar continues to change. In 2017, quasar ULAS J1342+0928 was detected at redshift z = 7.54. Light observed from this 800-million-solar-mass quasar was emitted when the universe was only 690 million years old.[7][8][9] In 2020, quasar Pōniuāʻena was detected from a time only 700 million years after the Big Bang, and with an estimated mass of 1.5 billion times the mass of the Sun.[10][11] In early 2021, the quasar QSO J0313–1806, with a 1.6-billion-solar-mass black hole, was reported at z = 7.64, 670 million years after the Big Bang.[12]

Quasar discovery surveys have shown that quasar activity was more common in the distant past; the peak epoch was approximately 10 billion years ago.[13] Concentrations of multiple, gravitationally attracted quasars are known as large quasar groups and constitute some of the largest known structures in the universe.
$
10
Question: What is the term "quasar" short for?
A: Quasi-stellar [star-like] radio source
B: Quasi-stellar object
C: Quasi-space anomaly radiation
D: Quasi-stellar radio emission
E: Quasi-stellar gas accretion
Answer: A

Question: What powers the emission from an active galactic nucleus (AGN), including quasars?
A: Supermassive white dwarfs
B: Supermassive neutron stars
C: Supermassive brown dwarfs
D: Supermassive black holes
E: Supermassive red giants
Answer: D

Question: How does gas in the accretion disc around a supermassive black hole release energy?
A: By emitting X-rays
B: By emitting gamma rays
C: By emitting radio waves
D: By emitting visible light
E: By emitting electromagnetic radiation
Answer: E

Question: What is the radiant energy of quasars like compared to that of a galaxy like the Milky Way?
A: Similar
B: Hundreds of times greater
C: Thousands of times greater
D: Millions of times greater
E: Billions of times greater
Answer: C

Question: In what kind of galaxies do quasars typically occur?
A: Spiral galaxies
B: Elliptical galaxies
C: Irregular galaxies
D: Dwarf galaxies
E: Host galaxies
Answer: E

Question: What factors can affect the observed properties of a quasar?
A: The presence of nearby planets
B: The type of accretion disc
C: The color of the host galaxy
D: The orientation of the accretion disc
E: The shape of the black hole
Answer: D

Question: How many quasars have been found to date?
A: Less than 100,000
B: Around 500,000
C: More than a million
D: Approximately 5 million
E: Over 10 million
Answer: C

Question: What was the redshift of the quasar ULAS J1342+0928, detected in 2017?
A: z = 1.23
B: z = 3.14
C: z = 5.67
D: z = 7.54
E: z = 9.82
Answer: D

Question: When was the light observed from the quasar Pōniuāʻena emitted?
A: 1 billion years ago
B: 700 million years ago
C: 500 million years ago
D: 300 million years ago
E: 100 million years ago
Answer: B

Question: What is the estimated mass of the supermassive black hole in the quasar QSO J0313–1806?
A: 100 million times the mass of the Sun
B: 500 million times the mass of the Sun
C: 1 billion times the mass of the Sun
D: 5 billion times the mass of the Sun
E: 10 billion times the mass of the Sun
Answer: C
@
A black hole is a region of spacetime where gravity is so strong that nothing, including light or other electromagnetic waves, has enough energy to escape it.[2] The theory of general relativity predicts that a sufficiently compact mass can deform spacetime to form a black hole.[3][4] The boundary of no escape is called the event horizon. Although it has a great effect on the fate and circumstances of an object crossing it, it has no locally detectable features according to general relativity.[5] In many ways, a black hole acts like an ideal black body, as it reflects no light.[6][7] Moreover, quantum field theory in curved spacetime predicts that event horizons emit Hawking radiation, with the same spectrum as a black body of a temperature inversely proportional to its mass. This temperature is of the order of billionths of a kelvin for stellar black holes, making it essentially impossible to observe directly.

Objects whose gravitational fields are too strong for light to escape were first considered in the 18th century by John Michell and Pierre-Simon Laplace.[8] In 1916, Karl Schwarzschild found the first modern solution of general relativity that would characterize a black hole. David Finkelstein, in 1958, first published the interpretation of "black hole" as a region of space from which nothing can escape. Black holes were long considered a mathematical curiosity; it was not until the 1960s that theoretical work showed they were a generic prediction of general relativity. The discovery of neutron stars by Jocelyn Bell Burnell in 1967 sparked interest in gravitationally collapsed compact objects as a possible astrophysical reality. The first black hole known was Cygnus X-1, identified by several researchers independently in 1971.[9][10]

Black holes of stellar mass form when massive stars collapse at the end of their life cycle. After a black hole has formed, it can grow by absorbing mass from its surroundings. Supermassive black holes of millions of solar masses (M☉) may form by absorbing other stars and merging with other black holes. There is consensus that supermassive black holes exist in the centres of most galaxies.

The presence of a black hole can be inferred through its interaction with other matter and with electromagnetic radiation such as visible light. Any matter that falls onto a black hole can form an external accretion disk heated by friction, forming quasars, some of the brightest objects in the universe. Stars passing too close to a supermassive black hole can be shredded into streamers that shine very brightly before being "swallowed."[11] If other stars are orbiting a black hole, their orbits can be used to determine the black hole's mass and location. Such observations can be used to exclude possible alternatives such as neutron stars. In this way, astronomers have identified numerous stellar black hole candidates in binary systems and established that the radio source known as Sagittarius A*, at the core of the Milky Way galaxy, contains a supermassive black hole of about 4.3 million solar masses.
$
10
Question: What is the boundary of no escape around a black hole called?
A: Event horizon
B: Singularity
C: Photon sphere
D: Ergosphere
E: Schwarzschild radius
Answer: A

Question: Who first proposed the concept of objects with gravitational fields strong enough to prevent light from escaping?
A: John Michell
B: Albert Einstein
C: Isaac Newton
D: Stephen Hawking
E: Galileo Galilei
Answer: A

Question: When did David Finkelstein first publish the interpretation of "black hole" as a region of space from which nothing can escape?
A: 1916
B: 1932
C: 1958
D: 1967
E: 1971
Answer: C

Question: What was the first black hole known, identified in 1971?
A: Cygnus X-1
B: Sagittarius A*
C: V404 Cygni
D: Centaurus A
E: M87
Answer: A

Question: How do supermassive black holes, with millions of solar masses, primarily form?
A: From the collapse of massive stars
B: By absorbing neutron stars
C: By merging with other supermassive black holes
D: Through the Hawking radiation process
E: From the collision of galaxies
Answer: E

Question: What is formed when matter falls onto a black hole and is heated by friction?
A: Accretion disk
B: Quasar
C: Event horizon
D: Ergosphere
E: Photon sphere
Answer: A

Question: How do astronomers determine the presence and characteristics of a black hole?
A: By observing the Schwarzschild radius
B: By studying the singularity
C: By analyzing gravitational waves
D: Through its interaction with other matter and electromagnetic radiation
E: By measuring the ergosphere
Answer: D

Question: What is the radio source at the core of the Milky Way galaxy that contains a supermassive black hole?
A: Cygnus X-1
B: Sagittarius A*
C: V404 Cygni
D: Centaurus A
E: M87
Answer: B

Question: What do stars passing too close to a supermassive black hole create before being consumed?
A: Quasars
B: Neutron stars
C: Accretion disks
D: Streamers
E: Photon spheres
Answer: D

Question: What is the estimated mass of the supermassive black hole at the core of the Milky Way galaxy?
A: 430,000 solar masses
B: 4.3 million solar masses
C: 43 million solar masses
D: 430 million solar masses
E: 4.3 billion solar masses
Answer: B
@
In the past, traditional multilayer perceptron (MLP) models were used for image recognition.[example needed] However, the full connectivity between nodes caused the curse of dimensionality, and was computationally intractable with higher-resolution images. A 1000×1000-pixel image with RGB color channels has 3 million weights per fully-connected neuron, which is too high to feasibly process efficiently at scale.


CNN layers arranged in 3 dimensions
For example, in CIFAR-10, images are only of size 32×32×3 (32 wide, 32 high, 3 color channels), so a single fully connected neuron in the first hidden layer of a regular neural network would have 32*32*3 = 3,072 weights. A 200×200 image, however, would lead to neurons that have 200*200*3 = 120,000 weights.

Also, such network architecture does not take into account the spatial structure of data, treating input pixels which are far apart in the same way as pixels that are close together. This ignores locality of reference in data with a grid-topology (such as images), both computationally and semantically. Thus, full connectivity of neurons is wasteful for purposes such as image recognition that are dominated by spatially local input patterns.

Convolutional neural networks are variants of multilayer perceptrons, designed to emulate the behavior of a visual cortex. These models mitigate the challenges posed by the MLP architecture by exploiting the strong spatially local correlation present in natural images. As opposed to MLPs, CNNs have the following distinguishing features:

3D volumes of neurons. The layers of a CNN have neurons arranged in 3 dimensions: width, height and depth.[74] Where each neuron inside a convolutional layer is connected to only a small region of the layer before it, called a receptive field. Distinct types of layers, both locally and completely connected, are stacked to form a CNN architecture.
Local connectivity: following the concept of receptive fields, CNNs exploit spatial locality by enforcing a local connectivity pattern between neurons of adjacent layers. The architecture thus ensures that the learned "filters" produce the strongest response to a spatially local input pattern. Stacking many such layers leads to nonlinear filters that become increasingly global (i.e. responsive to a larger region of pixel space) so that the network first creates representations of small parts of the input, then from them assembles representations of larger areas.
Shared weights: In CNNs, each filter is replicated across the entire visual field. These replicated units share the same parameterization (weight vector and bias) and form a feature map. This means that all the neurons in a given convolutional layer respond to the same feature within their specific response field. Replicating units in this way allows for the resulting activation map to be equivariant under shifts of the locations of input features in the visual field, i.e. they grant translational equivariance - given that the layer has a stride of one.[75]
Pooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value. In addition to reducing the sizes of feature maps, the pooling operation grants a degree of local translational invariance to the features contained therein, allowing the CNN to be more robust to variations in their positions.[14]
Together, these properties allow CNNs to achieve better generalization on vision problems. Weight sharing dramatically reduces the number of free parameters learned, thus lowering the memory requirements for running the network and allowing the training of larger, more powerful networks.
$
10
Question: What is the major problem with traditional multilayer perceptron (MLP) models when used for image recognition?
A: The full connectivity between nodes results in a high number of weights, causing computational inefficiency.
B: They cannot handle images with RGB color channels.
C: They lack depth in their neural network layers.
D: They are incapable of recognizing spatially local input patterns.
E: They have a limited number of neurons in the first hidden layer.
Answer: A

Question: In the CIFAR-10 dataset, what is the total number of weights for a single fully connected neuron in the first hidden layer of a regular neural network?
A: 32
B: 3,072
C: 32323
D: 200
E: 120,000
Answer: B

Question: Why is full connectivity of neurons wasteful for image recognition tasks like CNNs?
A: It does not account for the spatial structure of data in images.
B: It requires a large number of fully connected layers.
C: It lacks the ability to recognize color channels in images.
D: It treats all pixels in the same way, regardless of their spatial proximity.
E: It uses too few weights in the first hidden layer.
Answer: A

Question: What distinguishes convolutional neural networks (CNNs) from traditional multilayer perceptrons (MLPs)?
A: CNNs have a lower number of layers.
B: CNNs use shared weights for filters.
C: CNNs have fully connected layers.
D: CNNs lack depth in their neural network layers.
E: CNNs ignore the spatial structure of data.
Answer: B

Question: How are neurons arranged in convolutional neural networks (CNNs)?
A: In 2 dimensions: width and height
B: In 1 dimension: depth
C: In 3 dimensions: width, height, and depth
D: In a single dimension: depth
E: In 4 dimensions: width, height, depth, and color channels
Answer: C

Question: What is the term for the small region of a layer before a neuron in a convolutional neural network (CNN) is connected to it?
A: Weight vector
B: Bias
C: Receptive field
D: Activation map
E: Feature map
Answer: C

Question: How do convolutional neural networks (CNNs) exploit spatial locality in data?
A: By using shared weights for filters
B: By reducing the sizes of feature maps
C: By dividing feature maps into sub-regions
D: By enforcing a local connectivity pattern between neurons
E: By stacking many locally connected layers
Answer: D

Question: What does weight sharing mean in the context of convolutional neural networks (CNNs)?
A: Each neuron has its unique set of weights.
B: Neurons in a layer have different weight vectors.
C: Filters are not used in CNNs.
D: Each filter is replicated across the entire visual field and shares the same parameterization.
E: The weights of CNNs are not adjustable.
Answer: D

Question: What is the purpose of the pooling operation in a convolutional neural network (CNN)?
A: To increase the sizes of feature maps
B: To perform feature extraction
C: To reduce the depth of neural network layers
D: To reduce the dimensions of feature maps and introduce local translational invariance
E: To connect neurons across layers
Answer: D

Question: What advantage does weight sharing provide in convolutional neural networks (CNNs)?
A: It increases the number of free parameters learned.
B: It reduces the number of feature maps.
C: It lowers the memory requirements and allows for the training of larger networks.
D: It eliminates the need for convolutional layers.
E: It decreases the spatial resolution of input images.
Answer: C
@
In signal processing and related disciplines, aliasing is the overlapping of frequency components resulting from a sample rate below the Nyquist frequency. This overlap results in distortion or artifacts when the signal is reconstructed from samples which causes the reconstructed signal to differ from the original continuous signal. Aliasing that occurs in signals sampled in time, for instance in digital audio or the stroboscopic effect, is referred to as temporal aliasing. Aliasing in spatially sampled signals (e.g., moiré patterns in digital images) is referred to as spatial aliasing.

Aliasing is generally avoided by applying low-pass filters or anti-aliasing filters (AAF) to the input signal before sampling and when converting a signal from a higher to a lower sampling rate. Suitable reconstruction filtering should then be used when restoring the sampled signal to the continuous domain or converting a signal from a lower to a higher sampling rate. For spatial anti-aliasing, the types of anti-aliasing include fast approximate anti-aliasing (FXAA), multisample anti-aliasing, and supersampling.

When a digital image is viewed, a reconstruction is performed by a display or printer device, and by the eyes and the brain. If the image data is processed in some way during sampling or reconstruction, the reconstructed image will differ from the original image, and an alias is seen.

An example of spatial aliasing is the moiré pattern observed in a poorly pixelized image of a brick wall. Spatial anti-aliasing techniques avoid such poor pixelizations. Aliasing can be caused either by the sampling stage or the reconstruction stage; these may be distinguished by calling sampling aliasing prealiasing and reconstruction aliasing postaliasing.[1]
$
10
Question: What is the term for the overlapping of frequency components resulting from a sample rate below the Nyquist frequency?
A: Aliasing
B: Reconstruction
C: Sampling
D: Distortion
E: Nyquist effect
Answer: A

Question: What is the term for the type of aliasing that occurs in signals sampled in time, as seen in digital audio or the stroboscopic effect?
A: Temporal aliasing
B: Spatial aliasing
C: Nyquist aliasing
D: Reconstruction aliasing
E: Sampling aliasing
Answer: A

Question: How is aliasing generally avoided in signal processing when converting a signal from a higher to a lower sampling rate?
A: By applying anti-aliasing filters before sampling
B: By using high-pass filters after sampling
C: By increasing the Nyquist frequency
D: By reducing the sample rate further
E: By applying distortion filters before sampling
Answer: A

Question: What should be used when restoring a sampled signal to the continuous domain to prevent aliasing?
A: High-pass filters
B: Low-pass filters
C: Distortion filters
D: Reconstruction filters
E: Nyquist filters
Answer: B

Question: What is the term for the spatial aliasing technique that helps avoid poor pixelizations in digital images?
A: Fast approximate anti-aliasing (FXAA)
B: Sampling aliasing
C: Temporal aliasing
D: Nyquist aliasing
E: Multisample anti-aliasing
Answer: A

Question: When is aliasing seen in digital images?
A: When the original image is perfectly reconstructed
B: When the sampling rate exceeds the Nyquist frequency
C: When the image data is not processed during sampling or reconstruction
D: When the reconstructed image differs from the original image
E: When there is no moiré pattern observed
Answer: D

Question: What is the term for aliasing caused by the sampling stage in signal processing?
A: Temporal aliasing
B: Spatial aliasing
C: Prealiasing
D: Postaliasing
E: Nyquist aliasing
Answer: C

Question: What is the term for aliasing caused by the reconstruction stage in signal processing?
A: Temporal aliasing
B: Spatial aliasing
C: Prealiasing
D: Postaliasing
E: Nyquist aliasing
Answer: D

Question: What is an example of spatial aliasing mentioned in the text?
A: The overlapping of frequency components
B: The reconstruction of digital audio
C: The moiré pattern in a pixelized image of a brick wall
D: The Nyquist effect in signal processing
E: The use of low-pass filters in anti-aliasing
Answer: C

Question: What type of filters are used to avoid poor pixelizations and spatial aliasing in digital images?
A: High-pass filters
B: Distortion filters
C: Reconstruction filters
D: Anti-aliasing filters
E: Nyquist filters
Answer: D
@
Early digital fax machines such as the Bartlane cable picture transmission system preceded digital cameras and computers by decades. The first picture to be scanned, stored, and recreated in digital pixels was displayed on the Standards Eastern Automatic Computer (SEAC) at NIST.[12] The advancement of digital imagery continued in the early 1960s, alongside development of the space program and in medical research. Projects at the Jet Propulsion Laboratory, MIT, Bell Labs and the University of Maryland, among others, used digital images to advance satellite imagery, wirephoto standards conversion, medical imaging, videophone technology, character recognition, and photo enhancement.[13]

Rapid advances in digital imaging began with the introduction of MOS integrated circuits in the 1960s and microprocessors in the early 1970s, alongside progress in related computer memory storage, display technologies, and data compression algorithms.

The invention of computerized axial tomography (CAT scanning), using x-rays to produce a digital image of a "slice" through a three-dimensional object, was of great importance to medical diagnostics. As well as origination of digital images, digitization of analog images allowed the enhancement and restoration of archaeological artifacts and began to be used in fields as diverse as nuclear medicine, astronomy, law enforcement, defence and industry.[14]

Advances in microprocessor technology paved the way for the development and marketing of charge-coupled devices (CCDs) for use in a wide range of image capture devices and gradually displaced the use of analog film and tape in photography and videography towards the end of the 20th century. The computing power necessary to process digital image capture also allowed computer-generated digital images to achieve a level of refinement close to photorealism.[15]
$
10
Question: What was the first computer to display a scanned, stored, and recreated digital image in pixels?
A: Standards Eastern Automatic Computer (SEAC)
B: MIT computer
C: Bell Labs computer
D: University of Maryland computer
E: Jet Propulsion Laboratory computer
Answer: A

Question: In what decade did the rapid advances in digital imaging begin with the introduction of MOS integrated circuits?
A: 1950s
B: 1960s
C: 1970s
D: 1980s
E: 1990s
Answer: B

Question: What technological advancement allowed the development of charge-coupled devices (CCDs) for image capture devices?
A: Introduction of microprocessors
B: Development of analog film
C: Advancement of nuclear medicine
D: Use of digital cameras
E: Progress in character recognition
Answer: A

Question: What is the term for using x-rays to produce a digital image of a "slice" through a three-dimensional object, important for medical diagnostics?
A: Videography
B: Photorealism
C: Image restoration
D: Computerized axial tomography (CAT scanning)
E: Satellite imagery
Answer: D

Question: Besides medical diagnostics, in what other field was the digitization of analog images used?
A: Archaeology
B: Astronomy
C: Videophone technology
D: Law enforcement
E: Character recognition
Answer: A

Question: What allowed computer-generated digital images to achieve a level of refinement close to photorealism?
A: Introduction of microprocessors
B: Development of analog film
C: Progress in nuclear medicine
D: Use of charge-coupled devices (CCDs)
E: Advancement of character recognition
Answer: A

Question: What organization or institution displayed the first scanned, stored, and recreated digital image in pixels on the SEAC computer?
A: Bell Labs
B: MIT
C: NIST
D: Jet Propulsion Laboratory
E: University of Maryland
Answer: C

Question: What type of circuits were introduced in the 1960s and contributed to rapid advances in digital imaging?
A: Analog circuits
B: Photographic circuits
C: MOS integrated circuits
D: Nuclear circuits
E: Videographic circuits
Answer: C

Question: What technology gradually displaced the use of analog film and tape in photography and videography?
A: Introduction of microprocessors
B: Charge-coupled devices (CCDs)
C: Progress in medical imaging
D: Use of digital cameras
E: Advancement of character recognition
Answer: B

Question: What kind of image capture devices widely used CCDs for image capture?
A: Analog cameras
B: Film cameras
C: Digital cameras
D: Videography cameras
E: Medical cameras
Answer: C
@
A web browser is an application for accessing websites. When a user requests a web page from a particular website, the browser retrieves its files from a web server and then displays the page on the user's screen. Browsers are used on a range of devices, including desktops, laptops, tablets, and smartphones. In 2020, an estimated 4.9 billion people have used a browser.[1] The most used browser is Google Chrome, with a 65% global market share on all devices, followed by Safari with 18%.[2]

A web browser is not the same thing as a search engine, though the two are often confused.[3][4] A search engine is a website that provides links to other websites. However, to connect to a website's server and display its web pages, a user must have a web browser installed.[5] In some technical contexts, browsers are referred to as user agents.

The purpose of a web browser is to fetch content from the World Wide Web or from local storage and display it on a user's device.[6] This process begins when the user inputs a Uniform Resource Locator (URL), such as https://en.wikipedia.org/, into the browser. Virtually all URLs are retrieved using the Hypertext Transfer Protocol (HTTP), a set of rules for the transfer of data. If the URL uses the secure mode of HTTP (HTTPS), the connection between the browser and the web server is encrypted for the purposes of communications security and information privacy.[7]

Web pages usually contain hyperlinks to other pages and resources. Each link contains a URL, and when it is clicked or tapped, the browser navigates to the new resource. Most browsers use an internal cache of web page resources to improve loading times for subsequent visits to the same page. The cache can store many items, such as large images, so they do not need to be downloaded from the server again.[8] Cached items are usually only stored for as long as the web server stipulates in its HTTP response messages.[9]
$
10
Question: What is the primary function of a web browser?
A: Displaying web pages
B: Providing links to other websites
C: Encrypting data communication
D: Storing large images
E: Navigating to new resources
Answer: A

Question: How many people were estimated to have used a web browser in 2020?
A: 1.9 billion
B: 2.5 billion
C: 4.9 billion
D: 6.3 billion
E: 8.1 billion
Answer: C

Question: Which web browser has the highest global market share on all devices?
A: Safari
B: Mozilla Firefox
C: Microsoft Edge
D: Google Chrome
E: Opera
Answer: D

Question: What is the primary purpose of a search engine?
A: Displaying web pages
B: Providing links to other websites
C: Encrypting data communication
D: Storing large images
E: Navigating to new resources
Answer: B

Question: What protocol is commonly used to retrieve URLs from the World Wide Web?
A: HTTP
B: HTTPS
C: HTML
D: FTP
E: SMTP
Answer: A

Question: What does HTTP stand for in the context of web browsing?
A: Hyperlink Transfer Protocol
B: Hypertext Transfer Program
C: Hypertext Transfer Protocol
D: Hypertext Transport Program
E: Hyperlink Transport Protocol
Answer: C

Question: What does the term "user agent" refer to in technical contexts?
A: A type of search engine
B: A type of web browser
C: The purpose of a web browser
D: The user's device
E: The URL of a web page
Answer: B

Question: What purpose does the internal cache of a web browser serve?
A: Displaying web pages
B: Providing links to other websites
C: Encrypting data communication
D: Storing large images
E: Improving loading times for subsequent visits
Answer: E

Question: What happens when a user clicks or taps on a hyperlink in a web page?
A: The browser encrypts the data communication.
B: The browser stores the hyperlink in its cache.
C: The browser navigates to the new resource.
D: The browser displays the URL of the hyperlink.
E: The browser provides links to other websites.
Answer: C

Question: How long are cached items typically stored in a web browser's cache?
A: Indefinitely
B: Until the user deletes them
C: For as long as the web server specifies
D: For one year
E: For one month
Answer: C
@
The World Wide Web (WWW), commonly known as the Web, is an information system that enables information sharing over the Internet through user-friendly ways meant to appeal to users beyond IT specialists and hobbyists.[1] It allows documents and other web resources to be accessed over the Internet according to specific rules of the Hypertext Transfer Protocol (HTTP).[2]

Documents and downloadable media are made available to the network through web servers and can be accessed by programs such as web browsers. Servers and resources on the World Wide Web are identified and located through character strings called uniform resource locators (URLs). The original and still very common document type is a web page formatted in Hypertext Markup Language (HTML). This markup language supports plain text, images, embedded video and audio contents, and scripts (short programs) that implement complex user interaction. The HTML language also supports hyperlinks (embedded URLs) which provide immediate access to other web resources. Web navigation, or web surfing, is the common practice of following such hyperlinks across multiple websites. Web applications are web pages that function as application software. The information in the Web is transferred across the Internet using the Hypertext Transfer Protocol (HTTP).

Multiple web resources with a common theme and usually a common domain name make up a website. A single web server may provide multiple websites, while some websites, especially the most popular ones, may be provided by multiple servers. Website content is provided by a myriad of companies, organizations, government agencies, and individual users; and comprises an enormous amount of educational, entertainment, commercial, and government information.

The World Wide Web has become the world's dominant information systems platform.[3][4][5][6] It is the primary tool billions of people worldwide use to interact with the Internet.[7]

The Web was invented by Tim Berners-Lee at CERN in 1989 and opened to the public in 1991. It was conceived as a "universal linked information system".[8][9]
$
10
Question: What character strings are used to identify and locate servers and resources on the World Wide Web?
A: URLs
B: HTML
C: HTTP
D: Web browsers
E: Web servers
Answer: A

Question: What markup language is commonly used for formatting web pages on the World Wide Web?
A: XML
B: JavaScript
C: CSS
D: HTML
E: PHP
Answer: D

Question: What is the common practice of following hyperlinks across multiple websites on the Web called?
A: Web surfing
B: Web scripting
C: Web indexing
D: Web hosting
E: Web encoding
Answer: A

Question: What protocol is used to transfer information across the Internet on the World Wide Web?
A: FTP
B: SMTP
C: HTTP
D: TCP/IP
E: HTML
Answer: C

Question: What type of web resources function as application software?
A: Web servers
B: Web browsers
C: Web pages
D: Web scripts
E: Web applications
Answer: E

Question: In what year was the World Wide Web opened to the public?
A: 1989
B: 1990
C: 1991
D: 1992
E: 1993
Answer: C

Question: Who is credited with inventing the World Wide Web?
A: Bill Gates
B: Steve Jobs
C: Mark Zuckerberg
D: Tim Berners-Lee
E: Jeff Bezos
Answer: D

Question: What is the primary tool used by billions of people worldwide to interact with the Internet?
A: Email
B: Social media
C: Web browsers
D: Search engines
E: FTP clients
Answer: C

Question: What does HTTP stand for in the context of the World Wide Web?
A: Hyper Transfer Text Protocol
B: Hypertext Transmission Protocol
C: Hypertext Transfer Protocol
D: High-Speed Text Protocol
E: Hyperlink Transfer Protocol
Answer: C

Question: What type of contents can be embedded in web pages on the World Wide Web?
A: 3D models
B: Virtual reality
C: Videos and audio
D: PDF documents
E: System software
Answer: C
@
The Internet (or internet)[a] is the global system of interconnected computer networks that uses the Internet protocol suite (TCP/IP)[b] to communicate between networks and devices. It is a network of networks that consists of private, public, academic, business, and government networks of local to global scope, linked by a broad array of electronic, wireless, and optical networking technologies. The Internet carries a vast range of information resources and services, such as the interlinked hypertext documents and applications of the World Wide Web (WWW), electronic mail, telephony, and file sharing.

The origins of the Internet date back to research to enable time-sharing of computer resources and the development of packet switching in the 1960s.[2] The set of rules (communication protocols) to enable internetworking on the Internet arose from research and development commissioned in the 1970s by the Defense Advanced Research Projects Agency (DARPA) of the United States Department of Defense in collaboration with universities and researchers across the United States and in the United Kingdom and France.[3][4][5] The ARPANET initially served as a backbone for the interconnection of regional academic and military networks in the United States to enable resource sharing. The funding of the National Science Foundation Network as a new backbone in the 1980s, as well as private funding for other commercial extensions, encouraged worldwide participation in the development of new networking technologies and the merger of many networks using DARPA's Internet protocol suite.[6] The linking of commercial networks and enterprises by the early 1990s, as well as the advent of the World Wide Web,[7] marked the beginning of the transition to the modern Internet,[8] and generated a sustained exponential growth as generations of institutional, personal, and mobile computers were connected to the network. Although the Internet was widely used by academia in the 1980s, subsequent commercialization is what incorporated its services and technologies into virtually every aspect of modern life.
$
10
Question: What is the global system of interconnected computer networks known as?
A: The Web
B: The Internet
C: The Intranet
D: The Ethernet
E: The Darknet
Answer: B

Question: What set of rules enables internetworking on the Internet?
A: Hyperlink protocols
B: Networking standards
C: Communication protocols
D: Packet switching rules
E: Web development guidelines
Answer: C

Question: What organization commissioned research and development for internetworking on the Internet in the 1970s?
A: United Nations (UN)
B: National Aeronautics and Space Administration (NASA)
C: Federal Communications Commission (FCC)
D: Defense Advanced Research Projects Agency (DARPA)
E: International Telecommunication Union (ITU)
Answer: D

Question: What network initially served as a backbone for the interconnection of academic and military networks in the United States?
A: ARPANET
B: NSA Network
C: NASA Network
D: CIA Network
E: UN Network
Answer: A

Question: What marked the beginning of the transition to the modern Internet?
A: The development of packet switching
B: The interconnection of academic networks
C: The creation of the World Wide Web
D: The introduction of email services
E: The growth of telephony services
Answer: C

Question: What encouraged worldwide participation in the development of new networking technologies for the Internet?
A: Private funding for commercial extensions
B: Expansion of academic networks
C: Introduction of wireless technologies
D: Government regulation
E: Decrease in computer usage
Answer: A

Question: When did the transition to the modern Internet begin?
A: In the 1950s
B: In the 1960s
C: In the 1970s
D: In the 1980s
E: In the 1990s
Answer: D

Question: What has incorporated Internet services and technologies into virtually every aspect of modern life?
A: Commercialization
B: Government regulation
C: Academic research
D: Military funding
E: International cooperation
Answer: A

Question: What is the primary protocol suite used on the Internet?
A: TCP/IP
B: HTTP/HTTPS
C: FTP
D: SMTP
E: UDP
Answer: A

Question: What encouraged sustained exponential growth in the number of computers connected to the Internet?
A: Decreased interest in technology
B: Commercialization of academic networks
C: Introduction of mobile computers
D: Expansion of military networks
E: Development of new computer resources
Answer: B
@
Most traditional communication media, including telephone, radio, television, paper mail, and newspapers, are reshaped, redefined, or even bypassed by the Internet, giving birth to new services such as email, Internet telephone, Internet television, online music, digital newspapers, and video streaming websites. Newspaper, book, and other print publishing have adapted to website technology or have been reshaped into blogging, web feeds, and online news aggregators. The Internet has enabled and accelerated new forms of personal interaction through instant messaging, Internet forums, and social networking services. Online shopping has grown exponentially for major retailers, small businesses, and entrepreneurs, as it enables firms to extend their "brick and mortar" presence to serve a larger market or even sell goods and services entirely online. Business-to-business and financial services on the Internet affect supply chains across entire industries.

The Internet has no single centralized governance in either technological implementation or policies for access and usage; each constituent network sets its own policies.[9] The overarching definitions of the two principal name spaces on the Internet, the Internet Protocol address (IP address) space and the Domain Name System (DNS), are directed by a maintainer organization, the Internet Corporation for Assigned Names and Numbers (ICANN). The technical underpinning and standardization of the core protocols is an activity of the Internet Engineering Task Force (IETF), a non-profit organization of loosely affiliated international participants that anyone may associate with by contributing technical expertise.[10] In November 2006, the Internet was included on USA Today's list of the New Seven Wonders.[11]
$
10
Question: What technology has reshaped traditional communication media and given rise to new services?
A: Television
B: Radio
C: The Internet
D: Telephone
E: Paper mail
Answer: C

Question: Which organization oversees the Internet's Domain Name System (DNS) and IP address space?
A: USA Today
B: Internet Corporation for Assigned Names and Numbers (ICANN)
C: Internet Engineering Task Force (IETF)
D: United Nations (UN)
E: Federal Communications Commission (FCC)
Answer: B

Question: What type of personal interaction has been accelerated by the Internet?
A: Face-to-face meetings
B: Handwritten letters
C: Telephone conversations
D: Instant messaging
E: In-person seminars
Answer: D

Question: What activity does the Internet Engineering Task Force (IETF) primarily engage in?
A: International diplomacy
B: Standardization of core protocols
C: Regulation of online content
D: Hosting of social networking services
E: Internet governance
Answer: B

Question: Which media has adapted to website technology and transformed into blogging, web feeds, and online news aggregators?
A: Radio
B: Television
C: Newspapers
D: Telephone
E: Paper mail
Answer: C

Question: What major effect has the Internet had on online shopping for businesses?
A: Reduced market reach
B: Limited small business growth
C: Decreased online sales
D: Increased market reach
E: Eliminated small businesses
Answer: D

Question: What non-profit organization is responsible for the technical underpinning and standardization of core Internet protocols?
A: United Nations (UN)
B: Federal Communications Commission (FCC)
C: Internet Corporation for Assigned Names and Numbers (ICANN)
D: Internet Engineering Task Force (IETF)
E: Internet Society (ISOC)
Answer: D

Question: Which entity sets its own policies for access and usage on the Internet?
A: Internet users
B: Federal governments
C: Internet Corporation for Assigned Names and Numbers (ICANN)
D: Internet Engineering Task Force (IETF)
E: Internet Service Providers (ISPs)
Answer: C

Question: In what way has the Internet affected supply chains in various industries?
A: It has decreased the need for supply chains.
B: It has had no impact on supply chains.
C: It has made supply chains more efficient.
D: It has increased the complexity of supply chains.
E: It has eliminated the need for supply chains.
Answer: C

Question: What recognition did the Internet receive in November 2006 according to USA Today?
A: It was included on the New Seven Wonders list.
B: It was awarded the Nobel Prize in Technology.
C: It was designated as a United Nations heritage site.
D: It was named the World's Most Innovative Technology.
E: It was chosen as the Time Magazine Invention of the Year.
Answer: A
@
The history of the Internet has its origin in information theory and the efforts of scientists and engineers to build and interconnect computer networks. The Internet Protocol Suite, the set of rules used to communicate between networks and devices on the Internet, arose from research and development in the United States and involved international collaboration, particularly with researchers in the United Kingdom and France.[1][2][3][4]

Computer science was an emerging discipline in the late 1950s that began to consider time-sharing between computer users, and later, the possibility of achieving this over wide area networks. J. C. R. Licklider developed the idea of a universal network at the Information Processing Techniques Office (IPTO) of the United States Department of Defense (DoD) Advanced Research Projects Agency (ARPA). Independently, Paul Baran at the RAND Corporation proposed a distributed network based on data in message blocks in the early 1960s, and Donald Davies conceived of packet switching in 1965 at the National Physical Laboratory (NPL), proposing a national commercial data network in the United Kingdom.

ARPA awarded contracts in 1969 for the development of the ARPANET project, directed by Robert Taylor and managed by Lawrence Roberts. ARPANET adopted the packet switching technology proposed by Davies and Baran, underpinned by mathematical work in the early 1970s by Leonard Kleinrock at UCLA. The network was built by a team at Bolt, Beranek, and Newman, which included Bob Kahn.

Several early packet-switched networks emerged in the 1970s which researched and provided data networking. ARPA projects, international working groups and commercial initiatives led to the development of various standards and protocols for internetworking, in which multiple separate networks could be joined into a network of networks. Louis Pouzin at the IRIA and, separately, Peter Kirstein at University College London put internetworking into practice in 1973. Vint Cerf, at Stanford University, and Bob Kahn, now at DARPA, published research in 1974 that evolved into the Transmission Control Protocol (TCP) and Internet Protocol (IP), two protocols of the Internet protocol suite. The design included concepts from the French CYCLADES project directed by Louis Pouzin.
$
10
Question: Who developed the idea of a universal network at the Information Processing Techniques Office (IPTO) of the United States Department of Defense (DoD)?
A: Paul Baran
B: Donald Davies
C: J. C. R. Licklider
D: Leonard Kleinrock
E: Robert Taylor
Answer: C

Question: What technology did Donald Davies conceive of in 1965?
A: Packet switching
B: Universal network
C: Time-sharing
D: Distributed network
E: Data networking
Answer: A

Question: Who managed the ARPANET project and directed its development in 1969?
A: Paul Baran
B: Donald Davies
C: Leonard Kleinrock
D: Robert Taylor
E: Vint Cerf
Answer: D

Question: What mathematical work in the early 1970s underpinned the development of ARPANET?
A: Packet switching
B: Data networking
C: Time-sharing
D: Universal network
E: Internet protocol suite
Answer: A

Question: Who published research in 1974 that evolved into the Transmission Control Protocol (TCP) and Internet Protocol (IP)?
A: Paul Baran
B: Donald Davies
C: Leonard Kleinrock
D: Vint Cerf
E: Robert Taylor
Answer: D

Question: What concept from the French CYCLADES project influenced the design of TCP and IP?
A: Packet switching
B: Data networking
C: Time-sharing
D: Universal network
E: Internet protocol suite
Answer: A

Question: What organization put internetworking into practice in 1973?
A: ARPANET
B: IRIA
C: University College London
D: UCLA
E: DARPA
Answer: B

Question: Who was responsible for the development of the ARPANET's packet switching technology?
A: Paul Baran
B: Donald Davies
C: Leonard Kleinrock
D: Robert Taylor
E: Bob Kahn
Answer: E

Question: What were the two protocols of the Internet protocol suite developed by Vint Cerf and Bob Kahn in 1974?
A: HTTP and FTP
B: TCP and IP
C: SMTP and POP3
D: DNS and DHCP
E: UDP and ICMP
Answer: B

Question: What project led by Louis Pouzin influenced the design of the Internet protocol suite?
A: ARPANET
B: CYCLADES
C: IRIA
D: UCLA
E: DARPA
Answer: B
@
In the late 1970s, national and international public data networks emerged based on the X.25 protocol, the design of which included the work of Rémi Després. In the United States, the National Science Foundation (NSF) funded national supercomputing centers at several universities in the United States, and provided interconnectivity in 1986 with the NSFNET project, thus creating network access to these supercomputer sites for research and academic organizations in the United States. International connections to NSFNET, the emergence of architecture such as the Domain Name System, and the adoption of TCP/IP on existing networks in the United States and around the world marked the beginnings of the Internet.[5][6][7] Commercial Internet service providers (ISPs) emerged in 1989 in the United States and Australia.[8] The ARPANET was decommissioned in 1990.[9] Limited private connections to parts of the Internet by officially commercial entities emerged in several American cities by late 1989 and 1990.[10] The optical backbone of the NSFNET was decommissioned in 1995, removing the last restrictions on the use of the Internet to carry commercial traffic, as traffic transitioned to optical networks managed by Sprint, MCI and AT&T in the United States.

Research at CERN in Switzerland by the British computer scientist Tim Berners-Lee in 1989–90 resulted in the World Wide Web, linking hypertext documents into an information system, accessible from any node on the network.[11] The dramatic expansion of capacity of the Internet, enabled by the advent of wave division multiplexing (WDM) and the roll out of fiber optic cables in the mid-1990s, had a revolutionary impact on culture, commerce, and technology. This made possible the rise of near-instant communication by electronic mail, instant messaging, voice over Internet Protocol (VoIP) telephone calls, video chat, and the World Wide Web with its discussion forums, blogs, social networking services, and online shopping sites. Increasing amounts of data are transmitted at higher and higher speeds over fiber-optic networks operating at 1 Gbit/s, 10 Gbit/s, and 800 Gbit/s by 2019.[12] The Internet's takeover of the global communication landscape was rapid in historical terms: it only communicated 1% of the information flowing through two-way telecommunications networks in the year 1993, 51% by 2000, and more than 97% of the telecommunicated information by 2007.[13] The Internet continues to grow, driven by ever greater amounts of online information, commerce, entertainment, and social networking services. However, the future of the global network may be shaped by regional differences.[14]
$
10
Question: In the late 1970s, what protocol was the basis for the emergence of national and international public data networks?
A: X.25
B: TCP/IP
C: HTTP
D: DNS
E: VoIP
Answer: A

Question: In 1986, what project funded by the National Science Foundation (NSF) provided network access to supercomputer sites in the United States?
A: NSFNET
B: ARPANET
C: WDM
D: AT&T
E: VoIP
Answer: A

Question: What British computer scientist is credited with inventing the World Wide Web in 1989–90?
A: Tim Berners-Lee
B: Rémi Després
C: Leonard Kleinrock
D: Paul Baran
E: Bob Kahn
Answer: A

Question: What technology enabled the dramatic expansion of Internet capacity in the mid-1990s?
A: X.25
B: VoIP
C: Wave division multiplexing (WDM)
D: DNS
E: TCP/IP
Answer: C

Question: What percentage of the telecommunicated information was communicated through the Internet by the year 2007?
A: 1%
B: 51%
C: 97%
D: 10%
E: 800%
Answer: C

Question: When did commercial Internet service providers (ISPs) emerge in the United States and Australia?
A: 1970
B: 1986
C: 1989
D: 1990
E: 1995
Answer: C

Question: What network managed by Sprint, MCI, and AT&T in the United States removed the last restrictions on the use of the Internet to carry commercial traffic?
A: ARPANET
B: NSFNET
C: VoIP
D: WDM
E: DNS
Answer: B

Question: What technology allowed the transmission of increasing amounts of data at higher speeds over fiber-optic networks?
A: X.25
B: DNS
C: VoIP
D: Wave division multiplexing (WDM)
E: TCP/IP
Answer: D

Question: Which of the following was NOT mentioned as a form of near-instant communication enabled by the Internet?
A: Electronic mail
B: Instant messaging
C: VoIP telephone calls
D: Newspapers
E: Video chat
Answer: D

Question: What did the Internet only communicate 1% of the information flowing through in the year 1993?
A: 10 Gbit/s
B: Voice over Internet Protocol (VoIP) telephone calls
C: Telecommunications networks
D: Blogs
E: Hypertext documents
Answer: C
@
Fiber-optic communication is a method of transmitting information from one place to another by sending pulses of infrared or visible light through an optical fiber.[1][2] The light is a form of carrier wave that is modulated to carry information.[3] Fiber is preferred over electrical cabling when high bandwidth, long distance, or immunity to electromagnetic interference is required.[4] This type of communication can transmit voice, video, and telemetry through local area networks or across long distances.[5]

Optical fiber is used by many telecommunications companies to transmit telephone signals, internet communication, and cable television signals. Researchers at Bell Labs have reached a record bandwidth–distance product of over 100 petabit × kilometers per second using fiber-optic communication.[6]

Optical fiber is used by telecommunications companies to transmit telephone signals, Internet communication and cable television signals. It is also used in other industries, including medical, defense, government, industrial and commercial. In addition to serving the purposes of telecommunications, it is used as light guides, for imaging tools, lasers, hydrophones for seismic waves, SONAR, and as sensors to measure pressure and temperature.

Due to lower attenuation and interference, optical fiber has advantages over copper wire in long-distance, high-bandwidth applications. However, infrastructure development within cities is relatively difficult and time-consuming, and fiber-optic systems can be complex and expensive to install and operate. Due to these difficulties, early fiber-optic communication systems were primarily installed in long-distance applications, where they can be used to their full transmission capacity, offsetting the increased cost. The prices of fiber-optic communications have dropped considerably since 2000.[10]

The price for rolling out fiber to homes has currently become more cost-effective than that of rolling out a copper-based network. Prices have dropped to $850 per subscriber in the US and lower in countries like The Netherlands, where digging costs are low and housing density is high.[citation needed]

Since 1990, when optical-amplification systems became commercially available, the telecommunications industry has laid a vast network of intercity and transoceanic fiber communication lines. By 2002, an intercontinental network of 250,000 km of submarine communications cable with a capacity of 2.56 Tb/s was completed, and although specific network capacities are privileged information, telecommunications investment reports indicate that network capacity has increased dramatically since 2004.[11] As of 2020, over 5 billion kilometers of fiber-optic cable has been deployed around the globe.[12]
$
10
Question: What form of light is used for fiber-optic communication?
A: Ultraviolet light
B: Infrared light
C: Visible light
D: X-rays
E: Radio waves
Answer: B

Question: When is fiber preferred over electrical cabling in communication?
A: When low bandwidth is required
B: When short distances are involved
C: When susceptibility to electromagnetic interference is desired
D: When high bandwidth, long distance, or immunity to electromagnetic interference is required
E: When voice transmission is the primary goal
Answer: D

Question: What is the record bandwidth–distance product achieved by researchers at Bell Labs in fiber-optic communication?
A: 100 petabit × kilometers per second
B: 1 gigabit × kilometers per second
C: 10 terabit × kilometers per second
D: 100 terabit × kilometers per second
E: 1 petabit × kilometers per second
Answer: A

Question: In addition to telecommunications, in what other industries is optical fiber used?
A: Automotive
B: Agriculture
C: Entertainment
D: Medical, defense, government, industrial, and commercial
E: Food and beverage
Answer: D

Question: What advantage does optical fiber have over copper wire in long-distance, high-bandwidth applications?
A: It is cheaper to install.
B: It is less prone to breakage.
C: It is less complex.
D: It has lower attenuation and interference.
E: It is easier to maintain.
Answer: D
@
An optical fiber, or optical fibre in Commonwealth English, is a flexible glass or plastic fiber that can transmit light[a] from one end to the other. Such fibers are made by drawing or extruding of glass or various plastics.[1][2] Such fibers find wide usage in fiber-optic communications, where they permit transmission over longer distances and at higher bandwidths (data transfer rates) than electrical cables. Fibers are used instead of metal wires because signals travel along them with less loss; in addition, fibers are immune to electromagnetic interference, a problem from which metal wires suffer.[3] Fibers are also used for illumination and imaging, and are often wrapped in bundles so they may be used to carry light into, or images out of confined spaces, as in the case of a fiberscope.[4] Specially designed fibers are also used for a variety of other applications, some of them being fiber optic sensors and fiber lasers.[5]

Optical fibers typically include a core surrounded by a transparent cladding material with a lower index of refraction. Light is kept in the core by the phenomenon of total internal reflection which causes the fiber to act as a waveguide.[6] Fibers that support many propagation paths or transverse modes are called multi-mode fibers, while those that support a single mode are called single-mode fibers (SMF).[7] Multi-mode fibers generally have a wider core diameter[8] and are used for short-distance communication links and for applications where high power must be transmitted.[9] Single-mode fibers are used for most communication links longer than 1,050 meters (3,440 ft).[10]

Being able to join optical fibers with low loss is important in fiber optic communication.[11] This is more complex than joining electrical wire or cable and involves careful cleaving of the fibers, precise alignment of the fiber cores, and the coupling of these aligned cores. For applications that demand a permanent connection a fusion splice is common. In this technique, an electric arc is used to melt the ends of the fibers together. Another common technique is a mechanical splice, where the ends of the fibers are held in contact by mechanical force. Temporary or semi-permanent connections are made by means of specialized optical fiber connectors.[12]

The field of applied science and engineering concerned with the design and application of optical fibers is known as fiber optics. The term was coined by Indian-American physicist Narinder Singh Kapany.[13]
$
10

Question: What materials are optical fibers typically made of?
A: Copper and aluminum
B: Glass or plastic
C: Steel and iron
D: Rubber and silicone
E: Paper and cardboard
Answer: B

Question: Why are fibers used instead of metal wires in fiber-optic communications?
A: Fibers are cheaper to manufacture.
B: Signals travel along fibers with less loss.
C: Fibers are easier to install.
D: Fibers are immune to electrical interference.
E: Metal wires have higher bandwidth.
Answer: B

Question: What causes optical fibers to act as waveguides and keep light within the core?
A: Refraction
B: Diffraction
C: Total internal reflection
D: Scattering
E: Absorption
Answer: C

Question: What are optical fibers called when they support many propagation paths or transverse modes?
A: Single-mode fibers
B: Multi-mode fibers
C: Waveguide fibers
D: Cladding fibers
E: Core fibers
Answer: B

Question: What technique is commonly used to join optical fibers with low loss in fiber optic communication?
A: Electrical welding
B: Mechanical splicing
C: Soldering
D: Chemical bonding
E: Gluing
Answer: B

Question: Who coined the term "fiber optics"?
A: Thomas Edison
B: Alexander Graham Bell
C: Albert Einstein
D: Narinder Singh Kapany
E: Isaac Newton
Answer: D

Question: What type of optical fibers are used for communication links longer than 1,050 meters (3,440 ft)?
A: Multi-mode fibers
B: Single-mode fibers
C: Cladding fibers
D: Waveguide fibers
E: Core fibers
Answer: B

Question: In which field of science and engineering is the design and application of optical fibers studied?
A: Electrical engineering
B: Mechanical engineering
C: Civil engineering
D: Fiber optics
E: Computer science
Answer: D

Question: What is used to melt the ends of optical fibers together in a fusion splice?
A: Electrical current
B: Pressure
C: Heat from a flame
D: Chemical bonding
E: Ultraviolet light
Answer: C

Question: What is the phenomenon that causes optical fibers to act as waveguides?
A: Scattering
B: Diffraction
C: Refraction
D: Total internal reflection
E: Absorption
Answer: D
@
A computer network is a set of computers sharing resources located on or provided by network nodes. Computers use common communication protocols over digital interconnections to communicate with each other. These interconnections are made up of telecommunication network technologies based on physically wired, optical, and wireless radio-frequency methods that may be arranged in a variety of network topologies.

The nodes of a computer network can include personal computers, servers, networking hardware, or other specialized or general-purpose hosts. They are identified by network addresses and may have hostnames. Hostnames serve as memorable labels for the nodes and are rarely changed after initial assignment. Network addresses serve for locating and identifying the nodes by communication protocols such as the Internet Protocol.

Computer networks may be classified by many criteria, including the transmission medium used to carry signals, bandwidth, communications protocols to organize network traffic, the network size, the topology, traffic control mechanisms, and organizational intent.[citation needed]

Computer networks support many applications and services, such as access to the World Wide Web, digital video and audio, shared use of application and storage servers, printers and fax machines, and use of email and instant messaging applications.

Most modern computer networks use protocols based on packet-mode transmission. A network packet is a formatted unit of data carried by a packet-switched network.

Packets consist of two types of data: control information and user data (payload). The control information provides data the network needs to deliver the user data, for example, source and destination network addresses, error detection codes, and sequencing information. Typically, control information is found in packet headers and trailers, with payload data in between.

With packets, the bandwidth of the transmission medium can be better shared among users than if the network were circuit switched. When one user is not sending packets, the link can be filled with packets from other users, and so the cost can be shared, with relatively little interference, provided the link is not overused. Often the route a packet needs to take through a network is not immediately available. In that case, the packet is queued and waits until a link is free.

The physical link technologies of packet networks typically limit the size of packets to a certain maximum transmission unit (MTU). A longer message may be fragmented before it is transferred and once the packets arrive, they are reassembled to construct the original message.
$
10
Question: What is the purpose of network addresses in computer networks?
A: To serve as memorable labels for the nodes
B: To carry user data (payload)
C: To provide control information for the network
D: To identify the source of network traffic
E: To define the network's topology
Answer: D

Question: What is the primary advantage of using packet-mode transmission in computer networks?
A: It allows for unlimited bandwidth sharing.
B: It eliminates the need for network addresses.
C: It enables circuit-switched communication.
D: It provides better sharing of bandwidth among users.
E: It doesn't require packet headers and trailers.
Answer: D

Question: What do network packets consist of in packet-switched networks?
A: Only control information
B: Only user data (payload)
C: Both control information and user data
D: Source and destination network addresses
E: Sequencing information only
Answer: C

Question: What is the purpose of control information in a network packet?
A: To carry user data (payload)
B: To serve as memorable labels for nodes
C: To identify the source and destination network addresses
D: To provide data the network needs to deliver the user data
E: To determine the network's size
Answer: D

Question: What do hostnames serve as in computer networks?
A: Control information in network packets
B: Memorable labels for the nodes
C: Transmission mediums for data
D: Sequencing information for packets
E: Error detection codes in packet headers
Answer: B

Question: How do most modern computer networks transmit data?
A: Using circuit-switched transmission
B: By eliminating packet headers and trailers
C: Via packet-mode transmission
D: Through analog interconnections
E: Using telecommunication network technologies
Answer: C

Question: In packet-switched networks, what happens when one user is not sending packets?
A: The link is overused.
B: The network becomes congested.
C: The link is immediately available for other users.
D: The user's data is lost.
E: The link is filled with packets from other users.
Answer: E

Question: What is the maximum transmission unit (MTU) in packet networks?
A: The bandwidth of the transmission medium
B: The size limit for network addresses
C: The maximum number of nodes in the network
D: The maximum size of network packets
E: The number of network protocols used
Answer: D

Question: What is the function of packet headers and trailers in network packets?
A: To provide error detection codes
B: To carry user data (payload)
C: To define the network's topology
D: To serve as memorable labels for nodes
E: To identify the source and destination network addresses
Answer: A

Question: What happens to longer messages in packet-switched networks?
A: They are discarded.
B: They are immediately sent as a single packet.
C: They are transmitted without fragmentation.
D: They are fragmented before transmission.
E: They are queued indefinitely.
Answer: D
@
Radar is a radiolocation system that uses radio waves to determine the distance (ranging), angle (azimuth), and radial velocity of objects relative to the site. It is used to detect and track aircraft, ships, spacecraft, guided missiles, and motor vehicles, and map weather formations, and terrain. A radar system consists of a transmitter producing electromagnetic waves in the radio or microwaves domain, a transmitting antenna, a receiving antenna (often the same antenna is used for transmitting and receiving) and a receiver and processor to determine properties of the objects. Radio waves (pulsed or continuous) from the transmitter reflect off the objects and return to the receiver, giving information about the objects' locations and speeds.

Radar was developed secretly for military use by several countries in the period before and during World War II. A key development was the cavity magnetron in the United Kingdom, which allowed the creation of relatively small systems with sub-meter resolution. The term RADAR was coined in 1940 by the United States Navy as an acronym for radio detection and ranging.[1][2][3][4][5] The term radar has since entered English and other languages as a common noun, losing all capitalization.

The modern uses of radar are highly diverse, including air and terrestrial traffic control, radar astronomy, air-defense systems, anti-missile systems, marine radars to locate landmarks and other ships, aircraft anti-collision systems, ocean surveillance systems, outer space surveillance and rendezvous systems, meteorological precipitation monitoring, altimetry and flight control systems, guided missile target locating systems, self-driving cars, and ground-penetrating radar for geological observations. Modern high tech radar systems use digital signal processing and machine learning and are capable of extracting useful information from very high noise levels.

Other systems which are similar to radar make use of other parts of the electromagnetic spectrum. One example is lidar, which uses predominantly infrared light from lasers rather than radio waves. With the emergence of driverless vehicles, radar is expected to assist the automated platform to monitor its environment, thus preventing unwanted incidents.[6]
$
10
Question: What is the purpose of a radar system?
A: To generate radio waves
B: To determine the color of objects
C: To track and detect objects' distance, angle, and speed
D: To create electromagnetic waves
E: To map weather patterns
Answer: C

Question: What key development allowed the creation of relatively small radar systems with sub-meter resolution?
A: Cavity magnetron
B: Radar astronomy
C: Air-defense systems
D: Guided missile target locating systems
E: Radio detection and ranging
Answer: A

Question: When was the term "RADAR" coined?
A: During World War I
B: In the early 1930s
C: In the late 1940s
D: During World War II
E: In the 1950s
Answer: D

Question: What are some modern uses of radar systems?
A: Baking and cooking
B: Vehicle maintenance
C: Air and terrestrial traffic control
D: Agriculture and farming
E: Movie production
Answer: C

Question: In a radar system, what reflects off objects and provides information about their locations and speeds?
A: Microwaves
B: Electromagnetic waves
C: Radio waves
D: Laser beams
E: Infrared light
Answer: C

Question: What does lidar primarily use to detect objects?
A: Radio waves
B: Infrared light from lasers
C: Microwaves
D: Ultraviolet light
E: X-rays
Answer: B

Question: What technology is expected to assist driverless vehicles in monitoring their environment?
A: Sonar
B: Radar
C: Lidar
D: Radiolocation
E: Microwave
Answer: B

Question: What did the term "RADAR" originally stand for?
A: Radar Detection and Ranging
B: Radiowave Deployment and Reception
C: Radioactive Detection and Reflection
D: Remote Access and Detection
E: Radar Amplification and Reception
Answer: A

Question: What is the role of the receiver and processor in a radar system?
A: To generate radio waves
B: To determine the color of objects
C: To produce electromagnetic waves
D: To calculate properties of objects
E: To transmit signals to objects
Answer: D

Question: What technological advancements are used in modern high-tech radar systems?
A: Digital signal processing and machine learning
B: Vacuum tubes and analog processing
C: Cathode ray tubes and optical processing
D: Morse code and analog recording
E: Amplitude modulation and analog processing
Answer: A
@
In military terminology, a missile is a guided airborne ranged weapon capable of self-propelled flight usually by a jet engine or rocket motor.[1] Missiles are thus also called guided missiles or guided rockets (when a previously unguided rocket is made guided). Missiles have five system components: targeting, guidance system, flight system, engine, and warhead. Missiles come in types adapted for different purposes: surface-to-surface and air-to-surface missiles (ballistic, cruise, anti-ship, anti-submarine, anti-tank, etc.), surface-to-air missiles (and anti-ballistic), air-to-air missiles, and anti-satellite weapons.

Airborne explosive devices without propulsion are referred to as shells if fired by an artillery piece and bombs if dropped by an aircraft. Unguided jet- or rocket-propelled weapons are usually described as rocket artillery.

Missiles are generally categorized by their launch platform and intended target. In broadest terms, the launcher and target are either surface (ground or water) or air, and then missiles are sub-categorized by range and the exact target type (such as anti-tank or anti-ship). Many weapons are designed to be launched from both surface or the air, and a few are designed to attack either surface or air targets (such as the ADATS missile). Most weapons require some modification in order to be launched from the air or surface, such as adding boosters to the surface-launched version.

Missiles generally have one or more explosive warheads, although other weapon types may also be used. The warheads of a missile provide its primary destructive power (many missiles have extensive secondary destructive power due to the high kinetic energy of the weapon and unburnt fuel that may be on board). Warheads are most commonly of the high explosive type, often employing shaped charges to exploit the accuracy of a guided weapon to destroy hardened targets. Other warhead types include submunitions, incendiaries, nuclear weapons, chemical, biological or radiological weapons or kinetic energy penetrators. Warheadless missiles are often used for testing and training purposes.
$
10
Question: What are the five system components of a missile?
A: Targeting, propulsion system, wings, guidance system, and warhead
B: Targeting, guidance system, flight system, engine, and warhead
C: Launch platform, propulsion system, wings, guidance system, and warhead
D: Launch platform, guidance system, flight system, engine, and warhead
E: Targeting, propulsion system, flight system, engine, and warhead
Answer: B

Question: What is the primary purpose of the warheads on missiles?
A: To provide propulsion
B: To guide the missile
C: To destroy hardened targets
D: To enhance the missile's accuracy
E: To provide kinetic energy
Answer: C

Question: What is the term used for unguided jet- or rocket-propelled weapons?
A: Shells
B: Bombs
C: Missiles
D: Rockets
E: Torpedoes
Answer: A

Question: How are missiles generally categorized?
A: By their warhead type
B: By their propulsion system
C: By their guidance system
D: By their launch platform and intended target
E: By their flight altitude
Answer: D

Question: What type of missile is designed to attack both surface and air targets?
A: Anti-tank missile
B: Surface-to-surface missile
C: Anti-ship missile
D: Surface-to-air missile
E: Anti-satellite weapon
Answer: D

Question: What is the term for airborne explosive devices without propulsion?
A: Shells
B: Rockets
C: Bombs
D: Torpedoes
E: Missiles
Answer: C

Question: What is the primary source of destructive power in missile warheads?
A: High-speed flight
B: Unburnt fuel
C: Shaped charges
D: Secondary explosions
E: Kinetic energy
Answer: C

Question: What is the primary source of a missile's propulsion?
A: Wings
B: Guidance system
C: Jet engine or rocket motor
D: Warhead
E: Secondary explosions
Answer: C

Question: What term is used for missiles that have no warheads and are used for testing and training?
A: Dummy missiles
B: Inert missiles
C: Lightweight missiles
D: Training missiles
E: Warheadless missiles
Answer: B

Question: What type of missile is designed for underwater attacks?
A: Anti-ship missile
B: Anti-tank missile
C: Surface-to-air missile
D: Anti-submarine missile
E: Air-to-air missile
Answer: D
@
A rocket engine uses stored rocket propellants as the reaction mass for forming a high-speed propulsive jet of fluid, usually high-temperature gas. Rocket engines are reaction engines, producing thrust by ejecting mass rearward, in accordance with Newton's third law. Most rocket engines use the combustion of reactive chemicals to supply the necessary energy, but non-combusting forms such as cold gas thrusters and nuclear thermal rockets also exist. Vehicles propelled by rocket engines are commonly called rockets. Rocket vehicles carry their own oxidiser, unlike most combustion engines, so rocket engines can be used in a vacuum to propel spacecraft and ballistic missiles.

Compared to other types of jet engine, rocket engines are the lightest and have the highest thrust, but are the least propellant-efficient (they have the lowest specific impulse). The ideal exhaust is hydrogen, the lightest of all elements, but chemical rockets produce a mix of heavier species, reducing the exhaust velocity.

Rocket engines become more efficient at high speeds, due to the Oberth effect.[1]

Rocket engines produce thrust by the expulsion of an exhaust fluid that has been accelerated to high speed through a propelling nozzle. The fluid is usually a gas created by high pressure (150-to-4,350-pound-per-square-inch (10 to 300 bar)) combustion of solid or liquid propellants, consisting of fuel and oxidiser components, within a combustion chamber. As the gases expand through the nozzle, they are accelerated to very high (supersonic) speed, and the reaction to this pushes the engine in the opposite direction. Combustion is most frequently used for practical rockets, as the laws of thermodynamics (specifically Carnot's theorem) dictate that high temperatures and pressures are desirable for the best thermal efficiency. Nuclear thermal rockets are capable of higher efficiencies, but currently have environmental problems which preclude their routine use in the Earth's atmosphere and cislunar space.

For model rocketry, an available alternative to combustion is the water rocket pressurized by compressed air, carbon dioxide, nitrogen, or any other readily available, inert gas.
$
10
Question: What is the primary principle behind rocket engine operation?
A: Combustion of fuel and oxidizer
B: Electric propulsion
C: Use of compressed air
D: Nuclear reactions
E: Combustion of hydrogen
Answer: A

Question: What distinguishes rocket engines from other jet engines?
A: They have the highest specific impulse
B: They are the heaviest
C: They are the most propellant-efficient
D: They don't use combustion
E: They carry their own oxidizer
Answer: E

Question: What is the ideal exhaust for rocket engines?
A: Oxygen
B: Nitrogen
C: Hydrogen
D: Carbon dioxide
E: Water vapor
Answer: C

Question: What effect makes rocket engines more efficient at high speeds?
A: Oberth effect
B: Bernoulli's principle
C: Venturi effect
D: Doppler effect
E: Boyle's law
Answer: A

Question: How do rocket engines produce thrust?
A: By expelling an accelerated exhaust fluid through a nozzle
B: By compressing air within the engine
C: By igniting solid propellants
D: By heating up the combustion chamber
E: By using magnetic fields to propel the spacecraft
Answer: A

Question: What is the primary advantage of combustion in rocket engines?
A: Low temperatures and pressures
B: High thermal efficiency
C: Environmental friendliness
D: Low thrust
E: Low exhaust velocity
Answer: B

Question: In model rocketry, what is an alternative to combustion for rocket propulsion?
A: Nuclear reactions
B: Electric propulsion
C: Compressed air
D: Water rocket pressurized by inert gases
E: Hydrogen combustion
Answer: D

Question: What do rocket engines use as their reaction mass?
A: Solid materials
B: Water
C: High-temperature gas
D: Magnetic fields
E: Laser beams
Answer: C

Question: What dictates the desirability of high temperatures and pressures in rocket engine combustion?
A: Boyle's law
B: Carnot's theorem
C: Newton's third law
D: Bernoulli's principle
E: Doppler effect
Answer: B

Question: What is the primary use of nuclear thermal rockets?
A: Earth's atmosphere and cislunar space propulsion
B: Compressed air propulsion
C: Water rocketry for model rocketry
D: Environmental conservation
E: Combustion of hydrogen
Answer: A
@
In astronautics, a powered flyby, or Oberth maneuver, is a maneuver in which a spacecraft falls into a gravitational well and then uses its engines to further accelerate as it is falling, thereby achieving additional speed.[1] The resulting maneuver is a more efficient way to gain kinetic energy than applying the same impulse outside of a gravitational well. The gain in efficiency is explained by the Oberth effect, wherein the use of a reaction engine at higher speeds generates a greater change in mechanical energy than its use at lower speeds. In practical terms, this means that the most energy-efficient method for a spacecraft to burn its fuel is at the lowest possible orbital periapsis, when its orbital velocity (and so, its kinetic energy) is greatest.[1] In some cases, it is even worth spending fuel on slowing the spacecraft into a gravity well to take advantage of the efficiencies of the Oberth effect.[1] The maneuver and effect are named after the person who first described them in 1927, Hermann Oberth, a Transylvanian Saxon physicist and a founder of modern rocketry.[2]

Because the vehicle remains near periapsis only for a short time, for the Oberth maneuver to be most effective the vehicle must be able to generate as much impulse as possible in the shortest possible time. As a result the Oberth maneuver is much more useful for high-thrust rocket engines like liquid-propellant rockets, and less useful for low-thrust reaction engines such as ion drives, which take a long time to gain speed. The Oberth effect also can be used to understand the behavior of multi-stage rockets: the upper stage can generate much more usable kinetic energy than the total chemical energy of the propellants it carries.[2]

In terms of the energies involved, the Oberth effect is more effective at higher speeds because at high speed the propellant has significant kinetic energy in addition to its chemical potential energy.[2]: 204  At higher speed the vehicle is able to employ the greater change (reduction) in kinetic energy of the propellant (as it is exhausted backward and hence at reduced speed and hence reduced kinetic energy) to generate a greater increase in kinetic energy of the vehicle.[2]: 204 
$
10
Question: What is the Oberth maneuver in astronautics?
A: A maneuver where a spacecraft falls into a gravitational well and uses its engines to further accelerate.
B: A maneuver for changing a spacecraft's orbit.
C: A maneuver for entering a stable orbit.
D: A maneuver for slowing down a spacecraft.
E: A maneuver for landing on a celestial body.
Answer: A

Question: Who is Hermann Oberth, and why is he associated with this maneuver?
A: He was a famous astronaut and the inventor of the Oberth maneuver.
B: He was a founder of modern rocketry and described the Oberth effect in 1927.
C: He was a physicist who explained the behavior of multi-stage rockets.
D: He was a Transylvanian Saxon engineer.
E: He was the first astronaut to perform the Oberth maneuver.
Answer: B

Question: What is the Oberth effect, and why is it important in the Oberth maneuver?
A: It is the resistance of a spacecraft to acceleration, making the maneuver more challenging.
B: It is the tendency of a spacecraft to lose energy during the maneuver, reducing its efficiency.
C: It is the phenomenon of a spacecraft gaining more kinetic energy when using engines at higher speeds, making the maneuver more efficient.
D: It is the reaction of a spacecraft's engines to gravity, allowing it to hover in orbit.
E: It is the process of slowing down a spacecraft to enter a gravitational well.
Answer: C

Question: Why is the Oberth maneuver more effective with high-thrust rocket engines?
A: High-thrust engines generate more power.
B: High-thrust engines are more fuel-efficient.
C: High-thrust engines can be used for longer durations.
D: High-thrust engines can generate more impulse in a short time.
E: High-thrust engines are less prone to overheating.
Answer: D

Question: When is the Oberth maneuver most energy-efficient?
A: At the highest possible orbital periapsis.
B: At the lowest possible orbital periapsis.
C: At the apogee of the spacecraft's orbit.
D: At the point of lunar capture.
E: At the moment of liftoff from Earth.
Answer: B

Question: What is the primary advantage of performing the Oberth maneuver?
A: It allows the spacecraft to remain near periapsis for a longer time.
B: It conserves fuel by avoiding the use of engines.
C: It generates greater kinetic energy for the spacecraft.
D: It reduces the spacecraft's orbital velocity.
E: It enables the spacecraft to enter a stable orbit.
Answer: C

Question: In terms of kinetic energy, why is the Oberth effect more effective at higher speeds?
A: At high speeds, the spacecraft loses kinetic energy rapidly.
B: At high speeds, the spacecraft's engines become less efficient.
C: At high speeds, the propellant has higher kinetic energy in addition to its chemical potential energy.
D: At high speeds, the spacecraft's engines generate less thrust.
E: At high speeds, the spacecraft experiences more drag.
Answer: C

Question: What type of rocket engines are most suitable for the Oberth maneuver?
A: Ion drives
B: Solid-propellant rockets
C: High-thrust liquid-propellant rockets
D: Low-thrust liquid-propellant rockets
E: Hypergolic engines
Answer: C

Question: Why might it be worth slowing down a spacecraft into a gravity well to use the Oberth effect?
A: Slowing down saves fuel.
B: It allows the spacecraft to hover in place.
C: The Oberth effect is more efficient at lower speeds.
D: It allows the spacecraft to enter a stable orbit.
E: Slowing down increases the spacecraft's kinetic energy.
Answer: C

Question: What determines the effectiveness of the Oberth maneuver?
A: The spacecraft's size
B: The duration of the maneuver
C: The type of propellant used
D: The spacecraft's altitude
E: The amount of thrust generated
Answer: E
@
Explanation in terms of momentum and kinetic energy
A rocket works by transferring momentum to its propellant.[3] At a fixed exhaust velocity, this will be a fixed amount of momentum per unit of propellant.[4] For a given mass of rocket (including remaining propellant), this implies a fixed change in velocity per unit of propellant. Because kinetic energy equals mv2/2, this change in velocity imparts a greater increase in kinetic energy at a high velocity than it would at a low velocity. For example, considering a 2 kg rocket:

at 1 m/s, the rocket starts with 12 = 1 J of kinetic energy. Adding 1 m/s increases the kinetic energy to 22 = 4 J, for a gain of 3 J;
at 10 m/s, the rocket starts with 102 = 100 J of kinetic energy. Adding 1 m/s increases the kinetic energy to 112 = 121 J, for a gain of 21 J.
This greater change in kinetic energy can then carry the rocket higher in the gravity well than if the propellant were burned at a lower speed.

Description in terms of work
Rocket engines produce the same force regardless of their velocity. A rocket acting on a fixed object, as in a static firing, does no useful work at all; the rocket's stored energy is entirely expended on accelerating its propellant in the form of exhaust. But when the rocket moves, its thrust acts through the distance it moves. Force multiplied by distance is the definition of mechanical energy or work. So the farther the rocket and payload move during the burn (i.e. the faster they move), the greater the kinetic energy imparted to the rocket and its payload and the less to its exhaust.

Integrating the above energy equation is often unnecessary if the burn duration is short. Short burns of chemical rocket engines close to periapsis or elsewhere are usually mathematically modeled as impulsive burns, where the force of the engine dominates any other forces that might change the vehicle's energy over the burn.

For example, as a vehicle falls toward periapsis in any orbit (closed or escape orbits) the velocity relative to the central body increases. Briefly burning the engine (an “impulsive burn”) prograde at periapsis increases the velocity by the same increment as at any other time (
Δ
�
\Delta v). However, since the vehicle's kinetic energy is related to the square of its velocity, this increase in velocity has a non-linear effect on the vehicle's kinetic energy, leaving it with higher energy than if the burn were achieved at any other time.[5]
$
10
Question: What principle explains why rockets are more effective at transferring kinetic energy at higher velocities?
A: The conservation of energy
B: The conservation of momentum
C: The law of thermodynamics
D: The law of relativity
E: The law of gravity
Answer: B

Question: How does a rocket's change in velocity affect its kinetic energy?
A: It decreases its kinetic energy.
B: It has no effect on its kinetic energy.
C: It increases its kinetic energy.
D: It keeps its kinetic energy constant.
E: It reduces its propellant efficiency.
Answer: C

Question: What is the relationship between force, distance, and work in the context of rocket engines?
A: Rocket engines produce more force at lower distances.
B: Rocket engines produce less force at higher distances.
C: Rocket engines do not perform any work.
D: Rocket engines produce the same force regardless of distance.
E: Rocket engines perform work only when stationary.
Answer: D

Question: Why is it important for rockets to move during their burn in terms of work?
A: Moving rockets perform less work.
B: Moving rockets perform the same amount of work as stationary ones.
C: Moving rockets perform more work because they cover a greater distance.
D: Moving rockets perform work only on their exhaust.
E: Moving rockets perform work only in the absence of gravity.
Answer: C

Question: When are short burns of rocket engines typically modeled as impulsive burns?
A: When the burn duration is long
B: When the vehicle is far from periapsis
C: When the rocket is stationary
D: When the force of the engine is weak
E: When the burn duration is short
Answer: E

Question: What effect does a brief impulsive burn have on a falling vehicle near periapsis?
A: It decreases the vehicle's velocity.
B: It increases the vehicle's kinetic energy linearly.
C: It has no effect on the vehicle's energy.
D: It increases the vehicle's kinetic energy nonlinearly.
E: It reduces the vehicle's propellant efficiency.
Answer: D

Question: In the context of rockets, what is the definition of mechanical energy or work?
A: The force applied by the rocket
B: The distance the rocket travels
C: The force multiplied by the distance the rocket moves
D: The propellant efficiency of the engine
E: The velocity of the rocket
Answer: C

Question: Why does a rocket's thrust perform useful work during its movement?
A: Because it applies force to the exhaust
B: Because it moves at a constant velocity
C: Because it conserves energy
D: Because it accelerates the propellant
E: Because it remains stationary during the burn
Answer: A

Question: What does the Oberth effect explain in terms of rocket propulsion?
A: How rockets conserve momentum
B: Why rockets burn propellant at high speeds
C: How rockets gain energy by remaining stationary
D: Why rockets use nuclear propulsion
E: How rockets change their orbits
Answer: B

Question: What is the primary advantage of performing impulsive burns near periapsis?
A: It allows rockets to change their orbits.
B: It conserves rocket fuel.
C: It decreases the rocket's velocity.
D: It maximizes the rocket's kinetic energy.
E: It reduces the rocket's altitude.
Answer: D
@
Nozzle
The hot gas produced in the combustion chamber is permitted to escape through an opening (the "throat"), and then through a diverging expansion section. When sufficient pressure is provided to the nozzle (about 2.5–3 times ambient pressure), the nozzle chokes and a supersonic jet is formed, dramatically accelerating the gas, converting most of the thermal energy into kinetic energy. Exhaust speeds vary, depending on the expansion ratio the nozzle is designed for, but exhaust speeds as high as ten times the speed of sound in air at sea level are not uncommon. About half of the rocket engine's thrust comes from the unbalanced pressures inside the combustion chamber, and the rest comes from the pressures acting against the inside of the nozzle (see diagram). As the gas expands (adiabatically) the pressure against the nozzle's walls forces the rocket engine in one direction while accelerating the gas in the other.

The most commonly used nozzle is the de Laval nozzle, a fixed geometry nozzle with a high expansion-ratio. The large bell- or cone-shaped nozzle extension beyond the throat gives the rocket engine its characteristic shape.

The exit static pressure of the exhaust jet depends on the chamber pressure and the ratio of exit to throat area of the nozzle. As exit pressure varies from the ambient (atmospheric) pressure, a choked nozzle is said to be

under-expanded (exit pressure greater than ambient),
perfectly expanded (exit pressure equals ambient),
over-expanded (exit pressure less than ambient; shock diamonds form outside the nozzle), or
grossly over-expanded (a shock wave forms inside the nozzle extension).
In practice, perfect expansion is only achievable with a variable-exit area nozzle (since ambient pressure decreases as altitude increases), and is not possible above a certain altitude as ambient pressure approaches zero. If the nozzle is not perfectly expanded, then loss of efficiency occurs. Grossly over-expanded nozzles lose less efficiency, but can cause mechanical problems with the nozzle. Fixed-area nozzles become progressively more under-expanded as they gain altitude. Almost all de Laval nozzles will be momentarily grossly over-expanded during startup in an atmosphere.[5]

Nozzle efficiency is affected by operation in the atmosphere because atmospheric pressure changes with altitude; but due to the supersonic speeds of the gas exiting from a rocket engine, the pressure of the jet may be either below or above ambient, and equilibrium between the two is not reached at all altitudes (see diagram).
$
10
Question: How does a rocket nozzle convert thermal energy into kinetic energy?
A: By expanding the hot gas through a diverging section
B: By cooling the gas rapidly
C: By compressing the gas within the nozzle
D: By heating the nozzle walls
E: By restricting the gas flow
Answer: A

Question: What happens when sufficient pressure is provided to the rocket nozzle?
A: The nozzle becomes choked.
B: The nozzle contracts.
C: The nozzle overheats.
D: The nozzle expands.
E: The nozzle ignites.
Answer: A

Question: What is the primary function of the nozzle in a rocket engine?
A: To cool the combustion chamber
B: To produce thermal energy
C: To balance the pressures inside the combustion chamber
D: To convert thermal energy into kinetic energy
E: To create shock diamonds
Answer: D

Question: Which type of nozzle is commonly used in rocket engines and has a fixed geometry with a high expansion ratio?
A: Converging-diverging nozzle
B: Variable-exit nozzle
C: Bell-shaped nozzle
D: de Laval nozzle
E: Under-expanded nozzle
Answer: D

Question: What determines the exit static pressure of the exhaust jet in a rocket nozzle?
A: The shape of the combustion chamber
B: The altitude of the rocket
C: The size of the rocket's payload
D: The chamber pressure and nozzle area ratio
E: The velocity of the rocket
Answer: D

Question: When is a rocket nozzle considered perfectly expanded?
A: When the exit pressure is less than ambient
B: When the exit pressure is greater than ambient
C: When the exit pressure equals ambient
D: When the exit pressure reaches zero
E: When the exit pressure is variable
Answer: C

Question: What type of nozzle is required for perfect expansion at all altitudes?
A: Fixed-area nozzle
B: Variable-exit area nozzle
C: Converging-diverging nozzle
D: Under-expanded nozzle
E: Bell-shaped nozzle
Answer: B

Question: What can happen if a rocket nozzle is grossly over-expanded?
A: Loss of efficiency
B: Perfect expansion
C: Increased thrust
D: Reduced temperatures
E: Improved combustion
Answer: A

Question: How do fixed-area nozzles behave as they gain altitude?
A: They become perfectly expanded.
B: They remain over-expanded.
C: They become more under-expanded.
D: They increase in size.
E: They develop shock diamonds.
Answer: C

Question: Why do almost all de Laval nozzles momentarily become grossly over-expanded during startup in an atmosphere?
A: To maximize efficiency
B: To minimize noise
C: To balance pressures inside the nozzle
D: To reduce combustion temperature
E: To prevent nozzle overheating
Answer: A
@
For a rocket engine to be propellant efficient, it is important that the maximum pressures possible be created on the walls of the chamber and nozzle by a specific amount of propellant; as this is the source of the thrust. This can be achieved by all of:

heating the propellant to as high a temperature as possible (using a high energy fuel, containing hydrogen and carbon and sometimes metals such as aluminium, or even using nuclear energy)
using a low specific density gas (as hydrogen rich as possible)
using propellants which are, or decompose to, simple molecules with few degrees of freedom to maximise translational velocity
Since all of these things minimise the mass of the propellant used, and since pressure is proportional to the mass of propellant present to be accelerated as it pushes on the engine, and since from Newton's third law the pressure that acts on the engine also reciprocally acts on the propellant, it turns out that for any given engine, the speed that the propellant leaves the chamber is unaffected by the chamber pressure (although the thrust is proportional). However, speed is significantly affected by all three of the above factors and the exhaust speed is an excellent measure of the engine propellant efficiency. This is termed exhaust velocity, and after allowance is made for factors that can reduce it, the effective exhaust velocity is one of the most important parameters of a rocket engine (although weight, cost, ease of manufacture etc. are usually also very important).

For aerodynamic reasons the flow goes sonic ("chokes") at the narrowest part of the nozzle, the 'throat'. Since the speed of sound in gases increases with the square root of temperature, the use of hot exhaust gas greatly improves performance. By comparison, at room temperature the speed of sound in air is about 340 m/s while the speed of sound in the hot gas of a rocket engine can be over 1700 m/s; much of this performance is due to the higher temperature, but additionally rocket propellants are chosen to be of low molecular mass, and this also gives a higher velocity compared to air.

Expansion in the rocket nozzle then further multiplies the speed, typically between 1.5 and 2 times, giving a highly collimated hypersonic exhaust jet. The speed increase of a rocket nozzle is mostly determined by its area expansion ratio—the ratio of the area of the exit to the area of the throat, but detailed properties of the gas are also important. Larger ratio nozzles are more massive but are able to extract more heat from the combustion gases, increasing the exhaust velocity.
$
10
Question: What factors are important for achieving propellant efficiency in a rocket engine?
A: High chamber pressure, low specific density gas, and complex molecules
B: Low chamber pressure, high specific density gas, and complex molecules
C: High chamber pressure, low specific density gas, and simple molecules
D: Low chamber pressure, high specific density gas, and simple molecules
E: High chamber pressure, high specific density gas, and simple molecules
Answer: C

Question: What is the term used to describe the measure of a rocket engine's propellant efficiency and is determined by exhaust speed?
A: Thrust-to-weight ratio
B: Specific impulse
C: Mach number
D: Chamber pressure
E: Drag coefficient
Answer: B

Question: Why is it important for a rocket engine to heat the propellant to as high a temperature as possible?
A: To increase chamber pressure
B: To reduce exhaust velocity
C: To minimize thrust
D: To improve propellant efficiency
E: To increase the weight of the propellant
Answer: D

Question: What is the term for the narrowest part of the rocket nozzle where the flow goes sonic?
A: Throat
B: Exhaust
C: Chamber
D: Expansion
E: Convergence
Answer: A

Question: How does the speed of sound in gases relate to temperature?
A: It decreases with increasing temperature.
B: It remains constant regardless of temperature.
C: It increases with increasing temperature.
D: It is not affected by temperature.
E: It is inversely proportional to temperature.
Answer: C

Question: What is the effect of using hot exhaust gas in a rocket engine?
A: It reduces performance.
B: It has no effect on performance.
C: It greatly improves performance.
D: It decreases exhaust velocity.
E: It increases chamber pressure.
Answer: C

Question: What is the area expansion ratio of a rocket nozzle?
A: The ratio of the nozzle's weight to its thrust
B: The ratio of the nozzle's length to its diameter
C: The ratio of the nozzle's exit area to its throat area
D: The ratio of the nozzle's exhaust temperature to its chamber temperature
E: The ratio of the nozzle's propellant mass to its chamber pressure
Answer: C

Question: What effect does a larger area expansion ratio have on a rocket nozzle's performance?
A: It reduces performance.
B: It has no effect on performance.
C: It increases chamber pressure.
D: It decreases exhaust velocity.
E: It increases exhaust velocity.
Answer: E

Question: How does the speed increase of a rocket nozzle primarily depend on?
A: Chamber pressure
B: Thrust
C: Weight
D: Area expansion ratio
E: Propellant mass
Answer: D

Question: What is the result of expansion in a rocket nozzle?
A: A decrease in exhaust velocity
B: A decrease in thrust
C: A highly collimated hypersonic exhaust jet
D: An increase in chamber pressure
E: An increase in drag coefficient
Answer: C
@
Rocket propellants require a high energy per unit mass (specific energy), which must be balanced against the tendency of highly energetic propellants to spontaneously explode. Assuming that the chemical potential energy of the propellants can be safely stored, the combustion process results in a great deal of heat being released. A significant fraction of this heat is transferred to kinetic energy in the engine nozzle, propelling the rocket forward in combination with the mass of combustion products released.

Ideally all the reaction energy appears as kinetic energy of the exhaust gases, as exhaust velocity is the single most important performance parameter of an engine. However, real exhaust species are molecules, which typically have translation, vibrational, and rotational modes with which to dissipate energy. Of these, only translation can do useful work to the vehicle, and while energy does transfer between modes this process occurs on a timescale far in excess of the time required for the exhaust to leave the nozzle.

The more chemical bonds an exhaust molecule has, the more rotational and vibrational modes it will have. Consequently, it is generally desirable for the exhaust species to be as simple as possible, with a diatomic molecule composed of light, abundant atoms such as H2 being ideal in practical terms. However, in the case of a chemical rocket, hydrogen is a reactant and reducing agent, not a product. An oxidizing agent, most typically oxygen or an oxygen-rich species, must be introduced into the combustion process, adding mass and chemical bonds to the exhaust species.

An additional advantage of light molecules is that they may be accelerated to high velocity at temperatures that can be contained by currently available materials - the high gas temperatures in rocket engines pose serious problems for the engineering of survivable motors.

Liquid hydrogen (LH2) and oxygen (LOX, or LO2), are the most effective propellants in terms of exhaust velocity that have been widely used to date, though a few exotic combinations involving boron or liquid ozone are potentially somewhat better in theory if various practical problems could be solved.[39]

When computing the specific reaction energy of a given propellant combination, the entire mass of the propellants (both fuel and oxidiser) must be included. The exception is in the case of air-breathing engines, which use atmospheric oxygen and consequently have to carry less mass for a given energy output. Fuels for car or turbojet engines have a much better effective energy output per unit mass of propellant that must be carried, but are similar per unit mass of fuel.

Computer programs that predict the performance of propellants in rocket engines are available.[40][41][42]
$
10

Question: Why is it important for rocket propellants to have a high energy per unit mass (specific energy)?
A: To increase the mass of combustion products
B: To reduce the kinetic energy in the engine nozzle
C: To minimize the heat released during combustion
D: To balance the risk of spontaneous explosion
E: To decrease the exhaust velocity
Answer: D

Question: What is the most important performance parameter of a rocket engine?
A: Mass of combustion products
B: Heat released during combustion
C: Specific energy of propellants
D: Mass of chemical bonds in exhaust molecules
E: Exhaust velocity
Answer: E

Question: Which mode of exhaust molecules dissipates energy that cannot do useful work for the rocket?
A: Vibrational
B: Translational
C: Rotational
D: Combustion
E: Chemical
Answer: A

Question: Why is it desirable for exhaust species to be as simple as possible in a rocket engine?
A: To increase rotational modes
B: To decrease the temperature of the exhaust gases
C: To reduce the combustion process
D: To minimize the number of chemical bonds
E: To improve survivability of rocket motors
Answer: D

Question: Which diatomic molecule composed of light, abundant atoms is ideal for rocket engine exhaust in practical terms?
A: CO2
B: O2
C: H2O
D: N2
E: H2
Answer: E

Question: Why is liquid hydrogen (LH2) considered an effective rocket propellant?
A: It is an effective reactant and reducing agent.
B: It is a product of combustion.
C: It is easy to store and transport.
D: It has a high specific heat capacity.
E: It has a high exhaust velocity.
Answer: E

Question: What is the advantage of using light molecules as rocket engine propellants?
A: They are less effective reactants.
B: They require higher gas temperatures.
C: They have more rotational and vibrational modes.
D: They can be accelerated to high velocity at manageable temperatures.
E: They have lower specific energy.
Answer: D

Question: Which two propellants are mentioned as the most effective in terms of exhaust velocity in rocket engines?
A: CO2 and H2O
B: N2 and O2
C: NH3 and CH4
D: LH2 and LOX
E: C2H4 and O3
Answer: D

Question: What is the exception when computing the specific reaction energy of propellants for rocket engines?
A: Atmospheric oxygen is excluded.
B: All mass of the propellants must be included.
C: Chemical bonds in exhaust molecules are not considered.
D: Mass of the fuel is excluded.
E: Mass of the oxidizer is not considered.
Answer: A

Question: What do computer programs predict in the performance of propellants in rocket engines?
A: The heat released during combustion
B: The mass of combustion products
C: The survivability of rocket motors
D: The specific energy of propellants
E: The exhaust velocity
Answer: E
@
Specific energy or massic energy is energy per unit mass. It is also sometimes called gravimetric energy density, which is not to be confused with energy density, which is defined as energy per unit volume. It is used to quantify, for example, stored heat and other thermodynamic properties of substances such as specific internal energy, specific enthalpy, specific Gibbs free energy, and specific Helmholtz free energy. It may also be used for the kinetic energy or potential energy of a body. Specific energy is an intensive property, whereas energy and mass are extensive properties.

The SI unit for specific energy is the joule per kilogram (J/kg). Other units still in use in some contexts are the kilocalorie per gram (Cal/g or kcal/g), mostly in food-related topics, watt hours per kilogram in the field of batteries, and the Imperial unit BTU per pound (Btu/lb), in some engineering and applied technical fields.[1]

The concept of specific energy is related to but distinct from the notion of molar energy in chemistry, that is energy per mole of a substance, which uses units such as joules per mole, or the older but still widely used calories per mole.[2]
$
10
Question: What is specific energy also sometimes referred to as?
A: Gravimetric energy density
B: Energy per unit volume
C: Kinetic energy
D: Potential energy
E: Enthalpy
Answer: A

Question: Which property of substances does specific energy quantify?
A: Energy density
B: Internal energy
C: Volume
D: Pressure
E: Mass
Answer: B

Question: What is the SI unit for specific energy?
A: Cal/g
B: Btu/lb
C: Watt hours per kilogram
D: Joule per kilogram
E: Joules per mole
Answer: D

Question: What are joules per mole used to measure in chemistry?
A: Gravimetric energy density
B: Specific energy
C: Internal energy
D: Mass
E: Volume
Answer: C

Question: In which field are kilocalories per gram (Cal/g) often used?
A: Physics
B: Chemistry
C: Food-related topics
D: Battery technology
E: Engineering
Answer: C

Question: What is the relationship between specific energy and energy density?
A: They are equivalent terms.
B: Energy density is an extensive property.
C: Energy density is used to quantify kinetic energy.
D: They have no relationship; they are distinct concepts.
E: Specific energy is an extensive property.
Answer: D

Question: Which unit is commonly used for specific energy in the field of batteries?
A: Cal/g
B: Btu/lb
C: Watt hours per kilogram
D: Joule per kilogram
E: Joules per mole
Answer: C

Question: What is the Imperial unit used for specific energy in some engineering and applied technical fields?
A: Cal/g
B: Btu/lb
C: Watt hours per kilogram
D: Joule per kilogram
E: Joules per mole
Answer: B

Question: What is molar energy in chemistry?
A: Energy per unit mass
B: Energy per unit volume
C: Energy per mole of a substance
D: Energy per kilogram
E: Energy per joule
Answer: C

Question: What does specific energy quantify for a body?
A: Energy per unit mass
B: Energy per unit volume
C: Mass
D: Pressure
E: Temperature
Answer: A
@
Food energy is chemical energy that animals (including humans) derive from their food to sustain their metabolism, including their muscular activity.[1]

Most animals derive most of their energy from aerobic respiration, namely combining the carbohydrates, fats, and proteins with oxygen from air or dissolved in water.[2] Other smaller components of the diet, such as organic acids, polyols, and ethanol (drinking alcohol) may contribute to the energy input. Some diet components that provide little or no food energy, such as water, minerals, vitamins, cholesterol, and fiber, may still be necessary to health and survival for other reasons. Some organisms have instead anaerobic respiration, which extracts energy from food by reactions that do not require oxygen.

The energy contents of a given mass of food is usually expressed in the metric (SI) unit of energy, the joule (J), and its multiple the kilojoule (kJ); or in the traditional unit of heat energy, the calorie (cal). In nutritional contexts, the latter is often (especially in US) the "large" variant of the unit, also written "Calorie" (with symbol Cal, both with capital "C") or "kilocalorie" (kcal), and equivalent to 4184 J or 4.184 kJ.[3] Thus, for example, fats and ethanol have the greatest amount of food energy per unit mass, 37 and 29 kJ/g (9 and 7 kcal/g), respectively. Proteins and most carbohydrates have about 17 kJ/g (4 kcal/g), though there are differences between different kinds. For example, the values for glucose, sucrose, and starch are 15.57, 16.48 and 17.48 kilojoules per gram (3.72, 3.94 and 4.18 kcal/g) respectively. The differing energy density of foods (fat, alcohols, carbohydrates and proteins) lies mainly in their varying proportions of carbon, hydrogen, and oxygen atoms. Carbohydrates that are not easily absorbed, such as fibre, or lactose in lactose-intolerant individuals, contribute less food energy. Polyols (including sugar alcohols) and organic acids contribute 10 kJ/g (2.4 kcal/g) and 13 kJ/g (3.1 kcal/g) respectively.[4]

The energy contents of a complex dish or meal can be approximated by adding the energy contents of its components.
$
10
Question: What is the primary source of energy for most animals, including humans?
A: Organic acids
B: Anaerobic respiration
C: Combining carbohydrates, fats, and proteins with oxygen
D: Fiber
E: Vitamins
Answer: C

Question: Which unit is commonly used to express the energy contents of food in nutritional contexts?
A: Calorie
B: Calorimeter
C: Joule
D: Kilocalorie
E: Watt
Answer: D

Question: What is the energy content of fats per unit mass, approximately?
A: 29 kJ/g
B: 17 kJ/g
C: 15.57 kJ/g
D: 10 kJ/g
E: 3.72 kJ/g
Answer: A

Question: Which component of the diet does not provide food energy but may still be necessary for health and survival?
A: Carbohydrates
B: Vitamins
C: Fiber
D: Proteins
E: Water
Answer: C

Question: What is the energy content of glucose per gram, approximately?
A: 17.48 kilojoules
B: 3.94 kilocalories
C: 4.18 kilojoules
D: 16.48 kilocalories
E: 15.57 kilojoules
Answer: E

Question: What is the traditional unit of heat energy used to express food energy?
A: Joule
B: Kilocalorie
C: Calorimeter
D: Watt
E: Calorie
Answer: E

Question: What is the energy content of ethanol per unit mass, approximately?
A: 15.57 kJ/g
B: 3.72 kJ/g
C: 17 kJ/g
D: 4.18 kJ/g
E: 29 kJ/g
Answer: B

Question: Which component of food contributes the least amount of energy per unit mass?
A: Fats
B: Proteins
C: Carbohydrates
D: Organic acids
E: Fiber
Answer: E

Question: How can the energy content of a complex dish or meal be estimated?
A: It cannot be estimated accurately.
B: By subtracting the energy contents of its components.
C: By adding the energy contents of its components.
D: By measuring its volume.
E: By counting the number of ingredients.
Answer: C

Question: What is the SI unit of energy used to express the energy content of food?
A: Calorie
B: Joule
C: Kilocalorie
D: Watt
E: Kilogram
Answer: B
@
The typical human diet consists chiefly of carbohydrates, fats, proteins, water, ethanol, and indigestible components such as bones, seeds, and fibre (mostly cellulose). Carbohydrates, fats, and proteins typically comprise ninety percent of the dry weight of food.[10] Ruminants can extract food energy from the respiration of cellulose because of bacteria in their rumens that decompose it into digestible carbohydrates.

Other minor components of the human diet that contribute to its energy content are organic acids such as citric and tartaric, and polyols such as glycerol, xylitol, inositol, and sorbitol.

Some nutrients have regulatory roles affected by cell signaling, in addition to providing energy for the body.[11] For example, leucine plays an important role in the regulation of protein metabolism and suppresses an individual's appetite.[12] Small amounts of essential fatty acids, constituents of some fats that cannot be synthesized by the human body, are used (and necessary) for other biochemical processes.

The approximate food energy contents of various human diet components, to be used in package labeling according to the EU regulations[13] and UK regulations,[14] are:

Food component	Energy density
kJ/g	kcal/g
Fat	37	9
Ethanol	29	7
Proteins	17	4
Carbohydrates	17	4
Organic acids	13	3
Polyols (sugar alcohols, sweeteners) (1)	10	2.4
Fiber (2)	8	2
(1) Some polyols, like erythritol, are not digested and should be excluded from the count.

(2) This entry exists in the EU regulations of 2008,[13] but not in the UK regulations, according to which fibre shall not be counted.[14]

More detailed tables for specific foods have been published by many organizations, such as the United Nations Food and Agriculture Organization also has published a similar table.[3]

Other components of the human diet are either noncaloric, or are usually consumed in such small amounts that they can be neglected.
$
10
Question: What are the three main components of the typical human diet that make up ninety percent of the dry weight of food?
A: Carbohydrates, water, and ethanol
B: Fats, proteins, and fibers
C: Carbohydrates, fats, and proteins
D: Organic acids, polyols, and proteins
E: Ethanol, fibers, and polyols
Answer: C

Question: What allows ruminants to extract food energy from cellulose?
A: Bacteria in their rumens
B: Specialized enzymes in their saliva
C: High acidity in their stomachs
D: The structure of their teeth
E: Consuming cellulose-rich plants
Answer: A

Question: Which organic acid contributes to the energy content of the human diet?
A: Acetic acid
B: Citric acid
C: Lactic acid
D: Formic acid
E: Malic acid
Answer: B

Question: What is the regulatory role of leucine in the human body?
A: It regulates blood sugar levels.
B: It controls body temperature.
C: It plays a role in protein metabolism regulation.
D: It influences bone density.
E: It regulates heart rate.
Answer: C

Question: What are essential fatty acids used for in the human body?
A: They provide energy.
B: They are involved in regulating body temperature.
C: They are used for structural purposes in cell membranes.
D: They are necessary for blood clotting.
E: They are essential for muscle contraction.
Answer: C

Question: Which component of the human diet is often excluded from energy content calculations because it is not digested?
A: Carbohydrates
B: Proteins
C: Organic acids
D: Polyols (sugar alcohols)
E: Fiber
Answer: D

Question: According to EU regulations, which component of the human diet should not be counted in energy content calculations?
A: Fiber
B: Organic acids
C: Carbohydrates
D: Proteins
E: Fats
Answer: A

Question: What is the energy density of carbohydrates in the human diet, in kilojoules per gram (kJ/g)?
A: 17 kJ/g
B: 29 kJ/g
C: 13 kJ/g
D: 8 kJ/g
E: 10 kJ/g
Answer: A

Question: According to the subject text, which component of the human diet is usually consumed in such small amounts that it can be neglected in energy content calculations?
A: Carbohydrates
B: Fats
C: Organic acids
D: Water
E: Polyols (sugar alcohols)
Answer: D

Question: Which organization has published detailed tables for specific foods' energy content?
A: United Nations Food and Agriculture Organization
B: World Health Organization
C: European Union
D: World Food Programme
E: Food and Drug Administration
Answer: A
@
The heating value (or energy value or calorific value) of a substance, usually a fuel or food (see food energy), is the amount of heat released during the combustion of a specified amount of it.

The calorific value is the total energy released as heat when a substance undergoes complete combustion with oxygen under standard conditions. The chemical reaction is typically a hydrocarbon or other organic molecule reacting with oxygen to form carbon dioxide and water and release heat. It may be expressed with the quantities:

energy/mole of fuel
energy/mass of fuel
energy/volume of the fuel
There are two kinds of enthalpy of combustion, called high(er) and low(er) heat(ing) value, depending on how much the products are allowed to cool and whether compounds like H
2O are allowed to condense. The high heat values are conventionally measured with a bomb calorimeter. Low heat values are calculated from high heat value test data. They may also be calculated as the difference between the heat of formation ΔH⦵
f of the products and reactants (though this approach is somewhat artificial since most heats of formation are typically calculated from measured heats of combustion).[1]

By convention, the (higher) heat of combustion is defined to be the heat released for the complete combustion of a compound in its standard state to form stable products in their standard states: hydrogen is converted to water (in its liquid state), carbon is converted to carbon dioxide gas, and nitrogen is converted to nitrogen gas. That is, the heat of combustion, ΔH°comb, is the heat of reaction of the following process:

C
cH
hN
nO
o (std.) + (c + h⁄4 - o⁄2) O
2 (g) → cCO
2 (g) + h⁄2H
2O (l) + n⁄2N
2 (g)
Chlorine and sulfur are not quite standardized; they are usually assumed to convert to hydrogen chloride gas and SO
2 or SO
3 gas, respectively, or to dilute aqueous hydrochloric and sulfuric acids, respectively, when the combustion is conducted in a bomb calorimeter containing some quantity of water.[2][3]
$
10
Question: What is the heating value of a substance?
A: The temperature at which it boils
B: The amount of heat released during its combustion
C: The energy required to break its chemical bonds
D: The energy needed to convert it into a gas
E: The rate at which it conducts heat
Answer: B

Question: What are the two kinds of enthalpy of combustion?
A: High and low enthalpy
B: High and low heat values
C: Exothermic and endothermic enthalpy
D: Standard and non-standard enthalpy
E: Atomic and molecular enthalpy
Answer: B

Question: How are high heat values conventionally measured?
A: Using a thermometer
B: With a spectrophotometer
C: Using a bomb calorimeter
D: Through titration
E: By conducting a flame test
Answer: C

Question: What is the difference between high heat values and low heat values?
A: High heat values are higher than low heat values.
B: High heat values include the energy released from water condensation, while low heat values do not.
C: High heat values are calculated, while low heat values are measured directly.
D: High heat values involve bomb calorimetry, while low heat values use a different method.
E: There is no practical difference between high and low heat values.
Answer: B

Question: What is the (higher) heat of combustion defined as?
A: The heat released when a compound is partially combusted
B: The heat released when a compound is combusted in its standard state to form stable products in their standard states
C: The heat required to initiate combustion
D: The heat released when a compound is completely converted into gas
E: The heat released when a compound is combusted in a non-standard state
Answer: B

Question: Which substance is hydrogen typically converted to in the (higher) heat of combustion definition?
A: Water in its liquid state
B: Water in its gaseous state
C: Oxygen gas
D: Nitrogen gas
E: Hydrogen chloride gas
Answer: A

Question: How are chlorine and sulfur typically assumed to convert in combustion experiments?
A: To hydrogen chloride gas and sulfur dioxide gas
B: To oxygen gas and nitrogen gas
C: To dilute aqueous hydrochloric and sulfuric acids
D: To water vapor and nitrogen gas
E: To carbon dioxide and oxygen gas
Answer: A

Question: What is the heat of formation typically calculated from?
A: Measured heats of combustion
B: Thermodynamic tables
C: Bomb calorimetry
D: Enthalpy values
E: The ideal gas law
Answer: A

Question: What is the unit of measurement for the energy/mole of fuel in calorific values?
A: Joules per gram
B: Watts per kilogram
C: Joules per mole
D: Watts per liter
E: Calories per pound
Answer: C

Question: What is the calorific value used to quantify?
A: The energy required for chemical reactions
B: The energy released during combustion
C: The energy stored in chemical bonds
D: The energy needed for phase changes
E: The energy density of a substance
Answer: B
@
In organic chemistry, a hydrocarbon is an organic compound consisting entirely of hydrogen and carbon.[1]: 620  Hydrocarbons are examples of group 14 hydrides. Hydrocarbons are generally colourless and hydrophobic; their odor is usually faint, and may be similar to that of gasoline or lighter fluid. They occur in a diverse range of molecular structures and phases: they can be gases (such as methane and propane), liquids (such as hexane and benzene), low melting solids (such as paraffin wax and naphthalene) or polymers (such as polyethylene and polystyrene).

In the fossil fuel industries, hydrocarbon refers to naturally occurring petroleum, natural gas and coal, or their hydrocarbon derivatives and purified forms. Combustion of hydrocarbons is the main source of the world's energy. Petroleum is the dominant raw-material source for organic commodity chemicals such as solvents and polymers. Most anthropogenic (human-generated) emissions of greenhouse gases are either carbon dioxide released by the burning of fossil fuels, or methane released from the handling of natural gas or from agriculture.

Types
As defined by the International Union of Pure and Applied Chemistry's nomenclature of organic chemistry, hydrocarbons are classified as follows:

Saturated hydrocarbons, which are the simplest of the hydrocarbon types. They are composed entirely of single bonds and are saturated with hydrogen. The formula for acyclic saturated hydrocarbons (i.e., alkanes) is CnH2n+2.[1]: 623  The most general form of saturated hydrocarbons, (whether linear or branched species, and whether with without one or more rings) is CnH2n+2(1-r), where r is the number of rings. Those with exactly one ring are the cycloalkanes. Saturated hydrocarbons are the basis of petroleum fuels and may be either linear or branched species. One or more of the hydrogen atoms can be replaced with other atoms, for example chlorine or another halogen: this is called a substitution reaction. An example is the conversion of methane to chloroform using a chlorination reaction. Note that halogenating a hydrocarbon produces something that is not a hydrocarbon. It is a very common and useful process. Hydrocarbons with the same molecular formula but different structural formulae are called structural isomers.[1]: 625  As given in the example of 3-methylhexane and its higher homologues, branched hydrocarbons can be chiral.[1]: 627  Chiral saturated hydrocarbons constitute the side chains of biomolecules such as chlorophyll and tocopherol.[2]
Unsaturated hydrocarbons, which have one or more double or triple bonds between carbon atoms. Those with one or more double bonds are called alkenes. Those with one double bond have the formula CnH2n (assuming non-cyclic structures).[1]: 628  Those containing triple bonds are called alkyne. Those with one triple bond have the formula CnH2n−2.[1]: 631 
Aromatic hydrocarbons, also known as arenes, which are hydrocarbons that have at least one aromatic ring. 10% of total nonmethane organic carbon emission are aromatic hydrocarbons from the exhaust of gasoline-powered vehicles.[3]
The term 'aliphatic' refers to non-aromatic hydrocarbons. Saturated aliphatic hydrocarbons are sometimes referred to as 'paraffins'. Aliphatic hydrocarbons containing a double bond between carbon atoms are sometimes referred to as 'olefins'.
$
10
Question: What are hydrocarbons primarily composed of?
A: Hydrogen and oxygen
B: Hydrogen and nitrogen
C: Hydrogen and carbon
D: Oxygen and carbon
E: Carbon and nitrogen
Answer: C

Question: Which hydrocarbons are generally colorless and hydrophobic?
A: Saturated hydrocarbons
B: Aromatic hydrocarbons
C: Unsaturated hydrocarbons
D: Aliphatic hydrocarbons
E: Halogenated hydrocarbons
Answer: A

Question: Which type of hydrocarbon is the main source of the world's energy through combustion?
A: Aromatic hydrocarbons
B: Unsaturated hydrocarbons
C: Saturated hydrocarbons
D: Aliphatic hydrocarbons
E: Fossil fuel hydrocarbons
Answer: E

Question: How are saturated hydrocarbons defined in terms of their chemical bonds?
A: They contain only single bonds and are saturated with hydrogen.
B: They contain one or more double or triple bonds.
C: They have at least one aromatic ring.
D: They contain no carbon-carbon bonds.
E: They contain chlorine or another halogen.
Answer: A

Question: What is the general formula for acyclic saturated hydrocarbons (alkanes)?
A: CnH2n
B: CnH2n+2
C: CnH2n-2
D: CnH2n+2(1-r)
E: CnH2n-1
Answer: B

Question: What is the term for hydrocarbons with the same molecular formula but different structural formulae?
A: Isomers
B: Homologues
C: Aromatics
D: Substituents
E: Polymers
Answer: A

Question: Which type of hydrocarbon has one or more double or triple bonds between carbon atoms?
A: Aromatic hydrocarbons
B: Saturated hydrocarbons
C: Aliphatic hydrocarbons
D: Unsaturated hydrocarbons
E: Halogenated hydrocarbons
Answer: D

Question: What is the formula for hydrocarbons with one triple bond?
A: CnH2n
B: CnH2n-2
C: CnH2n+2
D: CnH2n−2
E: CnH2n+1
Answer: B

Question: What are hydrocarbons with at least one aromatic ring known as?
A: Aliphatic hydrocarbons
B: Olefins
C: Paraffins
D: Aromatic hydrocarbons
E: Cycloalkanes
Answer: D

Question: What is the term for non-aromatic hydrocarbons?
A: Olefins
B: Arene hydrocarbons
C: Paraffins
D: Aliphatic hydrocarbons
E: Halogenated hydrocarbons
Answer: D
@
The predominant use of hydrocarbons is as a combustible fuel source. Methane is the predominant component of natural gas. The C6 through C10 alkanes, alkenes and isomeric cycloalkanes are the top components of gasoline, naphtha, jet fuel and specialized industrial solvent mixtures. With the progressive addition of carbon units, the simple non-ring structured hydrocarbons have higher viscosities, lubricating indices, boiling points, solidification temperatures, and deeper color. At the opposite extreme from methane lie the heavy tars that remain as the lowest fraction in a crude oil refining retort. They are collected and widely utilized as roofing compounds, pavement composition (bitumen), wood preservatives (the creosote series) and as extremely high viscosity shear-resisting liquids.

Some large-scale non-fuel applications of hydrocarbons begins with ethane and propane, which are obtained from petroleum and natural gas. These two gases are converted either to syngas or to ethylene and propylene. Global consumption of benzene in 2021 is estimated at more than 58 million metric tons, which will increase to 60 million tons in 2022.[4]

Hydrocarbons are also prevalent in nature. Some eusocial arthropods, such as the Brazilian stingless bee, Schwarziana quadripunctata, use unique cuticular hydrocarbon "scents" in order to determine kin from non-kin. This hydrocarbon composition varies between age, sex, nest location, and hierarchal position.[5]

There is also potential to harvest hydrocarbons from plants like Euphorbia lathyris and E. tirucalli as an alternative and renewable energy source for vehicles that use diesel.[6] Furthermore, endophytic bacteria from plants that naturally produce hydrocarbons have been used in hydrocarbon degradation in attempts to deplete hydrocarbon concentration in polluted soils.[7]
$
10
Question: What is the predominant component of natural gas?
A: Ethylene
B: Methane
C: Benzene
D: Propane
E: Ethane
Answer: B

Question: What are the top components of gasoline, naphtha, jet fuel, and specialized industrial solvent mixtures?
A: Methane and ethane
B: Ethylene and propylene
C: C6 through C10 alkanes, alkenes, and isomeric cycloalkanes
D: Benzene and toluene
E: Propane and butane
Answer: C

Question: What is the primary use of heavy tars, the lowest fraction in crude oil refining?
A: Roofing compounds
B: Ethylene production
C: Lubricants
D: Natural gas production
E: Paints and dyes
Answer: A

Question: What gases, obtained from petroleum and natural gas, are converted to syngas or to ethylene and propylene?
A: Ethylene and butene
B: Ethane and propane
C: Methane and benzene
D: Isobutene and pentene
E: Propene and hexene
Answer: B

Question: In what context is benzene consumed globally, with an estimated consumption of over 58 million metric tons in 2021?
A: As a food preservative
B: In the production of synthetic rubber
C: As a fuel for rockets
D: As an industrial solvent
E: In the manufacture of plastics
Answer: D

Question: What do eusocial arthropods like the Brazilian stingless bee use cuticular hydrocarbons for?
A: As a source of energy
B: To determine kin from non-kin
C: To build nests
D: To communicate with other species
E: To produce honey
Answer: B

Question: From which plants can hydrocarbons be harvested as an alternative and renewable energy source for vehicles that use diesel?
A: Oak trees
B: Euphorbia lathyris and E. tirucalli
C: Sunflowers
D: Pine trees
E: Bamboo plants
Answer: B

Question: What is the purpose of using endophytic bacteria from plants that naturally produce hydrocarbons?
A: To create biofuels
B: To produce synthetic rubber
C: To enhance plant growth
D: To deplete hydrocarbon concentration in polluted soils
E: To improve soil fertility
Answer: D
@
Hydrogenation is a chemical reaction between molecular hydrogen (H2) and another compound or element, usually in the presence of a catalyst such as nickel, palladium or platinum. The process is commonly employed to reduce or saturate organic compounds. Hydrogenation typically constitutes the addition of pairs of hydrogen atoms to a molecule, often an alkene. Catalysts are required for the reaction to be usable; non-catalytic hydrogenation takes place only at very high temperatures. Hydrogenation reduces double and triple bonds in hydrocarbons.[1]

Hydrogenation has three components, the unsaturated substrate, the hydrogen (or hydrogen source) and, invariably, a catalyst. The reduction reaction is carried out at different temperatures and pressures depending upon the substrate and the activity of the catalyst.

Related or competing reactions
See also: § Food industry
The same catalysts and conditions that are used for hydrogenation reactions can also lead to isomerization of the alkenes from cis to trans. This process is of great interest because hydrogenation technology generates most of the trans fat in foods. A reaction where bonds are broken while hydrogen is added is called hydrogenolysis, a reaction that may occur to carbon-carbon and carbon-heteroatom (oxygen, nitrogen or halogen) bonds. Some hydrogenations of polar bonds are accompanied by hydrogenolysis.

Hydrogen sources
For hydrogenation, the obvious source of hydrogen is H2 gas itself, which is typically available commercially within the storage medium of a pressurized cylinder. The hydrogenation process often uses greater than 1 atmosphere of H2, usually conveyed from the cylinders and sometimes augmented by "booster pumps". Gaseous hydrogen is produced industrially from hydrocarbons by the process known as steam reforming.[2] For many applications, hydrogen is transferred from donor molecules such as formic acid, isopropanol, and dihydroanthracene.[3] These hydrogen donors undergo dehydrogenation to, respectively, carbon dioxide, acetone, and anthracene. These processes are called transfer hydrogenations.

Substrates
An important characteristic of alkene and alkyne hydrogenations, both the homogeneously and heterogeneously catalyzed versions, is that hydrogen addition occurs with "syn addition", with hydrogen entering from the least hindered side.[4] This reaction can be performed on a variety of different functional groups.
$
10
Question: What is hydrogenation?
A: A chemical reaction between molecular hydrogen (H2) and another compound or element.
B: A process of distillation.
C: The formation of double bonds in hydrocarbons.
D: A type of polymerization.
E: A reaction that occurs without a catalyst.
Answer: A

Question: What role do catalysts play in hydrogenation?
A: They break chemical bonds.
B: They produce hydrogen gas.
C: They reduce the need for high temperatures.
D: They are not involved in hydrogenation reactions.
E: They facilitate the reaction without being consumed.
Answer: E

Question: What can hydrogenation reduce in hydrocarbons?
A: The pressure of the reaction.
B: The need for a catalyst.
C: Double and triple bonds.
D: The volume of hydrogen gas.
E: The color of the substrate.
Answer: C

Question: What is the result of hydrogenation technology in the food industry?
A: Formation of trans fat.
B: Generation of saturated fats.
C: Reduction in hydrogen gas consumption.
D: Increased pressure in food processing.
E: Formation of cis isomers.
Answer: A

Question: How is gaseous hydrogen typically stored for hydrogenation?
A: In liquid form.
B: In open containers.
C: In pressurized cylinders.
D: In solid blocks.
E: In glass containers.
Answer: C

Question: From what molecules can hydrogen be transferred in transfer hydrogenations?
A: H2 gas.
B: Oxygen gas.
C: Carbon dioxide.
D: Hydrocarbons.
E: Donor molecules like formic acid and isopropanol.
Answer: E

Question: In alkene and alkyne hydrogenations, what is the characteristic addition pattern of hydrogen?
A: Hydrogen adds randomly to any side of the molecule.
B: Hydrogen adds in a "syn addition" manner from the most hindered side.
C: Hydrogen adds to the side with the most functional groups.
D: Hydrogen adds to the side with the highest pressure.
E: Hydrogen addition is not specific and varies with each reaction.
Answer: B

Question: What is the source of hydrogen used in industrial hydrogenation processes?
A: Formic acid.
B: Oxygen gas.
C: Carbon dioxide.
D: Hydrocarbons.
E: Hydrogen donors like isopropanol.
Answer: D

Question: What is the term for a reaction where bonds are broken while hydrogen is added?
A: Hydrogenation.
B: Hydrolysis.
C: Hydrogenolysis.
D: Hydroformylation.
E: Hydrosilylation.
Answer: C

Question: What is the primary function of catalysts in hydrogenation reactions?
A: To produce heat.
B: To increase pressure.
C: To break chemical bonds.
D: To facilitate the reaction without being consumed.
E: To convert hydrogen gas into other forms of energy.
Answer: D
@
A chemical reaction is a process that leads to the chemical transformation of one set of chemical substances to another.[1] Classically, chemical reactions encompass changes that only involve the positions of electrons in the forming and breaking of chemical bonds between atoms, with no change to the nuclei (no change to the elements present), and can often be described by a chemical equation. Nuclear chemistry is a sub-discipline of chemistry that involves the chemical reactions of unstable and radioactive elements where both electronic and nuclear changes can occur.

The substance (or substances) initially involved in a chemical reaction are called reactants or reagents. Chemical reactions are usually characterized by a chemical change, and they yield one or more products, which usually have properties different from the reactants. Reactions often consist of a sequence of individual sub-steps, the so-called elementary reactions, and the information on the precise course of action is part of the reaction mechanism. Chemical reactions are described with chemical equations, which symbolically present the starting materials, end products, and sometimes intermediate products and reaction conditions.

Chemical reactions happen at a characteristic reaction rate at a given temperature and chemical concentration. Typically, reaction rates increase with increasing temperature because there is more thermal energy available to reach the activation energy necessary for breaking bonds between atoms.

A reaction may be classified as redox in which oxidation and reduction occur or non-redox in which there is no oxidation and reduction occurring. Most simple redox reactions may be classified as a combination, decomposition, or single displacement reaction.

Different chemical reactions are used during chemical synthesis in order to obtain the desired product. In biochemistry, a consecutive series of chemical reactions (where the product of one reaction is the reactant of the next reaction) form metabolic pathways. These reactions are often catalyzed by protein enzymes. Enzymes increase the rates of biochemical reactions, so that metabolic syntheses and decompositions impossible under ordinary conditions can occur at the temperature and concentrations present within a cell.

The general concept of a chemical reaction has been extended to reactions between entities smaller than atoms, including nuclear reactions, radioactive decays and reactions between elementary particles, as described by quantum field theory.
$
10
Question: What is the general outcome of a chemical reaction?
A: The nuclei of the elements present change.
B: There is no change in the properties of the reactants.
C: The positions of electrons change, with no change to the nuclei.
D: The reaction rate decreases with increasing temperature.
E: Only intermediate products are formed.
Answer: C

Question: What term is used to describe the substances initially involved in a chemical reaction?
A: Products
B: Catalysts
C: Intermediate products
D: Reactants or reagents
E: Nuclei
Answer: D

Question: What are the products of a chemical reaction typically characterized by?
A: The same properties as the reactants
B: A change in temperature
C: A change in the number of atoms present
D: A chemical change
E: A decrease in thermal energy
Answer: D

Question: What are elementary reactions in a chemical reaction?
A: Individual sub-steps that make up the overall reaction
B: Intermediate products formed during the reaction
C: The end products of the reaction
D: Reactants or reagents
E: Non-essential steps in a reaction mechanism
Answer: A

Question: How does increasing temperature affect the reaction rate of most chemical reactions?
A: It has no effect on the reaction rate.
B: It decreases the reaction rate.
C: It leads to a decrease in thermal energy.
D: It increases the reaction rate.
E: It forms intermediate products.
Answer: D

Question: What type of reaction involves both oxidation and reduction?
A: Combination reaction
B: Non-redox reaction
C: Single displacement reaction
D: Decomposition reaction
E: Redox reaction
Answer: E

Question: In what field do consecutive chemical reactions form metabolic pathways, often catalyzed by enzymes?
A: Nuclear chemistry
B: Biochemistry
C: Quantum field theory
D: Organic chemistry
E: Inorganic chemistry
Answer: B

Question: What do enzymes do in biochemical reactions?
A: Decrease reaction rates
B: Prevent reactions from occurring
C: Form intermediate products
D: Increase the rates of biochemical reactions
E: Facilitate nuclear changes
Answer: D

Question: How are chemical reactions described symbolically?
A: With nuclear equations
B: With mathematical equations
C: With intermediate products
D: With chemical equations
E: With thermal energy equations
Answer: D

Question: In addition to chemical reactions, what other types of reactions are described by quantum field theory?
A: Radioactive decays and nuclear reactions
B: Combustion reactions
C: Chemical synthesis reactions
D: Redox reactions
E: Enzymatic reactions
Answer: A
@
A chemical substance may well be defined as "any material with a definite chemical composition" in an introductory general chemistry textbook.[5][page needed] According to this definition a chemical substance can either be a pure chemical element or a pure chemical compound. But, there are exceptions to this definition; a pure substance can also be defined as a form of matter that has both definite composition and distinct properties.[6] The chemical substance index published by CAS also includes several alloys of uncertain composition.[7] Non-stoichiometric compounds are a special case (in inorganic chemistry) that violates the law of constant composition, and for them, it is sometimes difficult to draw the line between a mixture and a compound, as in the case of palladium hydride. Broader definitions of chemicals or chemical substances can be found, for example: "the term 'chemical substance' means any organic or inorganic substance of a particular molecular identity, including – (i) any combination of such substances occurring in whole or in part as a result of a chemical reaction or occurring in nature".[8]

In geology, substances of uniform composition are called minerals, while physical mixtures (aggregates) of several minerals (different substances) are defined as rocks. Many minerals, however, mutually dissolve into solid solutions, such that a single rock is a uniform substance despite being a mixture in stoichiometric terms. Feldspars are a common example: anorthoclase is an alkali aluminum silicate, where the alkali metal is interchangeably either sodium or potassium.

In law, "chemical substances" may include both pure substances and mixtures with a defined composition or manufacturing process. For example, the EU regulation REACH defines "monoconstituent substances", "multiconstituent substances" and "substances of unknown or variable composition". The latter two consist of multiple chemical substances; however, their identity can be established either by direct chemical analysis or reference to a single manufacturing process. For example, charcoal is an extremely complex, partially polymeric mixture that can be defined by its manufacturing process. Therefore, although the exact chemical identity is unknown, identification can be made with a sufficient accuracy. The CAS index also includes mixtures.

Polymers almost always appear as mixtures of molecules of multiple molar masses, each of which could be considered a separate chemical substance. However, the polymer may be defined by a known precursor or reaction(s) and the molar mass distribution. For example, polyethylene is a mixture of very long chains of -CH2- repeating units, and is generally sold in several molar mass distributions, LDPE, MDPE, HDPE and UHMWPE.
$
10
Question: How is a chemical substance defined in an introductory general chemistry textbook?
A: As any material with a definite chemical composition
B: As a mixture of multiple chemical elements
C: As a complex mixture of unknown composition
D: As a uniform substance with variable properties
E: As a combination of substances occurring only in nature
Answer: A

Question: What is the broader definition of a chemical substance according to some sources?
A: Any naturally occurring substance
B: Any mixture of substances with unknown composition
C: Any combination of substances occurring as a result of a chemical reaction
D: Any substance with variable properties
E: Any substance with a single manufacturing process
Answer: C

Question: In geology, what are substances of uniform composition called?
A: Rocks
B: Minerals
C: Mixtures
D: Aggregates
E: Compounds
Answer: B

Question: What is an example of a mineral that mutually dissolves into a solid solution, appearing as a uniform substance despite being a mixture?
A: Feldspar
B: Quartz
C: Gypsum
D: Calcite
E: Halite
Answer: A

Question: How does the EU regulation REACH define "chemical substances" in the context of law?
A: Pure substances only
B: Mixtures with unknown composition
C: Any substances occurring in nature
D: Substances with known precursor or reaction
E: Only monoconstituent substances
Answer: D

Question: What is an example of a chemical substance that is defined by its manufacturing process despite its complex composition?
A: Charcoal
B: Water
C: Ethanol
D: Oxygen
E: Sodium chloride
Answer: A

Question: What is the CAS index's approach to defining "chemical substances"?
A: It includes only pure chemical compounds.
B: It includes substances of unknown composition.
C: It excludes mixtures.
D: It defines substances solely by their molar mass.
E: It includes mixtures and substances with a defined composition or manufacturing process.
Answer: E

Question: In the context of polymers, what are the multiple molar masses within a polymer mixture considered?
A: Different chemical substances
B: Elements
C: Impurities
D: Mixtures
E: Rocks
Answer: A

Question: What is the term used for substances that consist of multiple chemical substances, but their identity can be established by a single manufacturing process?
A: Complex mixtures
B: Unknown compositions
C: Monoconstituent substances
D: Multiconstituent substances
E: Impure substances
Answer: D

Question: What is the name for the different molar mass distributions of polyethylene?
A: LDDPE, MDDPE, HDDPE, UHMWPE
B: Low-density, high-density, ultra-high-density
C: Simple, complex, advanced
D: Monomer, dimer, trimer, polymer
E: Polycarbonate, polystyrene, polypropylene, polyethylene terephthalate
Answer: A
@
Hydrogen is the chemical element with the symbol H and atomic number 1. Hydrogen is the lightest element. At standard conditions hydrogen is a gas of diatomic molecules having the formula H2. It is colorless, odorless, tasteless,[8] non-toxic, and highly combustible. Hydrogen is the most abundant chemical substance in the universe, constituting roughly 75% of all normal matter.[9][note 1] Stars such as the Sun are mainly composed of hydrogen in the plasma state. Most of the hydrogen on Earth exists in molecular forms such as water and organic compounds. For the most common isotope of hydrogen (symbol 1H) each atom has one proton, one electron, and no neutrons.

In the early universe, the formation of protons, the nuclei of hydrogen, occurred during the first second after the Big Bang. The emergence of neutral hydrogen atoms throughout the universe occurred about 370,000 years later during the recombination epoch, when the plasma had cooled enough for electrons to remain bound to protons.[10]

Hydrogen is nonmetallic (except when it becomes metallic at extremely high pressures) and readily forms a single covalent bond with most nonmetallic elements, forming compounds such as water and nearly all organic compounds. Hydrogen plays a particularly important role in acid–base reactions because these reactions usually involve the exchange of protons between soluble molecules. In ionic compounds, hydrogen can take the form of a negative charge (i.e., anion) where it is known as a hydride, or as a positively charged (i.e., cation) species denoted by the symbol H+. The H+ cation is simply a proton (symbol p) but its behavior in aqueous solutions and in ionic compounds involves screening of its electric charge by nearby polar molecules or anions. Because hydrogen is the only neutral atom for which the Schrödinger equation can be solved analytically,[11] the study of its energetics and chemical bonding has played a key role in the development of quantum mechanics.
$
10
Question: Which chemical element has the atomic number 1 and is the lightest element?
A: Hydrogen
B: Helium
C: Oxygen
D: Carbon
E: Nitrogen
Answer: A

Question: Under standard conditions, what is the molecular formula of hydrogen gas?
A: H
B: H3
C: H2O
D: O2
E: CO2
Answer: A

Question: What is the most abundant chemical substance in the universe?
A: Oxygen
B: Carbon
C: Hydrogen
D: Helium
E: Nitrogen
Answer: C

Question: In what state does hydrogen exist in stars like the Sun?
A: Solid
B: Liquid
C: Gas
D: Plasma
E: Metal
Answer: D

Question: How many protons does the most common isotope of hydrogen (symbol 1H) have?
A: Zero
B: One
C: Two
D: Three
E: Four
Answer: B

Question: When did the formation of protons, the nuclei of hydrogen, occur in the early universe?
A: During the Big Bang
B: About 370,000 years after the Big Bang
C: During the recombination epoch
D: Before the Big Bang
E: None of the above
Answer: A

Question: In what state did neutral hydrogen atoms first emerge throughout the universe?
A: Solid
B: Liquid
C: Gas
D: Plasma
E: Metal
Answer: C

Question: What role does hydrogen play in acid–base reactions?
A: It forms ionic bonds with other elements
B: It serves as a catalyst
C: It exchanges protons between soluble molecules
D: It creates covalent bonds with metals
E: It becomes metallic
Answer: C

Question: In ionic compounds, what forms can hydrogen take?
A: Negative charge (hydride) and positive charge (H+ cation)
B: Negative charge (anion) only
C: Positive charge (cation) only
D: Neutral charge
E: None of the above
Answer: A

Question: Why has the study of hydrogen played a key role in the development of quantum mechanics?
A: Because hydrogen is the heaviest element.
B: Because hydrogen is the most abundant element on Earth.
C: Because hydrogen is metallic at standard conditions.
D: Because the Schrödinger equation can be solved analytically for hydrogen.
E: Because hydrogen forms covalent bonds with metals.
Answer: D
@
A nonmetal is a type of chemical element that, in general, has a low density and high electronegativity (the ability of an atom in a molecule to attract electrons to itself). They encompass a diverse selection of elements, ranging from colorless gases like hydrogen to solid substances with a shiny appearance, such as carbon in its graphite form. Nonmetals are usually poor conductors of heat and electricity. When they exist in solid form, they tend to be brittle or crumbly owing to the limited mobility of their electrons. This stands in contrast to metals, which are known for their efficient electrical conductivity and malleability, often being readily transformed into thin sheets and drawn into wires due to the free movement of their electrons. Additionally, whereas compounds of metals tend to be basic in nature those of nonmetals tend to be acidic.

Within the realm of elemental composition, two nonmetals, namely hydrogen and helium, constitute an overwhelming 99% of the observable ordinary matter in the universe by mass. Moreover, five nonmetallic elements, namely hydrogen, carbon, nitrogen, oxygen, and silicon, constitute the majority of the Earth's crust, atmosphere, oceans and biosphere, underscoring their pivotal role in the composition of the planet.

The unique properties exhibited by nonmetallic elements render them essential for various specialized applications, often complementing the capabilities of metallic elements. Vital to the composition of living organisms are the nonmetals hydrogen, oxygen, carbon, and nitrogen, which constitute a significant portion of their structural makeup. Beyond biology, nonmetallic elements play crucial roles in diverse industries, including electronics, energy storage, agriculture, and chemical production.

The term 'non-metallic' has roots dating back to as far as 1566, yet there is no widely agreed precise definition of a nonmetal. This ambiguity arises from the existence of elements that exhibit a marked combination of metallic and nonmetallic attributes. The classification of such borderline cases as nonmetals varies depending on the specific criteria employed for classification. Generally, the number of elements recognized as nonmetals falls within the range of 14 to 23 (or 24), reflecting the fluid nature of this classification.
$
10
Question: Which property is generally characteristic of nonmetals?
A: High electrical conductivity
B: Low electronegativity
C: Shiny appearance
D: Limited mobility of electrons
E: Basic nature in compounds
Answer: D

Question: What is the typical electrical conductivity of nonmetals?
A: High
B: Low
C: Moderate
D: Variable
E: None
Answer: B

Question: In terms of electrical conductivity, how do nonmetals compare to metals?
A: Nonmetals are better conductors of electricity.
B: Nonmetals have similar electrical conductivity to metals.
C: Nonmetals are poor conductors of electricity.
D: Nonmetals have variable electrical conductivity.
E: Nonmetals and metals are identical in electrical conductivity.
Answer: C

Question: Which elements constitute the majority of the Earth's crust, atmosphere, oceans, and biosphere?
A: Hydrogen and helium
B: Hydrogen, carbon, nitrogen, oxygen, and silicon
C: Helium, carbon, nitrogen, oxygen, and silicon
D: Hydrogen, helium, carbon, oxygen, and nitrogen
E: Helium, oxygen, carbon, silicon, and nitrogen
Answer: B

Question: What role do hydrogen, oxygen, carbon, and nitrogen play in living organisms?
A: They are involved in electrical conductivity.
B: They make up a significant portion of the structural makeup.
C: They are primarily found in metallic elements.
D: They are essential for energy storage.
E: They are basic in nature.
Answer: B

Question: In what industries do nonmetallic elements play crucial roles?
A: Transportation and construction
B: Entertainment and fashion
C: Electronics, energy storage, agriculture, and chemical production
D: Healthcare and education
E: Mining and metallurgy
Answer: C

Question: What makes the classification of elements as nonmetals ambiguous?
A: The existence of elements with metallic and nonmetallic attributes
B: Lack of historical documentation
C: Inconsistent naming conventions
D: The number of nonmetallic elements exceeding 50
E: Nonmetals not being part of the periodic table
Answer: A

Question: How many elements are generally recognized as nonmetals?
A: 7 to 10
B: 14 to 23 (or 24)
C: 50 to 60
D: 100 or more
E: 1 to 5
Answer: B

Question: What role do nonmetals typically play in compounds?
A: They make compounds basic in nature.
B: They serve as catalysts.
C: They enhance electrical conductivity.
D: They are not involved in compound formation.
E: They make compounds acidic in nature.
Answer: E

Question: What percentage of observable ordinary matter in the universe by mass is constituted by hydrogen and helium?
A: 25%
B: 50%
C: 75%
D: 90%
E: 99%
Answer: E
@
Electronegativity, symbolized as χ, is the tendency for an atom of a given chemical element to attract shared electrons (or electron density) when forming a chemical bond.[1] An atom's electronegativity is affected by both its atomic number and the distance at which its valence electrons reside from the charged nucleus. The higher the associated electronegativity, the more an atom or a substituent group attracts electrons. Electronegativity serves as a simple way to quantitatively estimate the bond energy, and the sign and magnitude of a bond's chemical polarity, which characterizes a bond along the continuous scale from covalent to ionic bonding. The loosely defined term electropositivity is the opposite of electronegativity: it characterizes an element's tendency to donate valence electrons.

On the most basic level, electronegativity is determined by factors like the nuclear charge (the more protons an atom has, the more "pull" it will have on electrons) and the number and location of other electrons in the atomic shells (the more electrons an atom has, the farther from the nucleus the valence electrons will be, and as a result, the less positive charge they will experience—both because of their increased distance from the nucleus and because the other electrons in the lower energy core orbitals will act to shield the valence electrons from the positively charged nucleus).

The term "electronegativity" was introduced by Jöns Jacob Berzelius in 1811,[2] though the concept was known before that and was studied by many chemists including Avogadro.[2] In spite of its long history, an accurate scale of electronegativity was not developed until 1932, when Linus Pauling proposed an electronegativity scale which depends on bond energies, as a development of valence bond theory.[3] It has been shown to correlate with a number of other chemical properties. Electronegativity cannot be directly measured and must be calculated from other atomic or molecular properties. Several methods of calculation have been proposed, and although there may be small differences in the numerical values of the electronegativity, all methods show the same periodic trends between elements.[4]

The most commonly used method of calculation is that originally proposed by Linus Pauling. This gives a dimensionless quantity, commonly referred to as the Pauling scale (χr), on a relative scale running from 0.79 to 3.98 (hydrogen = 2.20). When other methods of calculation are used, it is conventional (although not obligatory) to quote the results on a scale that covers the same range of numerical values: this is known as an electronegativity in Pauling units.

As it is usually calculated, electronegativity is not a property of an atom alone, but rather a property of an atom in a molecule.[5] Even so, the electronegativity of an atom is strongly correlated with the first ionization energy, and negatively correlated with the electron affinity. It is to be expected that the electronegativity of an element will vary with its chemical environment,[6] but it is usually considered to be a transferable property, that is to say that similar values will be valid in a variety of situations.

Caesium is the least electronegative element (0.79); fluorine is the most (3.98).
$
10

Question: What is electronegativity?
A: The tendency for an atom to attract shared electrons when forming a chemical bond.
B: The total number of electrons in an atom.
C: The ability of an atom to donate valence electrons.
D: The distance between an atom's nucleus and its valence electrons.
E: The number of protons in an atom's nucleus.
Answer: A

Question: What factors affect an atom's electronegativity?
A: The number of core electrons.
B: The number of protons.
C: The nuclear charge and the number and location of other electrons in the atomic shells.
D: The atomic mass.
E: The electron affinity.
Answer: C

Question: Who introduced the term "electronegativity" in 1811?
A: Linus Pauling
B: Jöns Jacob Berzelius
C: Avogadro
D: Niels Bohr
E: Werner Heisenberg
Answer: B

Question: When was an accurate scale of electronegativity first developed?
A: 1811
B: 1932
C: 1945
D: 1957
E: 1969
Answer: B

Question: Which element is the least electronegative according to the Pauling scale?
A: Hydrogen
B: Oxygen
C: Caesium
D: Fluorine
E: Carbon
Answer: C

Question: What is the Pauling scale commonly referred to as?
A: Electronegativity in units
B: Electropositivity scale
C: Ionization energy scale
D: Atomic radius scale
E: Electron affinity scale
Answer: A

Question: What is the most electronegative element according to the Pauling scale?
A: Hydrogen
B: Oxygen
C: Caesium
D: Fluorine
E: Carbon
Answer: D

Question: Is electronegativity a property of an isolated atom or an atom in a molecule?
A: Isolated atom
B: Atom in a molecule
C: Both
D: Neither
E: It depends on the atom.
Answer: B

Question: What is electronegativity strongly correlated with?
A: Atomic mass
B: Electron affinity
C: Ionization energy
D: Nuclear charge
E: Core electrons
Answer: C

Question: Which element is the most electronegative according to the Pauling scale?
A: Hydrogen
B: Oxygen
C: Caesium
D: Fluorine
E: Carbon
Answer: B
@
A covalent bond is a chemical bond that involves the sharing of electrons to form electron pairs between atoms. These electron pairs are known as shared pairs or bonding pairs. The stable balance of attractive and repulsive forces between atoms, when they share electrons, is known as covalent bonding.[1] For many molecules, the sharing of electrons allows each atom to attain the equivalent of a full valence shell, corresponding to a stable electronic configuration. In organic chemistry, covalent bonding is much more common than ionic bonding.

Covalent bonding also includes many kinds of interactions, including σ-bonding, π-bonding, metal-to-metal bonding, agostic interactions, bent bonds, three-center two-electron bonds and three-center four-electron bonds.[2][3] The term covalent bond dates from 1939.[4] The prefix co- means jointly, associated in action, partnered to a lesser degree, etc.; thus a "co-valent bond", in essence, means that the atoms share "valence", such as is discussed in valence bond theory.

In the molecule H
2, the hydrogen atoms share the two electrons via covalent bonding.[5] Covalency is greatest between atoms of similar electronegativities. Thus, covalent bonding does not necessarily require that the two atoms be of the same elements, only that they be of comparable electronegativity. Covalent bonding that entails the sharing of electrons over more than two atoms is said to be delocalized.
$
10
Question: What is a covalent bond primarily characterized by?
A: The exchange of electrons between atoms.
B: The transfer of electrons from one atom to another.
C: The sharing of electrons to form electron pairs.
D: The complete transfer of valence electrons.
E: The attraction between positively charged nuclei.
Answer: C

Question: What is the stable balance of forces between atoms when they share electrons known as?
A: Ionic bonding
B: Metallic bonding
C: Covalent bonding
D: Valence bonding
E: Electronegative bonding
Answer: C

Question: In organic chemistry, is covalent bonding more common than ionic bonding?
A: Yes
B: No
Answer: A

Question: What is the term for the sharing of electrons over more than two atoms in covalent bonding?
A: Delocalized bonding
B: Ionic bonding
C: Metallic bonding
D: Sigma bonding
E: Pi bonding
Answer: A

Question: In the molecule H2, how do the hydrogen atoms share electrons?
A: Via ionic bonding
B: Via metallic bonding
C: Via covalent bonding
D: Via sigma bonding
E: Via pi bonding
Answer: C

Question: What is the prefix "co-" in "covalent bond" indicative of?
A: Equal sharing of electrons
B: Different elements involved
C: Sharing of valence electrons
D: Ionic bonding
E: Metallic bonding
Answer: C

Question: What kind of covalent bond involves the sharing of electrons between atoms of similar electronegativity?
A: Polar covalent bond
B: Nonpolar covalent bond
C: Ionic bond
D: Metallic bond
E: Hydrogen bond
Answer: B

Question: What is the term for the shared pairs of electrons in a covalent bond?
A: Ionic pairs
B: Metallic pairs
C: Bonding pairs
D: Valence pairs
E: Electron pairs
Answer: C

Question: What is the name of the bonding that includes interactions like σ-bonding, π-bonding, and metal-to-metal bonding?
A: Covalent bonding
B: Ionic bonding
C: Metallic bonding
D: Van der Waals bonding
E: Hydrogen bonding
Answer: A

Question: When was the term "covalent bond" introduced?
A: 1811
B: 1939
C: 1954
D: 1967
E: 1982
Answer: B
@
Ionic bonding is a type of chemical bonding that involves the electrostatic attraction between oppositely charged ions, or between two atoms with sharply different electronegativities,[1] and is the primary interaction occurring in ionic compounds. It is one of the main types of bonding, along with covalent bonding and metallic bonding. Ions are atoms (or groups of atoms) with an electrostatic charge. Atoms that gain electrons make negatively charged ions (called anions). Atoms that lose electrons make positively charged ions (called cations). This transfer of electrons is known as electrovalence in contrast to covalence. In the simplest case, the cation is a metal atom and the anion is a nonmetal atom, but these ions can be more complex, e.g. molecular ions like NH+
4 or SO2−
4. In simpler words, an ionic bond results from the transfer of electrons from a metal to a non-metal to obtain a full valence shell for both atoms.

It is important to recognize that clean ionic bonding — in which one atom or molecule completely transfers an electron to another — cannot exist: all ionic compounds have some degree of covalent bonding or electron sharing. Thus, the term "ionic bonding" is given when the ionic character is greater than the covalent character – that is, a bond in which there is a large difference in electronegativity between the two atoms, causing the bonding to be more polar (ionic) than in covalent bonding where electrons are shared more equally. Bonds with partially ionic and partially covalent characters are called polar covalent bonds.

Ionic compounds conduct electricity when molten or in solution, typically not when solid. Ionic compounds generally have a high melting point, depending on the charge of the ions they consist of. The higher the charges the stronger the cohesive forces and the higher the melting point. They also tend to be soluble in water; the stronger the cohesive forces, the lower the solubility.[2]
@
Question: What is the primary interaction occurring in ionic compounds?
A: Covalent bonding
B: Ionic bonding
C: Metallic bonding
D: Van der Waals bonding
E: Hydrogen bonding
Answer: B

Question: What are atoms that gain electrons and become negatively charged called?
A: Cations
B: Anions
C: Ions
D: Electrons
E: Protons
Answer: B

Question: How is the transfer of electrons in ionic bonding different from covalence?
A: Electrons are completely transferred in ionic bonding.
B: Electrons are shared equally in ionic bonding.
C: Electrons are not involved in ionic bonding.
D: Electrons are transferred from a non-metal to a metal in covalence.
E: Electrons are transferred from a metal to a non-metal in covalence.
Answer: A

Question: When is the term "ionic bonding" used?
A: When there is no difference in electronegativity between two atoms.
B: When there is a large difference in electronegativity between two atoms.
C: When electrons are shared equally between two atoms.
D: When there is no electron transfer between two atoms.
E: When both atoms are metals.
Answer: B

Question: What type of bonds have partially ionic and partially covalent characters?
A: Ionic bonds
B: Covalent bonds
C: Metallic bonds
D: Van der Waals bonds
E: Polar covalent bonds
Answer: E

Question: When do ionic compounds typically conduct electricity?
A: When solid
B: When molten or in solution
C: When exposed to air
D: When heated to high temperatures
E: When exposed to strong light
Answer: B

Question: What tends to be the solubility of ionic compounds in water?
A: Low solubility
B: High solubility
C: No solubility
D: Solubility depends on the temperature
E: Solubility depends on the color of the compound
Answer: B

Question: What factor influences the melting point of ionic compounds?
A: The charge of the ions
B: The size of the ions
C: The color of the ions
D: The electron configuration of the ions
E: The atomic number of the ions
Answer: A

Question: In ionic bonding, what is transferred from a non-metal to a metal?
A: Electrons
B: Protons
C: Neutrons
D: Photons
E: Positrons
Answer: A

Question: What type of bonding results from the transfer of electrons from a metal to a non-metal to obtain a full valence shell for both atoms?
A: Covalent bonding
B: Metallic bonding
C: Ionic bonding
D: Van der Waals bonding
E: Hydrogen bonding
Answer: C
@
Silicon is a chemical element with the symbol Si and atomic number 14. It is a hard, brittle crystalline solid with a blue-grey metallic luster, and is a tetravalent metalloid and semiconductor. It is a member of group 14 in the periodic table: carbon is above it; and germanium, tin, lead, and flerovium are below it. It is relatively unreactive.

Because of its high chemical affinity for oxygen, it was not until 1823 that Jöns Jakob Berzelius was first able to prepare it and characterize it in pure form. Its oxides form a family of anions known as silicates. Its melting and boiling points of 1414 °C and 3265 °C, respectively, are the second highest among all the metalloids and nonmetals, being surpassed only by boron.

Silicon is the eighth most common element in the universe by mass, but very rarely occurs as the pure element in the Earth's crust. It is widely distributed in space in cosmic dusts, planetoids, and planets as various forms of silicon dioxide (silica) or silicates. More than 90% of the Earth's crust is composed of silicate minerals, making silicon the second most abundant element in the Earth's crust (about 28% by mass), after oxygen.

Most silicon is used commercially without being separated, often with very little processing of the natural minerals. Such use includes industrial construction with clays, silica sand, and stone. Silicates are used in Portland cement for mortar and stucco, and mixed with silica sand and gravel to make concrete for walkways, foundations, and roads. They are also used in whiteware ceramics such as porcelain, and in traditional silicate-based soda–lime glass and many other specialty glasses. Silicon compounds such as silicon carbide are used as abrasives and components of high-strength ceramics. Silicon is the basis of the widely used synthetic polymers called silicones.

The late 20th century to early 21st century has been described as the Silicon Age (also known as the Digital Age or Information Age) because of the large impact that elemental silicon has on the modern world economy. The small portion of very highly purified elemental silicon used in semiconductor electronics (<15%) is essential to the transistors and integrated circuit chips used in most modern technology such as smartphones and other computers. In 2019, 32.4% of the semiconductor market segment was for networks and communications devices, and the semiconductors industry is projected to reach $726.73 billion by 2027.[11]
$
10
Question: Which group does silicon belong to in the periodic table?
A: Group 14
B: Group 1
C: Group 8
D: Group 18
E: Group 7
Answer: A

Question: What are the melting and boiling points of silicon?
A: 1414 °C and 3265 °C
B: 100 °C and 212 °C
C: -273 °C and -150 °C
D: 0 °C and 100 °C
E: 500 °C and 1500 °C
Answer: A

Question: What is the second most abundant element in the Earth's crust by mass?
A: Oxygen
B: Silicon
C: Carbon
D: Aluminum
E: Iron
Answer: B

Question: What family of anions do silicon oxides form?
A: Carbonates
B: Sulfides
C: Nitrates
D: Silicates
E: Phosphates
Answer: D

Question: What is the widely used synthetic polymers called that are based on silicon?
A: Polyethylene
B: Polyurethane
C: Polystyrene
D: Silicones
E: Polypropylene
Answer: D

Question: What is the primary use of highly purified elemental silicon in the semiconductor industry?
A: Making concrete
B: Producing ceramics
C: Creating glass
D: Manufacturing smartphones
E: Constructing roads
Answer: D

Question: What has the late 20th century to early 21st century been described as due to the impact of silicon on the modern world economy?
A: Bronze Age
B: Stone Age
C: Iron Age
D: Silicon Age
E: Renaissance
Answer: D

Question: In what types of ceramics are silicates used?
A: Earthenware ceramics
B: Whiteware ceramics
C: Porcelain ceramics
D: Stoneware ceramics
E: Glass ceramics
Answer: B

Question: What is the most common compound of silicon found in space and on Earth?
A: Silicon carbide
B: Silicon dioxide (silica)
C: Silicon sulfide
D: Silicon nitride
E: Silicon chloride
Answer: B

Question: What percentage of the Earth's crust is composed of silicate minerals?
A: About 50%
B: About 10%
C: About 28%
D: About 70%
E: About 5%
Answer: C
@
The first semiconductor devices did not use silicon, but used galena, including German physicist Ferdinand Braun's crystal detector in 1874 and Indian physicist Jagadish Chandra Bose's radio crystal detector in 1901.[32][33] The first silicon semiconductor device was a silicon radio crystal detector, developed by American engineer Greenleaf Whittier Pickard in 1906.[33]

In 1940, Russell Ohl discovered the p–n junction and photovoltaic effects in silicon. In 1941, techniques for producing high-purity germanium and silicon crystals were developed for radar microwave detector crystals during World War II.[32] In 1947, physicist William Shockley theorized a field-effect amplifier made from germanium and silicon, but he failed to build a working device, before eventually working with germanium instead. The first working transistor was a point-contact transistor built by John Bardeen and Walter Brattain later that year while working under Shockley.[34] In 1954, physical chemist Morris Tanenbaum fabricated the first silicon junction transistor at Bell Labs.[35] In 1955, Carl Frosch and Lincoln Derick at Bell Labs accidentally discovered that silicon dioxide (SiO
2) could be grown on silicon,[36] and they later proposed this could mask silicon surfaces during diffusion processes in 1958.[37]

Silicon Age

The MOSFET, also known as the MOS transistor, is the key component of the Silicon Age. It was invented by Mohamed M. Atalla and Dawon Kahng at Bell Labs in 1959.
The "Silicon Age" refers to the late 20th century to early 21st century.[38][39][40] This is due to silicon being the dominant material of the Silicon Age (also known as the Digital Age or Information Age), similar to how the Stone Age, Bronze Age and Iron Age were defined by the dominant materials during their respective ages of civilization.[38]

Because silicon is an important element in high-technology semiconductor devices, many places in the world bear its name. For example, Santa Clara Valley in California acquired the nickname Silicon Valley, as the element is the base material in the semiconductor industry there. Since then, many other places have been similarly dubbed, including Silicon Wadi in Israel; Silicon Forest in Oregon; Silicon Hills in Austin, Texas; Silicon Slopes in Salt Lake City, Utah; Silicon Saxony in Germany, Silicon Valley in India, Silicon Border in Mexicali, Mexico; Silicon Fen in Cambridge, England; Silicon Roundabout in London; Silicon Glen in Scotland; Silicon Gorge in Bristol, England; Silicon Alley in New York City; and Silicon Beach in Los Angeles.[41]
$
10

Question: Who developed the first silicon semiconductor device?
A: Ferdinand Braun
B: Jagadish Chandra Bose
C: Greenleaf Whittier Pickard
D: Russell Ohl
E: William Shockley
Answer: C

Question: In what year did Russell Ohl discover the p–n junction and photovoltaic effects in silicon?
A: 1874
B: 1901
C: 1906
D: 1940
E: 1954
Answer: D

Question: What was the first working transistor called, and who built it?
A: MOSFET, built by John Bardeen
B: Point-contact transistor, built by William Shockley
C: Silicon junction transistor, built by Morris Tanenbaum
D: Crystal detector, built by Ferdinand Braun
E: Radio crystal detector, built by Jagadish Chandra Bose
Answer: B

Question: What did Carl Frosch and Lincoln Derick discover about silicon in 1955?
A: The first silicon junction transistor
B: The photovoltaic effects in silicon
C: That silicon could be grown on silicon dioxide
D: That silicon could mask silicon surfaces during diffusion processes
E: That silicon was a semiconductor
Answer: C

Question: Who invented the MOSFET, a key component of the Silicon Age?
A: John Bardeen and Walter Brattain
B: Morris Tanenbaum
C: Russell Ohl
D: Mohamed M. Atalla and Dawon Kahng
E: William Shockley
Answer: D

Question: Which valley in California is known as Silicon Valley due to its association with the semiconductor industry?
A: Death Valley
B: Napa Valley
C: Central Valley
D: Santa Clara Valley
E: San Fernando Valley
Answer: D

Question: What is the period from the late 20th century to the early 21st century often referred to as?
A: Stone Age
B: Bronze Age
C: Iron Age
D: Silicon Age
E: Digital Age
Answer: D

Question: Which country has an area known as Silicon Wadi?
A: United States
B: Israel
C: Germany
D: India
E: England
Answer: B

Question: What is the nickname for the high-technology semiconductor industry area in Austin, Texas?
A: Silicon Valley
B: Silicon Slopes
C: Silicon Hills
D: Silicon Saxony
E: Silicon Forest
Answer: C

Question: What is the name of the area in Los Angeles associated with the technology industry?
A: Silicon Beach
B: Silicon Border
C: Silicon Fen
D: Silicon Roundabout
E: Silicon Glen
Answer: A
@
Silicon of 96–99% purity is made by carbothermically reducing quartzite or sand with highly pure coke. The reduction is carried out in an electric arc furnace, with an excess of SiO
2 used to stop silicon carbide (SiC) from accumulating:[30]

SiO
2 + 2 C → Si + 2 CO
2 SiC + SiO
2 → 3 Si + 2 CO

Ferrosilicon alloy
This reaction, known as carbothermal reduction of silicon dioxide, usually is conducted in the presence of scrap iron with low amounts of phosphorus and sulfur, producing ferrosilicon.[30] Ferrosilicon, an iron-silicon alloy that contains varying ratios of elemental silicon and iron, accounts for about 80% of the world's production of elemental silicon, with China, the leading supplier of elemental silicon, providing 4.6 million tonnes (or 2/3rds of world output) of silicon, most of it in the form of ferrosilicon. It is followed by Russia (610,000 t), Norway (330,000 t), Brazil (240,000 t), and the United States (170,000 t).[90] Ferrosilicon is primarily used by the iron and steel industry (see below) with primary use as alloying addition in iron or steel and for de-oxidation of steel in integrated steel plants.[30]

Another reaction, sometimes used, is aluminothermal reduction of silicon dioxide, as follows:[91]

3 SiO
2 + 4 Al → 3 Si + 2 Al
2O
3
Leaching powdered 96–97% pure silicon with water results in ~98.5% pure silicon, which is used in the chemical industry. However, even greater purity is needed for semiconductor applications, and this is produced from the reduction of tetrachlorosilane (silicon tetrachloride) or trichlorosilane. The former is made by chlorinating scrap silicon and the latter is a byproduct of silicone production. These compounds are volatile and hence can be purified by repeated fractional distillation, followed by reduction to elemental silicon with very pure zinc metal as the reducing agent. The spongy pieces of silicon thus produced are melted and then grown to form cylindrical single crystals, before being purified by zone refining. Other routes use the thermal decomposition of silane or tetraiodosilane (SiI
4). Another process used is the reduction of sodium hexafluorosilicate, a common waste product of the phosphate fertilizer industry, by metallic sodium: this is highly exothermic and hence requires no outside energy source. Hyperfine silicon is made at a higher purity than almost any other material: transistor production requires impurity levels in silicon crystals less than 1 part per 1010, and in special cases impurity levels below 1 part per 1012 are needed and attained.[30]

Silicon nanostructures can directly be produced from silica sand using conventional metalothermic processes, or the combustion synthesis approach. Such nanostructured silicon materials can be used in various functional applications including the anode of lithium ion batteries (LIBs) or photocatalytic applications.[92]
$
10
Question: What is the primary method for producing silicon of 96–99% purity?
A: Carbothermal reduction of silicon tetrachloride
B: Aluminothermal reduction of silicon dioxide
C: Reduction of sodium hexafluorosilicate
D: Thermal decomposition of silane
E: Leaching powdered silicon with water
Answer: A

Question: Which element is used as the reducing agent in the production of silicon from tetrachlorosilane?
A: Zinc
B: Aluminum
C: Iron
D: Sodium
E: Copper
Answer: A

Question: What is the primary use of ferrosilicon?
A: Semiconductor manufacturing
B: De-oxidation of steel
C: Production of pure silicon
D: Photocatalytic applications
E: Lithium-ion battery anodes
Answer: B

Question: Which country is the leading supplier of elemental silicon, providing the majority of it in the form of ferrosilicon?
A: Russia
B: Norway
C: Brazil
D: China
E: United States
Answer: D

Question: What is the byproduct of silicone production that can be used to produce very pure silicon for semiconductor applications?
A: Silicon tetrachloride
B: Silicon dioxide
C: Sodium hexafluorosilicate
D: Aluminum
E: Zinc
Answer: A

Question: What is the impurity level required for transistor production in silicon crystals?
A: Less than 1 part per million
B: Less than 1 part per billion
C: Less than 1 part per trillion
D: Less than 1 part per 10 billion
E: Less than 1 part per 10 trillion
Answer: D

Question: How is hyperfine silicon made from sodium hexafluorosilicate?
A: It is produced using the combustion synthesis approach.
B: It is made through carbothermal reduction.
C: It is obtained by reducing it with metallic sodium.
D: It is purified by repeated fractional distillation.
E: It is extracted from silica sand.
Answer: C

Question: What process is used to grow cylindrical single crystals of silicon?
A: Aluminothermal reduction
B: Thermal decomposition of silane
C: Carbothermal reduction
D: Zone refining
E: Leaching with water
Answer: D

Question: What are silicon nanostructures primarily used for?
A: Iron and steel production
B: Semiconductor manufacturing
C: Photocatalytic applications
D: Silicon transistor production
E: Silicon dioxide production
Answer: C

Question: What is the key component of silicon nanostructures used in photocatalytic applications?
A: Silicon tetrachloride
B: Silicon dioxide
C: Silicon metal
D: Silane
E: Silica sand
Answer: C
@
Most elemental silicon produced remains as a ferrosilicon alloy, and only approximately 20% is refined to metallurgical grade purity (a total of 1.3–1.5 million metric tons/year). An estimated 15% of the world production of metallurgical grade silicon is further refined to semiconductor purity.[97] This typically is the "nine-9" or 99.9999999% purity,[98] nearly defect-free single crystalline material.[99]

Monocrystalline silicon of such purity is usually produced by the Czochralski process, and is used to produce silicon wafers used in the semiconductor industry, in electronics, and in some high-cost and high-efficiency photovoltaic applications.[100] Pure silicon is an intrinsic semiconductor, which means that unlike metals, it conducts electron holes and electrons released from atoms by heat; silicon's electrical conductivity increases with higher temperatures. Pure silicon has too low a conductivity (i.e., too high a resistivity) to be used as a circuit element in electronics. In practice, pure silicon is doped with small concentrations of certain other elements, which greatly increase its conductivity and adjust its electrical response by controlling the number and charge (positive or negative) of activated carriers. Such control is necessary for transistors, solar cells, semiconductor detectors, and other semiconductor devices used in the computer industry and other technical applications.[101] In silicon photonics, silicon may be used as a continuous wave Raman laser medium to produce coherent light.[102]

In common integrated circuits, a wafer of monocrystalline silicon serves as a mechanical support for the circuits, which are created by doping and insulated from each other by thin layers of silicon oxide, an insulator that is easily produced on Si surfaces by processes of thermal oxidation or local oxidation (LOCOS), which involve exposing the element to oxygen under the proper conditions that can be predicted by the Deal–Grove model. Silicon has become the most popular material for both high power semiconductors and integrated circuits because it can withstand the highest temperatures and greatest electrical activity without suffering avalanche breakdown (an electron avalanche is created when heat produces free electrons and holes, which in turn pass more current, which produces more heat). In addition, the insulating oxide of silicon is not soluble in water, which gives it an advantage over germanium (an element with similar properties which can also be used in semiconductor devices) in certain fabrication techniques.[103]

Monocrystalline silicon is expensive to produce, and is usually justified only in production of integrated circuits, where tiny crystal imperfections can interfere with tiny circuit paths. For other uses, other types of pure silicon may be employed. These include hydrogenated amorphous silicon and upgraded metallurgical-grade silicon (UMG-Si) used in the production of low-cost, large-area electronics in applications such as liquid crystal displays and of large-area, low-cost, thin-film solar cells. Such semiconductor grades of silicon are either slightly less pure or polycrystalline rather than monocrystalline, and are produced in comparable quantities as the monocrystalline silicon: 75,000 to 150,000 metric tons per year. The market for the lesser grade is growing more quickly than for monocrystalline silicon. By 2013, polycrystalline silicon production, used mostly in solar cells, was projected to reach 200,000 metric tons per year, while monocrystalline semiconductor grade silicon was expected to remain less than 50,000 tons per year.[97]
$
10
Question: What is the typical purity level of monocrystalline silicon used in semiconductor wafers?
A: 99.9999999%
B: 99.9%
C: 99%
D: 95%
E: 90%
Answer: A

Question: Which process is commonly used to produce monocrystalline silicon for semiconductor wafers?
A: Aluminothermal process
B: Czochralski process
C: Carbothermal reduction
D: Zone refining process
E: Fractional distillation process
Answer: B

Question: Why is pure silicon doped with small concentrations of other elements in semiconductor applications?
A: To reduce its electrical conductivity
B: To make it more brittle
C: To decrease its resistivity
D: To adjust its electrical response
E: To make it magnetic
Answer: D

Question: In which industry is monocrystalline silicon mainly used?
A: Automotive manufacturing
B: Aerospace
C: Semiconductor and electronics
D: Construction
E: Textiles
Answer: C

Question: What is the primary purpose of the insulating oxide of silicon in integrated circuits?
A: To enhance electrical conductivity
B: To make silicon soluble in water
C: To reduce the cost of production
D: To insulate and separate circuit components
E: To increase the heat resistance of silicon
Answer: D

Question: Why is monocrystalline silicon preferred for integrated circuits despite its higher cost?
A: It has better heat resistance.
B: It can withstand higher temperatures.
C: It has fewer imperfections.
D: It is less brittle.
E: It is less conductive.
Answer: C

Question: What type of silicon is used in the production of low-cost, large-area electronics and thin-film solar cells?
A: Monocrystalline silicon
B: Hydrogenated amorphous silicon
C: Silicon dioxide
D: Upgraded metallurgical-grade silicon
E: Polycrystalline silicon
Answer: B

Question: What is the expected production quantity of polycrystalline silicon used in solar cells by 2013?
A: Less than 50,000 metric tons per year
B: 75,000 metric tons per year
C: 150,000 metric tons per year
D: 200,000 metric tons per year
E: 500,000 metric tons per year
Answer: D

Question: Which element can also be used in semiconductor devices but is less favored than silicon due to certain fabrication techniques?
A: Carbon
B: Aluminum
C: Germanium
D: Oxygen
E: Hydrogen
Answer: C

Question: What property of silicon makes it preferable to germanium for certain fabrication techniques?
A: Solubility in water
B: Lower electrical activity
C: Avalanche breakdown resistance
D: Higher cost
E: Higher melting point
Answer: C
@
Device yield or die yield is the number of working chips or dies on a wafer, given in percentage since the number of chips on a wafer (Die per wafer, DPW) can vary depending on the chips' size and the wafer's diameter. Yield degradation is a reduction in yield, which historically was mainly caused by dust particles, however since the 1990s, yield degradation is mainly caused by process variation, the process itself and by the tools used in chip manufacturing, although dust still remains a problem in many older fabs. Dust particles have an increasing effect on yield as feature sizes are shrunk with newer processes. Automation and the use of mini environments inside of production equipment, FOUPs and SMIFs have enabled a reduction in defects caused by dust particles. Device yield must be kept high to reduce the selling price of the working chips since working chips have to pay for those chips that failed, and to reduce the cost of wafer processing. Yield can also be affected by the design and operation of the fab.

Tight control over contaminants and the production process are necessary to increase yield. Contaminants may be chemical contaminants or be dust particles. "Killer defects" are those caused by dust particles that cause complete failure of the device (such as a transistor). There are also harmless defects. A particle needs to be 1/5 the size of a feature to cause a killer defect. So if a feature is 100 nm across, a particle only needs to be 20 nm across to cause a killer defect. Electrostatic electricity can also affect yield adversely. Chemical contaminants or impurities include heavy metals such as iron, copper, nickel, zinc, chromium, gold, mercury and silver, alkali metals such as sodium, potassium and lithium, and elements such as aluminum, magnesium, calcium, chlorine, sulfur, carbon, and fluorine. It is important for these elements to not remain in contact with the silicon, as they could reduce yield. Chemical mixtures may be used to remove these elements from the silicon; different mixtures are effective against different elements.

Several models are used to estimate yield. They are Murphy's model, Poisson's model, the binomial model, Moore's model and Seeds' model. There is no universal model; a model has to be chosen based on actual yield distribution (the location of defective chips) For example, Murphy's model assumes that yield loss occurs more at the edges of the wafer (non-working chips are concentrated on the edges of the wafer), Poisson's model assumes that defective dies are spread relatively evenly across the wafer, and Seeds's model assumes that defective dies are clustered together.[41]

Smaller dies cost less to produce (since more fit on a wafer, and wafers are processed and priced as a whole), and can help achieve higher yields since smaller dies have a lower chance of having a defect, due to their lower surface area on the wafer. However, smaller dies require smaller features to achieve the same functions of larger dies or surpass them, and smaller features require reduced process variation and increased purity (reduced contamination) to maintain high yields. Metrology tools are used to inspect the wafers during the production process and predict yield, so wafers predicted to have too many defects may be scrapped to save on processing costs.[39]
$
10
Question: What is device yield, and how is it typically expressed?
A: Device yield is the number of working chips or dies on a wafer, expressed as a percentage.
B: Device yield is the number of wafers produced per hour.
C: Device yield is the total number of defects on a wafer.
D: Device yield is the total cost of wafer processing.
E: Device yield is the average size of semiconductor chips.

Answer: A

Question: What is the main cause of yield degradation in chip manufacturing since the 1990s?
A: Dust particles
B: Chemical contamination
C: Automation
D: Process variation
E: Mini environments

Answer: D

Question: What is a "killer defect" in semiconductor manufacturing?
A: A defect that causes a minor issue in a device.
B: A defect that increases yield.
C: A defect caused by electrostatic electricity.
D: A defect caused by dust particles that leads to complete device failure.
E: A harmless defect.

Answer: D

Question: How small does a dust particle need to be in relation to a feature to cause a "killer defect"?
A: Half the size of the feature
B: One-quarter the size of the feature
C: One-fifth the size of the feature
D: One-tenth the size of the feature
E: Equal to the size of the feature

Answer: C

Question: Which elements are considered chemical contaminants or impurities in semiconductor manufacturing?
A: Only heavy metals
B: Only alkali metals
C: Only elements such as aluminum, magnesium, and calcium
D: Both heavy metals and alkali metals
E: Only elements such as chlorine, sulfur, carbon, and fluorine

Answer: D

Question: What is the purpose of chemical mixtures in semiconductor manufacturing?
A: To increase the size of features on semiconductor chips.
B: To reduce process variation.
C: To remove chemical contaminants or impurities from silicon.
D: To predict yield distribution.
E: To reduce the cost of wafer processing.

Answer: C

Question: What are some of the models used to estimate yield in semiconductor manufacturing?
A: Poisson's model and the binomial model
B: Only Moore's model
C: Only Murphy's model
D: Only Seeds' model
E: Only Poisson's model

Answer: A

Question: How does the size of semiconductor dies on a wafer affect yield?
A: Smaller dies result in higher yield.
B: Smaller dies have a higher chance of defects.
C: Smaller dies are not used in semiconductor manufacturing.
D: Larger dies cost less to produce.
E: Smaller dies do not affect yield.

Answer: A

Question: What role do metrology tools play in semiconductor manufacturing?
A: They predict yield distribution.
B: They increase the cost of wafer processing.
C: They inspect wafers and predict yield during the production process.
D: They reduce the purity of semiconductor materials.
E: They are used to manufacture mini environments.

Answer: C

Question: What is the primary factor determining the choice of a yield estimation model?
A: The age of the semiconductor manufacturing equipment
B: The location of defective chips on the wafer
C: The size of the semiconductor dies
D: The cost of wafer processing
E: The purity of the semiconductor materials

Answer: B
@
Wafer fabrication is a procedure composed of many repeated sequential processes to produce complete electrical or photonic circuits on semiconductor wafers in semiconductor device fabrication process. Examples include production of radio frequency (RF) amplifiers, LEDs, optical computer components, and microprocessors for computers. Wafer fabrication is used to build components with the necessary electrical structures.

The main process begins with electrical engineers designing the circuit and defining its functions, and specifying the signals, inputs/outputs and voltages needed. These electrical circuit specifications are entered into electrical circuit design software, such as SPICE, and then imported into circuit layout programs, which are similar to ones used for computer aided design. This is necessary for the layers to be defined for photomask production. The resolution of the circuits increases rapidly with each step in design, as the scale of the circuits at the start of the design process is already being measured in fractions of micrometers. Each step thus increases circuit density for a given area.

The silicon wafers start out blank and pure. The circuits are built in layers in clean rooms. First, photoresist patterns are photo-masked in micrometer detail onto the wafers' surface. The wafers are then exposed to short-wave ultraviolet light and the unexposed areas are thus etched away and cleaned. Hot chemical vapors are deposited on to the desired zones and baked in high heat, which permeate the vapors into the desired zones. In some cases, ions, such as O2+ or O+, are implanted in precise patterns and at a specific depth by using RF-driven ion sources.

These steps are often repeated many hundreds of times, depending on the complexity of the desired circuit and its connections.
$
10
Question: What is the primary goal of wafer fabrication?
A: To design electrical circuits
B: To produce complete electrical or photonic circuits on semiconductor wafers
C: To create computer aided design software
D: To increase circuit density
E: To manufacture blank and pure silicon wafers

Answer: B

Question: What is the initial step in the wafer fabrication process?
A: Electrical circuit design
B: Importing circuit specifications into software
C: Ultraviolet light exposure
D: Implanting ions
E: Producing photoresist patterns

Answer: A

Question: How are circuit patterns transferred onto silicon wafers during wafer fabrication?
A: By baking the wafers in high heat
B: By implanting ions
C: By exposing the wafers to ultraviolet light
D: By using electrical circuit design software
E: By cleaning the wafers with chemical vapors

Answer: C

Question: What is the purpose of hot chemical vapors in the wafer fabrication process?
A: To etch away unexposed areas
B: To produce photoresist patterns
C: To increase circuit density
D: To implant ions into the wafers
E: To design electrical circuits

Answer: A

Question: Which of the following is NOT a step in the wafer fabrication process?
A: Importing circuit specifications into software
B: Implanting ions
C: Baking wafers in high heat
D: Creating photoresist patterns
E: Designing electrical circuits

Answer: E

Question: What happens to unexposed areas of silicon wafers during the wafer fabrication process?
A: They are etched away and cleaned.
B: They are implanted with ions.
C: They are exposed to ultraviolet light.
D: They are baked in high heat.
E: They are used to define photomasks.

Answer: A

Question: What is the purpose of RF-driven ion sources in wafer fabrication?
A: To bake wafers in high heat
B: To create photoresist patterns
C: To increase circuit density
D: To implant ions in precise patterns and at specific depths
E: To define photomasks

Answer: D

Question: What determines the complexity of the desired circuit in the wafer fabrication process?
A: The number of clean rooms used
B: The use of computer aided design software
C: The number of RF-driven ion sources employed
D: The scale of the circuits at the start of the design process
E: The temperature of the high heat used

Answer: D

Question: What is the purpose of repeating certain steps in wafer fabrication?
A: To decrease circuit density
B: To reduce the resolution of the circuits
C: To create blank and pure silicon wafers
D: To increase circuit density for a given area
E: To design electrical circuits

Answer: D

Question: What are the final results of wafer fabrication?
A: Blank and pure silicon wafers
B: Computer aided design software
C: Clean rooms for circuit production
D: Photomasks for ultraviolet exposure
E: Complete electrical or photonic circuits on semiconductor wafers

Answer: E
@
Moore's law is the observation that the number of transistors in an integrated circuit (IC) doubles about every two years. Moore's law is an observation and projection of a historical trend. Rather than a law of physics, it is an empirical relationship linked to gains from experience in production.

The observation is named after Gordon Moore, the co-founder of Fairchild Semiconductor and Intel (and former CEO of the latter), who in 1965 posited a doubling every year in the number of components per integrated circuit,[a] and projected this rate of growth would continue for at least another decade. In 1975, looking forward to the next decade, he revised the forecast to doubling every two years, a compound annual growth rate (CAGR) of 41%. While Moore did not use empirical evidence in forecasting that the historical trend would continue, his prediction held since 1975 and has since become known as a "law".

Moore's prediction has been used in the semiconductor industry to guide long-term planning and to set targets for research and development, thus functioning to some extent as a self-fulfilling prophecy. Advancements in digital electronics, such as the reduction in quality-adjusted microprocessor prices, the increase in memory capacity (RAM and flash), the improvement of sensors, and even the number and size of pixels in digital cameras, are strongly linked to Moore's law. These ongoing changes in digital electronics have been a driving force of technological and social change, productivity, and economic growth.
$
10

Question: Who is credited with the observation known as Moore's law?
A: Gordon Moore
B: Gordon Ramsay
C: Gordon Brown
D: Gordon Freeman
E: Gordon Hayward

Answer: A

Question: What is the timeframe for the doubling of transistors in an integrated circuit according to Moore's law?
A: Every year
B: Every three years
C: Every four years
D: Every two years
E: Every five years

Answer: D

Question: What kind of relationship is Moore's law?
A: A law of physics
B: An empirical relationship
C: A mathematical equation
D: A philosophical theory
E: A social contract

Answer: B

Question: In what year did Gordon Moore originally posited the doubling of components per integrated circuit?
A: 1950
B: 1965
C: 1975
D: 1985
E: 1995

Answer: B

Question: What compound annual growth rate (CAGR) did Gordon Moore predict for the doubling of components in integrated circuits?
A: 10%
B: 20%
C: 30%
D: 40%
E: 50%

Answer: D

Question: How often did Gordon Moore revise his forecast for the doubling of components in integrated circuits?
A: Every year
B: Every two years
C: Every five years
D: Every decade
E: He never revised it

Answer: D

Question: How has Moore's law impacted advancements in digital electronics?
A: It has slowed down digital electronics advancements.
B: It has had no impact on digital electronics.
C: It has led to a decrease in memory capacity.
D: It has driven advancements in digital electronics.
E: It has only affected analog electronics.

Answer: D

Question: What industry has used Moore's law for long-term planning and research and development targets?
A: Agriculture
B: Automobile manufacturing
C: Semiconductor industry
D: Textile industry
E: Food service

Answer: C

Question: What has been strongly linked to Moore's law and its impact on digital electronics?
A: Decreased microprocessor prices
B: Reduced memory capacity
C: Fewer sensors in devices
D: Smaller camera pixels
E: Slower technological change

Answer: A

Question: What kind of growth has Moore's law been a driving force for?
A: Economic growth
B: Population growth
C: Environmental degradation
D: Political stability
E: Technological regression

Answer: A
@
Flash memory is an electronic non-volatile computer memory storage medium that can be electrically erased and reprogrammed. The two main types of flash memory, NOR flash and NAND flash, are named for the NOR and NAND logic gates. Both use the same cell design, consisting of floating gate MOSFETs. They differ at the circuit level depending on whether the state of the bit line or word lines is pulled high or low: in NAND flash, the relationship between the bit line and the word lines resembles a NAND gate; in NOR flash, it resembles a NOR gate.

Flash memory, a type of floating-gate memory, was invented at Toshiba in 1980 and is based on EEPROM technology. Toshiba began marketing flash memory in 1987.[1] EPROMs had to be erased completely before they could be rewritten. NAND flash memory, however, may be erased, written, and read in blocks (or pages), which generally are much smaller than the entire device. NOR flash memory allows a single machine word to be written – to an erased location – or read independently. A flash memory device typically consists of one or more flash memory chips (each holding many flash memory cells), along with a separate flash memory controller chip.

The NAND type is found mainly in memory cards, USB flash drives, solid-state drives (those produced since 2009), feature phones, smartphones, and similar products, for general storage and transfer of data. NAND or NOR flash memory is also often used to store configuration data in digital products, a task previously made possible by EEPROM or battery-powered static RAM. A key disadvantage of flash memory is that it can endure only a relatively small number of write cycles in a specific block.[2]
$
10
Question: What is the main difference between NOR flash and NAND flash at the circuit level?
A: NOR flash uses floating gate MOSFETs, while NAND flash uses static RAM.
B: NOR flash has a higher storage capacity than NAND flash.
C: NOR flash resembles a NAND gate circuit, while NAND flash resembles a NOR gate circuit.
D: NOR flash can be electrically erased and reprogrammed, while NAND flash cannot.
E: NOR flash is a newer technology than NAND flash.

Answer: C

Question: When was flash memory invented at Toshiba?
A: 1960
B: 1970
C: 1980
D: 1990
E: 2000

Answer: C

Question: How do EPROMs differ from NAND flash memory in terms of erasure and rewriting?
A: EPROMs can be erased and rewritten in blocks, while NAND flash can only be erased entirely.
B: EPROMs cannot be erased or rewritten, while NAND flash can be erased, written, and read in blocks.
C: EPROMs can only be erased and rewritten using specialized equipment, while NAND flash can be done more easily.
D: EPROMs and NAND flash memory have the same erasure and rewriting capabilities.
E: EPROMs are faster at erasing and rewriting than NAND flash.

Answer: B

Question: What is the function of a flash memory controller chip in a flash memory device?
A: It stores configuration data.
B: It manages the bit line and word lines.
C: It provides power to the flash memory cells.
D: It performs encryption on the stored data.
E: It increases the number of write cycles in a specific block.

Answer: A

Question: In which types of products is NAND flash memory mainly found?
A: Desktop computers
B: Washing machines
C: Feature phones, smartphones, and USB flash drives
D: Vacuum cleaners
E: Microwave ovens

Answer: C

Question: What is a key disadvantage of flash memory?
A: It is too expensive.
B: It is not electrically erasable.
C: It has a limited number of write cycles in a specific block.
D: It requires a lot of power to operate.
E: It is slower than traditional hard drives.

Answer: C

Question: What are the two main types of flash memory based on logic gates?
A: AND flash and XOR flash
B: NOR flash and NAND flash
C: OR flash and NOT flash
D: XOR flash and NOR flash
E: AND flash and OR flash

Answer: B

Question: What is the typical use of NOR flash memory?
A: General storage and transfer of data in smartphones
B: Storing configuration data in digital products
C: Storing data in solid-state drives
D: Reading independently in memory cards
E: Erasing and rewriting entire blocks of data

Answer: B

Question: How is NAND flash memory different from NOR flash memory in terms of writing data?
A: NAND flash allows a single machine word to be written, while NOR flash writes in blocks.
B: NAND flash cannot write data independently.
C: NOR flash writes data in a page-by-page manner.
D: NAND flash and NOR flash have the same data writing method.
E: NAND flash writes data in a single operation.

Answer: A

Question: What was flash memory based on in terms of technology?
A: EEPROM technology
B: Vacuum tube technology
C: CRT technology
D: Transistor technology
E: Magnetic tape technology

Answer: A
@
A solid-state drive (SSD) is a solid-state storage device that uses integrated circuit assemblies to store data persistently, typically using flash memory, and functioning as secondary storage in the hierarchy of computer storage.[1] It is also sometimes called a semiconductor storage device, a solid-state device or a solid-state disk,[2] even though SSDs lack the physical spinning disks and movable read–write heads used in hard disk drives (HDDs) and floppy disks.[3] SSD also has rich internal parallelism for data processing.[4]

In comparison to hard disk drives and similar electromechanical media which use moving parts, SSDs are typically more resistant to physical shock, run silently, and have higher input/output rates and lower latency.[5] SSDs store data in semiconductor cells. As of 2019, cells can contain between 1 and 4 bits of data. SSD storage devices vary in their properties according to the number of bits stored in each cell, with single-bit cells ("Single Level Cells" or "SLC") being generally the most reliable, durable, fast, and expensive type, compared with 2- and 3-bit cells ("Multi-Level Cells/MLC" and "Triple-Level Cells/TLC"), and finally, quad-bit cells ("QLC") being used for consumer devices that do not require such extreme properties and are the cheapest per gigabyte (GB) of the four. In addition, 3D XPoint memory (sold by Intel under the Optane brand) stores data by changing the electrical resistance of cells instead of storing electrical charges in cells, and SSDs made from RAM can be used for high speed, when data persistence after power loss is not required, or may use battery power to retain data when its usual power source is unavailable.[6] Hybrid drives or solid-state hybrid drives (SSHDs), such as Intel's Hystor[7] and Apple's Fusion Drive, combine features of SSDs and HDDs in the same unit using both flash memory and spinning magnetic disks in order to improve the performance of frequently-accessed data.[8][9][10] Bcache achieves a similar effect purely in software, using combinations of dedicated regular SSDs and HDDs.

SSDs based on NAND flash will slowly leak charge over time if left for long periods without power. This causes worn-out drives (that have exceeded their endurance rating) to start losing data typically after one year (if stored at 30 °C) to two years (at 25 °C) in storage; for new drives it takes longer.[11] Therefore, SSDs are not suitable for archival storage. 3D XPoint is a possible exception to this rule; it is a relatively new technology with unknown long-term data-retention characteristics.
$
10
Question: What type of storage device uses integrated circuit assemblies to store data persistently?
A: Hard disk drive
B: Solid-state drive (SSD)
C: Floppy disk
D: CD-ROM
E: Magnetic tape

Answer: B

Question: How do SSDs differ from HDDs in terms of physical components?
A: SSDs have physical spinning disks and movable read-write heads, while HDDs do not.
B: SSDs use moving parts like HDDs.
C: SSDs use NAND flash memory, while HDDs use electromechanical media.
D: SSDs have higher latency than HDDs.
E: SSDs make more noise than HDDs.

Answer: C

Question: Which type of SSD cell is generally considered the most reliable and durable?
A: Multi-Level Cells (MLC)
B: Triple-Level Cells (TLC)
C: Quad-bit cells (QLC)
D: Single Level Cells (SLC)
E: 3D XPoint cells

Answer: D

Question: What is the primary advantage of SSDs over HDDs regarding physical characteristics?
A: SSDs are cheaper than HDDs.
B: SSDs have a longer lifespan.
C: SSDs are more resistant to physical shock.
D: SSDs make less noise than HDDs.
E: SSDs have higher latency than HDDs.

Answer: C

Question: What technology stores data by changing the electrical resistance of cells in SSDs?
A: NAND flash memory
B: 3D XPoint memory
C: RAM-based SSDs
D: HDD technology
E: CD-ROM technology

Answer: B

Question: In what circumstances might SSDs based on NAND flash slowly leak charge over time?
A: When left unplugged for long periods of time
B: When used regularly for data storage
C: When exposed to extreme temperatures
D: When connected to a power source
E: When subjected to physical shock

Answer: A

Question: Which type of SSD cells is the cheapest per gigabyte (GB)?
A: Multi-Level Cells (MLC)
B: Triple-Level Cells (TLC)
C: Quad-bit cells (QLC)
D: Single Level Cells (SLC)
E: 3D XPoint cells

Answer: C

Question: What type of drives combine features of SSDs and HDDs in the same unit to improve performance for frequently-accessed data?
A: RAM-based SSDs
B: 3D XPoint drives
C: Solid-state hybrid drives (SSHDs)
D: CD-ROM drives
E: Floppy disk drives

Answer: C

Question: Why are SSDs not suitable for archival storage?
A: They are too expensive.
B: They have a shorter lifespan than HDDs.
C: They are noisy.
D: They are prone to physical shock.
E: They leak charge over time if left without power.

Answer: E

Question: What is the technology that stores data by storing electrical charges in cells?
A: RAM-based SSDs
B: HDD technology
C: CD-ROM technology
D: NAND flash memory
E: 3D XPoint memory

Answer: D
@
A semiconductor & chip is the same. A semiconductor is a material which has an electrical conductivity value falling between that of a conductor, such as copper, and an insulator, such as glass. Its resistivity falls as its temperature rises; metals behave in the opposite way. Its conducting properties may be altered in useful ways by introducing impurities ("doping") into the crystal structure. When two differently doped regions exist in the same crystal, a semiconductor junction is created. The behavior of charge carriers, which include electrons, ions, and electron holes, at these junctions is the basis of diodes, transistors, and most modern electronics. Some examples of semiconductors are silicon, germanium, gallium arsenide, and elements near the so-called "metalloid staircase" on the periodic table. After silicon, gallium arsenide is the second-most common semiconductor and is used in laser diodes, solar cells, microwave-frequency integrated circuits, and others. Silicon is a critical element for fabricating most electronic circuits.

Semiconductor devices can display a range of different useful properties, such as passing current more easily in one direction than the other, showing variable resistance, and having sensitivity to light or heat. Because the electrical properties of a semiconductor material can be modified by doping and by the application of electrical fields or light, devices made from semiconductors can be used for amplification, switching, and energy conversion.

The conductivity of silicon is increased by adding a small amount (of the order of 1 in 108) of pentavalent (antimony, phosphorus, or arsenic) or trivalent (boron, gallium, indium) atoms. This process is known as doping, and the resulting semiconductors are known as doped or extrinsic semiconductors. Apart from doping, the conductivity of a semiconductor can be improved by increasing its temperature. This is contrary to the behavior of a metal, in which conductivity decreases with an increase in temperature.
$
10
Question: What is the key characteristic of a semiconductor material?
A: It has a fixed electrical conductivity.
B: Its resistivity decreases with rising temperature.
C: It behaves the same way as metals in terms of conductivity.
D: It cannot have its conducting properties altered.
E: It is an insulator.

Answer: B

Question: What is the effect of introducing impurities (doping) into the crystal structure of a semiconductor?
A: It reduces its resistivity.
B: It increases its resistivity.
C: It makes it behave like a metal.
D: It decreases its temperature sensitivity.
E: It turns it into an insulator.

Answer: A

Question: What kind of junction is created when two differently doped regions exist in the same semiconductor crystal?
A: Insulator junction
B: Metal junction
C: Semiconductor junction
D: Doped junction
E: Conductor junction

Answer: C

Question: Which semiconductor material is the second-most common after silicon and is used in laser diodes, solar cells, and microwave-frequency integrated circuits?
A: Germanium
B: Gallium arsenide
C: Antimony
D: Phosphorus
E: Boron

Answer: B

Question: How can the electrical properties of a semiconductor material be modified?
A: By heating it to a high temperature
B: By reducing its temperature
C: By applying an electrical field or light
D: By introducing metals into its crystal structure
E: By using it in its natural state

Answer: C

Question: What is the term for semiconductors that have had impurities introduced into their crystal structure to modify their conductivity?
A: Intrinsic semiconductors
B: Natural semiconductors
C: Doped semiconductors
D: Conductor semiconductors
E: Insulator semiconductors

Answer: C

Question: How does the conductivity of a semiconductor change with an increase in temperature?
A: It remains constant.
B: It decreases.
C: It becomes an insulator.
D: It increases.
E: It becomes a metal.

Answer: D

Question: What is the primary use of gallium arsenide, the second-most common semiconductor material after silicon?
A: Lighting
B: Plumbing
C: Solar cells
D: Cooking
E: Transportation

Answer: C

Question: What property of a semiconductor allows it to be used for amplification, switching, and energy conversion in electronic devices?
A: Variable resistance
B: High-temperature conductivity
C: Light sensitivity
D: Temperature sensitivity
E: Crystal structure

Answer: A

Question: In contrast to a metal, how does the conductivity of a semiconductor change with an increase in temperature?
A: It remains constant.
B: It decreases.
C: It becomes an insulator.
D: It increases.
E: It becomes a superconductor.

Answer: D
@
An electrical insulator is a material in which electric current does not flow freely. The atoms of the insulator have tightly bound electrons which cannot readily move. Other materials—semiconductors and conductors—conduct electric current more easily. The property that distinguishes an insulator is its resistivity; insulators have higher resistivity than semiconductors or conductors. The most common examples are non-metals.

A perfect insulator does not exist because even insulators contain small numbers of mobile charges (charge carriers) which can carry current. In addition, all insulators become electrically conductive when a sufficiently large voltage is applied that the electric field tears electrons away from the atoms. This is known as electrical breakdown, and the voltage at which it occurs is called the breakdown voltage of an insulator. Some materials such as glass, paper and PTFE, which have high resistivity, are very good electrical insulators. A much larger class of materials, even though they may have lower bulk resistivity, are still good enough to prevent significant current from flowing at normally used voltages, and thus are employed as insulation for electrical wiring and cables. Examples include rubber-like polymers and most plastics which can be thermoset or thermoplastic in nature.

Insulators are used in electrical equipment to support and separate electrical conductors without allowing current through themselves. An insulating material used in bulk to wrap electrical cables or other equipment is called insulation. The term insulator is also used more specifically to refer to insulating supports used to attach electric power distribution or transmission lines to utility poles and transmission towers. They support the weight of the suspended wires without allowing the current to flow through the tower to ground.
$
10
Question: What distinguishes an insulator from other materials like semiconductors and conductors?
A: Atomic composition
B: Resistivity
C: Mobile charges
D: Breakdown voltage
E: Conductivity

Answer: B

Question: Why doesn't a perfect insulator exist?
A: It has low resistivity.
B: It contains no mobile charges.
C: It doesn't conduct electric current.
D: It lacks tightly bound electrons.
E: It can withstand any voltage.

Answer: C

Question: What happens to insulators when a sufficiently large voltage is applied?
A: They become conductors.
B: They resist the voltage.
C: They lower their resistivity.
D: They lose their atomic composition.
E: They increase their breakdown voltage.

Answer: A

Question: Which materials, due to their high resistivity, are considered very good electrical insulators?
A: Semiconductors
B: Metals
C: Plastics
D: Conductors
E: Superconductors

Answer: C

Question: How are insulators used in electrical equipment?
A: To enhance current flow
B: To replace conductors
C: To connect electrical wires
D: To support and separate conductors
E: To increase resistivity

Answer: D

Question: What term is used to describe insulating supports used to attach electric power distribution or transmission lines to utility poles and transmission towers?
A: Electrical conductors
B: Insulating materials
C: Insulation
D: Breakdown voltage
E: Insulator supports

Answer: E

Question: What is the property that distinguishes an insulator from semiconductors and conductors?
A: Atomic arrangement
B: Breakdown voltage
C: Resistivity
D: Mobile charges
E: Voltage resistance

Answer: C

Question: When does electrical breakdown occur in an insulator?
A: When it has high resistivity
B: When it contains no mobile charges
C: When it becomes a perfect insulator
D: When a sufficiently large voltage is applied
E: When it reaches its breakdown voltage

Answer: D

Question: Which materials are commonly used for insulation in electrical wiring and cables?
A: Conductors
B: Semiconductors
C: Plastics
D: Metals
E: Superconductors

Answer: C

Question: What do insulators used in electrical equipment do?
A: Allow current to flow through themselves
B: Enhance the conductivity of conductors
C: Connect electrical conductors
D: Prevent current from flowing through themselves
E: Increase atomic composition

Answer: D
@
An electric current is a flow of charged particles, such as electrons or ions, moving through an electrical conductor or space. It is defined as the net rate of flow of electric charge through a surface.[1]: 2 [2]: 622  The moving particles are called charge carriers, which may be one of several types of particles, depending on the conductor. In electric circuits the charge carriers are often electrons moving through a wire. In semiconductors they can be electrons or holes. In an electrolyte the charge carriers are ions, while in plasma, an ionized gas, they are ions and electrons.[3]

The SI unit of electric current is the ampere, or amp, which is the flow of electric charge across a surface at the rate of one coulomb per second. The ampere (symbol: A) is an SI base unit.[4]: 15  Electric current is measured using a device called an ammeter.[2]: 788 

Electric currents create magnetic fields, which are used in motors, generators, inductors, and transformers. In ordinary conductors, they cause Joule heating, which creates light in incandescent light bulbs. Time-varying currents emit electromagnetic waves, which are used in telecommunications to broadcast information.

Symbol
The conventional symbol for current is I, which originates from the French phrase intensité du courant, (current intensity).[5][6] Current intensity is often referred to simply as current.[7] The I symbol was used by André-Marie Ampère, after whom the unit of electric current is named, in formulating Ampère's force law (1820).[8] The notation travelled from France to Great Britain, where it became standard, although at least one journal did not change from using C to I until 1896.[9]
$
10
Question: What is the SI unit of electric current?
A: Watt
B: Joule
C: Ampere
D: Volt
E: Ohm
Answer: C

Question: What term is used for the particles that carry electric charge in electric circuits?
A: Electromagnets
B: Electrons
C: Protons
D: Neutrons
E: Photons
Answer: B

Question: In which type of conductor are the charge carriers often electrons moving through a wire?
A: Semiconductors
B: Insulators
C: Superconductors
D: Electrolytes
E: Ordinary conductors
Answer: E

Question: What is the name of the device used to measure electric current?
A: Voltmeter
B: Ohmmeter
C: Ammeter
D: Multimeter
E: Capacitor
Answer: C

Question: What do electric currents create, which is used in motors, generators, and transformers?
A: Magnetic fields
B: Radio waves
C: Heat
D: Electromagnetic waves
E: Electric fields
Answer: A

Question: What phenomenon is responsible for creating light in incandescent light bulbs when electric currents flow through ordinary conductors?
A: Electromagnetic radiation
B: Joule heating
C: Magnetism
D: Voltage
E: Electric fields
Answer: B

Question: What type of particles are charge carriers in an electrolyte?
A: Electrons
B: Holes
C: Photons
D: Ions
E: Protons
Answer: D

Question: Which unit of electric current originates from the French phrase "intensité du courant"?
A: Joule
B: Volt
C: Ampere
D: Ohm
E: Watt
Answer: C

Question: Who used the symbol "I" to represent current intensity in formulating Ampère's force law?
A: André-Marie Ampère
B: James Clerk Maxwell
C: Michael Faraday
D: Alessandro Volta
E: Nikola Tesla
Answer: A

Question: In which country did the symbol "I" for electric current become standard?
A: France
B: Great Britain
C: Germany
D: United States
E: Russia
Answer: B
@
Alternating current (AC) is an electric current which periodically reverses direction and changes its magnitude continuously with time, in contrast to direct current (DC), which flows only in one direction. Alternating current is the form in which electric power is delivered to businesses and residences, and it is the form of electrical energy that consumers typically use when they plug kitchen appliances, televisions, fans and electric lamps into a wall socket. A common source of DC power is a battery cell in a flashlight. The abbreviations AC and DC are often used to mean simply alternating and direct, respectively, as when they modify current or voltage.[1][2]

The usual waveform of alternating current in most electric power circuits is a sine wave, whose positive half-period corresponds with positive direction of the current and vice versa (the full period is called a cycle). In certain applications, like guitar amplifiers, different waveforms are used, such as triangular waves or square waves. Audio and radio signals carried on electrical wires are also examples of alternating current. These types of alternating current carry information such as sound (audio) or images (video) sometimes carried by modulation of an AC carrier signal. These currents typically alternate at higher frequencies than those used in power transmission.

Electrical energy is distributed as alternating current because AC voltage may be increased or decreased with a transformer. This allows the power to be transmitted through power lines efficiently at high voltage, which reduces the energy lost as heat due to resistance of the wire, and transformed to a lower, safer voltage for use. Use of a higher voltage leads to significantly more efficient transmission of power. The power losses (
�
w
{\displaystyle P_{\rm {w}}}) in the wire are a product of the square of the current ( I ) and the resistance (R) of the wire, described by the formula:

�
w
=
�
2
�
.
{\displaystyle P_{\rm {w}}=I^{2}R\,.}
This means that when transmitting a fixed power on a given wire, if the current is halved (i.e. the voltage is doubled), the power loss due to the wire's resistance will be reduced to one quarter.

The power transmitted is equal to the product of the current and the voltage (assuming no phase difference); that is,

�
t
=
�
�
.
{\displaystyle P_{\rm {t}}=IV\,.}
Consequently, power transmitted at a higher voltage requires less loss-producing current than for the same power at a lower voltage. Power is often transmitted at hundreds of kilovolts on pylons, and transformed down to tens of kilovolts to be transmitted on lower level lines, and finally transformed down to 100 V – 240 V for domestic use.
$
10
Question: What is the usual waveform of alternating current in most electric power circuits?
A: Triangular wave
B: Square wave
C: Sine wave
D: Sawtooth wave
E: Rectangular wave
Answer: C

Question: What type of electrical energy is typically used when consumers plug kitchen appliances into a wall socket?
A: Direct current (DC)
B: Triangular current (TC)
C: Square current (SC)
D: Alternating current (AC)
E: Sine current (SiC)
Answer: D

Question: In what form is electrical energy distributed to businesses and residences?
A: Direct current (DC)
B: Alternating current (AC)
C: Triangular current (TC)
D: Square current (SC)
E: Sine current (SiC)
Answer: B

Question: What is the primary source of DC power mentioned in the text?
A: Wall socket
B: Electric lamp
C: Battery cell
D: Power lines
E: Guitar amplifier
Answer: C

Question: Why is electrical energy distributed as alternating current (AC)?
A: AC is safer to use.
B: AC is easier to generate.
C: AC is more efficient for power transmission.
D: AC is cheaper to produce.
E: AC is less prone to voltage fluctuations.
Answer: C

Question: What is the formula used to describe the power losses in a wire due to resistance?
A: P_loss = I / R
B: P_loss = I * R
C: P_loss = I^2 * R
D: P_loss = I + R
E: P_loss = I - R
Answer: C

Question: What happens to power loss when the voltage is doubled while transmitting the same power on a wire?
A: It remains the same.
B: It is reduced by half.
C: It is reduced to one-quarter.
D: It is doubled.
E: It increases by four times.
Answer: C

Question: What is the product of current and voltage equal to?
A: Power loss
B: Resistance
C: Power transmitted
D: Transformer efficiency
E: Electrical capacitance
Answer: C

Question: At what voltage level is power often transmitted on pylons?
A: Hundreds of volts
B: Tens of volts
C: Thousands of volts
D: Millivolts
E: Volts
Answer: C

Question: What voltage level is typically used for domestic use after transforming?
A: 1 V - 5 V
B: 10 V - 50 V
C: 100 V - 240 V
D: 500 V - 1000 V
E: 10,000 V - 20,000 V
Answer: C
@
Direct current (DC) is one-directional flow of electric charge. An electrochemical cell is a prime example of DC power. Direct current may flow through a conductor such as a wire, but can also flow through semiconductors, insulators, or even through a vacuum as in electron or ion beams. The electric current flows in a constant direction, distinguishing it from alternating current (AC). A term formerly used for this type of current was galvanic current.[1]

The abbreviations AC and DC are often used to mean simply alternating and direct, as when they modify current or voltage.[2][3]

Direct current may be converted from an alternating current supply by use of a rectifier, which contains electronic elements (usually) or electromechanical elements (historically) that allow current to flow only in one direction. Direct current may be converted into alternating current via an inverter.

Direct current has many uses, from the charging of batteries to large power supplies for electronic systems, motors, and more. Very large quantities of electrical energy provided via direct-current are used in smelting of aluminum and other electrochemical processes. It is also used for some railways, especially in urban areas. High-voltage direct current is used to transmit large amounts of power from remote generation sites or to interconnect alternating current power grids.

The term DC is used to refer to power systems that use only one electrical polarity of voltage or current, and to refer to the constant, zero-frequency, or slowly varying local mean value of a voltage or current.[9] For example, the voltage across a DC voltage source is constant as is the current through a direct current source. The DC solution of an electric circuit is the solution where all voltages and currents are constant. It can be shown that any stationary voltage or current waveform can be decomposed into a sum of a DC component and a zero-mean time-varying component; the DC component is defined to be the expected value, or the average value of the voltage or current over all time.

Although DC stands for "direct current", DC often refers to "constant polarity". Under this definition, DC voltages can vary in time, as seen in the raw output of a rectifier or the fluctuating voice signal on a telephone line.

Some forms of DC (such as that produced by a voltage regulator) have almost no variations in voltage, but may still have variations in output power and current.
$
10

Question: What does DC stand for in the context of electricity?
A: Direct Current
B: Dynamic Circuit
C: Digital Control
D: Alternating Current
E: Dual Circuit
Answer: A

Question: How does the flow of electric charge in direct current (DC) differ from alternating current (AC)?
A: In DC, the charge flows back and forth.
B: In DC, the charge flows only in one direction.
C: In DC, the charge moves at a constant speed.
D: In DC, the charge flows through a vacuum.
E: In DC, the charge flows through insulators.
Answer: B

Question: What is a common example of a device that uses DC power?
A: Microwave oven
B: Television
C: Battery charger
D: Blender
E: Air conditioner
Answer: C

Question: How can direct current be converted into alternating current?
A: Using a battery
B: Using a transformer
C: Using a rectifier
D: Using an inverter
E: Using a generator
Answer: D

Question: What are some uses of direct current?
A: Charging batteries and electrochemical processes
B: Generating electricity in power plants
C: Transmitting power over long distances
D: Operating household appliances
E: Heating homes and businesses
Answer: A

Question: What is the term used to refer to power systems that use only one electrical polarity of voltage or current?
A: Constant frequency
B: Direct polarity
C: Zero-frequency
D: AC voltage
E: Zero-mean value
Answer: B

Question: What is the expected value of the voltage or current over all time in a direct current (DC) circuit?
A: Zero
B: Fluctuating
C: Maximum
D: Minimum
E: Constant
Answer: E

Question: What type of voltage or current waveform can be decomposed into a sum of a DC component and a zero-mean time-varying component?
A: Sinusoidal
B: Alternating
C: Triangular
D: Rectangular
E: Any stationary waveform
Answer: E

Question: What does the term "DC" often refer to in electrical systems?
A: Dynamic current
B: Constant voltage
C: Continuous power
D: Constant polarity
E: Alternating frequency
Answer: D

Question: What characteristic distinguishes DC from AC in terms of voltage and current?
A: DC has constant voltage and current.
B: DC has a constantly changing voltage.
C: DC has a zero-frequency waveform.
D: DC has a fluctuating current.
E: DC has alternating polarity.
Answer: A
@
A battery electric vehicle (BEV), pure electric vehicle, only-electric vehicle, fully electric vehicle or all-electric vehicle is a type of electric vehicle (EV) that exclusively uses chemical energy stored in rechargeable battery packs, with no secondary source of propulsion (a hydrogen fuel cell, internal combustion engine, etc.). BEVs use electric motors and motor controllers instead of internal combustion engines (ICEs) for propulsion. They derive all power from battery packs and thus have no internal combustion engine, fuel cell, or fuel tank. BEVs include – but are not limited to[1][2] – motorcycles, bicycles, scooters, skateboards, railcars, watercraft, forklifts, buses, trucks, and cars.

In 2016, there were 210 million electric bikes worldwide used daily.[3] Cumulative global sales of highway-capable light-duty pure electric car vehicles passed the one million unit milestone in September 2016.[4] As of October 2020, the world's top selling all-electric car in history is the Tesla Model 3, with an estimated 645,000 sales,[5] followed by the Nissan Leaf with over 500,000 sales as of September 2020.[6]

The concept of battery electric vehicles is to use charged batteries on board vehicles for propulsion. Battery electric cars are becoming more and more attractive with the higher oil prices and the advancement of new battery technology (lithium-ion) that have higher power and energy density (i.e., greater possible acceleration and more range with fewer batteries).[12] Compared to older battery types such as lead-acid batteries. Lithium-ion batteries for example now have an energy density of 0.9–2.63 MJ/L whereas lead-acid batteries had an energy density of 0.36 MJ/L (so 2.5 to 7.3x higher). There is still a long way to go if comparing it to petroleum-based fuels and biofuels, however (gasoline having an energy density of 34.2 MJ/L -38x to 12.92x higher- and ethanol having an energy of 24 MJ/L -26x to 9.12x higher-). This is partially offset by higher conversion efficiency of electric motors – BEVs travel roughly 3x further than similar-size internal combustion vehicles per MJ of stored energy.

BEVs include automobiles, light trucks, and neighborhood electric vehicles.
$
10
Question: What distinguishes a battery electric vehicle (BEV) from other vehicles?
A: BEVs use chemical energy stored in rechargeable battery packs as their sole source of propulsion.
B: BEVs use both internal combustion engines and electric motors for propulsion.
C: BEVs primarily use hydrogen fuel cells for propulsion.
D: BEVs have a fuel tank in addition to battery packs for propulsion.
E: BEVs rely on gasoline as their primary source of energy.
Answer: A

Question: What is the primary source of propulsion in a battery electric vehicle (BEV)?
A: Hydrogen fuel cell
B: Rechargeable battery packs
C: Internal combustion engine
D: Gasoline engine
E: Biofuel
Answer: B

Question: Which type of vehicle does NOT fall under the category of battery electric vehicles (BEVs)?
A: Forklift
B: Motorcycle
C: Internal combustion engine car
D: Railcar
E: Bus
Answer: C

Question: What is the world's top-selling all-electric car as of October 2020?
A: Tesla Model S
B: Nissan Leaf
C: Chevrolet Bolt
D: Toyota Prius
E: Ford Mustang Mach-E
Answer: B

Question: What is the concept behind battery electric vehicles (BEVs)?
A: To use charged batteries onboard vehicles for propulsion
B: To rely solely on hydrogen fuel cells for propulsion
C: To combine internal combustion engines and electric motors for propulsion
D: To use biofuels as the primary source of energy
E: To utilize gasoline engines for long-range travel
Answer: A

Question: What has made battery electric cars more attractive in recent years?
A: Lower oil prices
B: Advancements in internal combustion engine technology
C: New battery technology with higher power and energy density
D: Widespread availability of hydrogen fuel cells
E: Decreased range with fewer batteries
Answer: C

Question: How does the energy density of lithium-ion batteries compare to that of lead-acid batteries?
A: Lithium-ion batteries have a lower energy density.
B: Lithium-ion batteries have roughly the same energy density.
C: Lithium-ion batteries have an energy density 2.5 to 7.3 times higher.
D: Lithium-ion batteries have an energy density 12.92 to 38 times higher.
E: Lithium-ion batteries have an energy density 9.12 to 26 times higher.
Answer: D

Question: What contributes to battery electric vehicles (BEVs) traveling roughly 3 times further than similar-size internal combustion vehicles per MJ of stored energy?
A: Higher energy density of lead-acid batteries
B: Higher energy density of gasoline
C: Higher conversion efficiency of electric motors
D: Lower availability of biofuels
E: Lower oil prices
Answer: C

Question: What types of vehicles are included in the category of battery electric vehicles (BEVs)?
A: Cars and trucks only
B: Motorcycles and bicycles only
C: Railcars and watercraft only
D: Buses and trucks only
E: Automobiles, light trucks, and neighborhood electric vehicles
Answer: E

Question: How does the energy density of gasoline compare to lithium-ion batteries?
A: Gasoline has an energy density roughly 3 times higher.
B: Gasoline has an energy density roughly 12.92 to 38 times higher.
C: Gasoline has an energy density roughly 9.12 to 26 times higher.
D: Gasoline has an energy density roughly the same as lithium-ion batteries.
E: Gasoline has an energy density roughly 2.5 to 7.3 times higher.
Answer: B
@
Radio waves are a type of electromagnetic radiation with the longest wavelengths in the electromagnetic spectrum, typically with frequencies of 300 gigahertz (GHz) and below.[citation needed] At 300 GHz, the corresponding wavelength is 1mm, which is shorter than the diameter of a grain of rice. At 30 Hz the corresponding wavelength is ~10,000 kilometers (6,200 miles), which is longer than the radius of the Earth. Wavelength of a radio wave is inversely proportional to its frequency, because its velocity is constant. Like all electromagnetic waves, radio waves in a vacuum travel at the speed of light, and in the Earth's atmosphere at a slightly slower speed. Radio waves are generated by charged particles undergoing acceleration, such as time-varying electric currents.[1] Naturally occurring radio waves are emitted by lightning and astronomical objects, and are part of the blackbody radiation emitted by all warm objects.

Radio waves are generated artificially by an electronic device called a transmitter, which is connected to an antenna which radiates the waves. They are received by another antenna connected to a radio receiver, which processes the received signal. Radio waves are very widely used in modern technology for fixed and mobile radio communication, broadcasting, radar and radio navigation systems, communications satellites, wireless computer networks and many other applications. Different frequencies of radio waves have different propagation characteristics in the Earth's atmosphere; long waves can diffract around obstacles like mountains and follow the contour of the earth (ground waves), shorter waves can reflect off the ionosphere and return to earth beyond the horizon (skywaves), while much shorter wavelengths bend or diffract very little and travel on a line of sight, so their propagation distances are limited to the visual horizon.

To prevent interference between different users, the artificial generation and use of radio waves is strictly regulated by law, coordinated by an international body called the International Telecommunication Union (ITU), which defines radio waves as "electromagnetic waves of frequencies arbitrarily lower than 3,000 GHz, propagated in space without artificial guide".[2] The radio spectrum is divided into a number of radio bands on the basis of frequency, allocated to different uses.
$
10
Question: What is the relationship between the frequency and wavelength of a radio wave?
A: Frequency and wavelength are directly proportional.
B: Frequency and wavelength are inversely proportional.
C: Frequency and wavelength have no relationship.
D: Frequency and wavelength are the same.
E: Frequency determines the speed of light.
Answer: B

Question: What is the speed at which radio waves travel in a vacuum?
A: Faster than the speed of light
B: Slower than the speed of light
C: Equal to the speed of light
D: Speed varies depending on the frequency
E: Speed varies depending on the wavelength
Answer: C

Question: How are radio waves naturally generated?
A: By mechanical vibrations
B: By temperature changes
C: By charged particles undergoing acceleration
D: By magnetic fields
E: By gravitational waves
Answer: C

Question: How are radio waves artificially generated?
A: By lightning strikes
B: By blackbody radiation
C: By cosmic rays
D: By charged particles undergoing acceleration
E: By gamma-ray bursts
Answer: D

Question: What is the primary purpose of a radio receiver?
A: To generate radio waves
B: To process received radio signals
C: To transmit radio waves
D: To amplify radio signals
E: To create interference in radio communication
Answer: B

Question: Which international body regulates the artificial generation and use of radio waves?
A: United Nations
B: World Health Organization
C: International Telecommunication Union (ITU)
D: International Atomic Energy Agency (IAEA)
E: European Space Agency (ESA)
Answer: C

Question: What is the definition of the radio spectrum?
A: A visual representation of radio waves
B: The range of radio frequencies allocated to different uses
C: A specific type of radio wave used for radar systems
D: The speed of radio waves in the Earth's atmosphere
E: A mathematical equation for calculating radio wave propagation
Answer: B

Question: How do long waves of radio waves behave in the Earth's atmosphere?
A: They reflect off the ionosphere and return to Earth.
B: They bend or diffract very little and travel in a straight line.
C: They are absorbed by the ground.
D: They can only travel in a straight line of sight.
E: They follow the contour of the Earth's surface.
Answer: E

Question: What is the primary application of radio waves in modern technology?
A: Cooking food in microwave ovens
B: Generating electricity in power plants
C: Wireless computer networks
D: Creating visual effects in television screens
E: Predicting weather patterns
Answer: C

Question: What defines radio waves as "electromagnetic waves of frequencies arbitrarily lower than 3,000 GHz, propagated in space without artificial guide"?
A: International Radio Regulations
B: International Broadcast Standards
C: International Telecommunication Union (ITU)
D: International Frequency Allocation Act
E: International Radio Spectrum Allocation
Answer: C
@













































































































































